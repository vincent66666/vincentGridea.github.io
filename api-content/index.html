{"posts":[{"title":"jenkins参数化构建:条件触发构建","content":"环境背景 km - 2cpu - 4g内存 - ip - 192.168.23.39 node1 - 2cpu - 2G内存 - ip - 192.168.23.40 node1 - 2cpu - 2G内存 - ip - 192.168.23.41 基于上篇文章已有可正常运行的jenkins工作任务 jenkins 已按文章安装好 kubernetes 与 Git Parameter 扩展 git 仓库地址（CI/CD所需文件及代码） https://gitee.com/lzcit/k8s.git master tag为: master-20220401-00 dev tag为: dev-20220401-00 所有操作基于官方文档说明 增加jenkins构建参数 勾选 This project is parameterized 增加 docker_registry 构建参数 点击增加参数选择 - String Parameter 填充如下数据 增加 banch_name 构建参数 点击增加参数选择 - Git Parameter 参数类型选择分支 填充如下数据 增加 tag_name 和 dev_tag_name 构建参数 点击增加参数选择 - Git Parameter 参数类型选择标签 填充如下数据 点击高级填充表填过滤 tag_name 填写 master* dev_tag_name 填写 dev* 修改排序方式为倒叙 构建显示 若首次构建无法出现分支与标签，需要先构建一次才会显示 修改Pipeline脚本 条件触发 script{ if(branch_name == &quot;origin/master&quot;){ #master构建 } else { #dev构建 } } 相关 Deployment与Service配置在git仓库内go_app.yaml文件 apiVersion: apps/v1 kind: Deployment metadata: name: go-app-${branch_name} labels: app: goweb${branch_name} spec: selector: matchLabels: app: goweb${branch_name} replicas: 10 strategy: type: RollingUpdate template: metadata: labels: app: goweb${branch_name} spec: containers: - name: go-app-${branch_name} image: ${docker_registry}/k8s:${tag_name} imagePullPolicy: Always ports: - name: http containerPort: 80 livenessProbe: httpGet: port: 80 path: /ping initialDelaySeconds: 2 periodSeconds: 60 timeoutSeconds: 3 --- apiVersion: v1 kind: Service metadata: name: go-app-${branch_name} spec: type: ClusterIP selector: app: goweb${branch_name} ports: - port: 80 protocol: TCP targetPort: 80 最终脚本 基于 上篇文章 修改 pipeline { agent any stages { stage('clone') { steps { echo 'clone' // 拉取代码 git credentialsId: 'gitee_userid', url: 'https://gitee.com/lzcit/k8s.git' sh &quot;git checkout ${branch_name}&quot; sh &quot;sed -i 's/\\${docker_registry}/${docker_registry}/g' go_app.yaml&quot; script{ //替换环境变量 if(branch_name == &quot;origin/master&quot;){ sh &quot;sed -i 's/\\${branch_name}/master/g' go_app.yaml&quot; sh &quot;sed -i 's/\\${branch_name}/master/g' run.go&quot; sh &quot;sed -i 's/\\${tag_name}/${tag_name}/g' go_app.yaml&quot; sh &quot;sed -i 's/\\${tag_name}/${tag_name}/g' run.go&quot; } else { sh &quot;sed -i 's/\\${branch_name}/dev/g' go_app.yaml&quot; sh &quot;sed -i 's/\\${branch_name}/dev/g' run.go&quot; sh &quot;sed -i 's/\\${tag_name}/${dev_tag_name}/g' go_app.yaml&quot; sh &quot;sed -i 's/\\${tag_name}/${dev_tag_name}/g' run.go&quot; } } } } stage('build go') { steps { echo 'build go' // 编译可执行文件 sh &quot;export GOPROXY='https://goproxy.cn' &amp;&amp; go mod tidy &amp;&amp; CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o ./run run.go&quot; sh &quot;mkdir -p work &amp;&amp; cp -a run ./work/ &amp;&amp; cp -a static ./work/&quot; } } stage('make image') { steps { echo 'make image' // 制作代码镜像 script{ if(branch_name == &quot;origin/master&quot;){ sh &quot;docker build -f Dockerfile -t ${docker_registry}/k8s:${tag_name} .&quot; } else { sh &quot;docker build -f Dockerfile -t ${docker_registry}/k8s:${dev_tag_name} .&quot; } } } } stage('push image') { steps { echo 'push image' // 推送到私有仓库 script{ if(branch_name == &quot;origin/master&quot;){ sh &quot;docker push ${docker_registry}/k8s:${tag_name}&quot; } else { sh &quot;docker push ${docker_registry}/k8s:${dev_tag_name}&quot; } } } } stage('deploy') { steps { echo 'deploy' // 部署代码 kubeconfig(caCertificate: '''-----BEGIN CERTIFICATE----- MIIC/jCCAeagAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJl cm5ldGVzMB4XDTIyMDQwMTAxNDU0NVoXDTMyMDMyOTAxNDU0NVowFTETMBEGA1UE AxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAJ6u P4IG/t/uorMEiVgseW1llz/XyO2BCvl7Hu1dtS1NNu7360H/fTs+HqP7Ss8Qf5Yh di3DbClKfERUHD8nKLztocSrrJNbKhniQOpI9tUJIbMVkCj5iBWthHrrQshdPB90 xP5skLM+aMoraIJqWdvzzcDKdjfi0pV6XM37YOovYT5e8IzTJ5a24dWCCu5z7J1+ rEQPxOp9AOyqctpUyneA5LK0nxxNs3Vqv16t97IzTPttAiRfUfNEVDswUqF/pspd aBM3u3saQ/08BhKn45lGNog3huC5kViT0U61Z84EuX/a+YOWxPAIWnSnRrwl7oFR fBpIKNJq59SlYtanVskCAwEAAaNZMFcwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB /wQFMAMBAf8wHQYDVR0OBBYEFJ3uWtxk0fbtEy5E+bodzUpPojErMBUGA1UdEQQO MAyCCmt1YmVybmV0ZXMwDQYJKoZIhvcNAQELBQADggEBAGgJH5enPPtMnQwyjtJm PH13dV/CU/R+8i3w4Mz567otNNTlWNZ5bHb6ddKUKQ6iaSMJ3y/O/Oi1RAVFAGA2 6ffL5BWiQyywNdzjUdd5nPFz97BfDqm5yIEVdIecSNnzbe47IDyXl0vHegp31DRf YHGOQ0PTOJz1rJ7qKNehsM3j5p2Hg22o4IT6EqaXNRS/tlaCb5cG5OLil+vAebl/ FNfII8/ORpMN6KFGH6iC1TBsXPzn1Y6vzLv96758L8DpLmMBZ/z9f+s/ZyPESrxo tkCZ89YwTMchrxHg0uluRnh8MQaUPgm1itTIdJNrwet1zBrQOogkOfFZdfunSkdy 0yE= -----END CERTIFICATE-----''', credentialsId: 'kubernetes-key', serverUrl: 'https://192.168.23.39:6443') { sh &quot;kubectl apply -f go_app.yaml&quot; } } } } } 查看结果 查看 kubernetes(k8s) pods 发布结果 校验 kubernetes(k8s) 最终发布 所需shell命令 kubectl get pod kubectl get svc curl svc_ip/ping ","link":"https://www.vincent.ac.cn/post/NyBeI-EwM/"},{"title":"jenkins+kubernetes(k8s)+docker持续集成与部署(CI/CD) ","content":"环境背景 km - 2cpu - 4g内存 - ip - 192.168.23.39 node1 - 2cpu - 2G内存 - ip - 192.168.23.40 node1 - 2cpu - 2G内存 - ip - 192.168.23.41 示例语言 - 因GO语言支持跨平台编译，对容器化部署非常友好，所以示例使用GO语言 git 仓库地址（CI/CD所需文件及代码） https://gitee.com/lzcit/k8s.git tag为: master-20220331-00 所有操作基于官方文档说明 GO语言安装 wget https://golang.google.cn/dl/go1.18.linux-amd64.tar.gz tar -xvzf go1.18.linux-amd64.tar.gz cp -a go /usr/local/go-1.18 ln -s /usr/local/go-1.18/* /bin/ 搭建本地仓库 搭建私有镜像仓库 #拉取所需镜像 docker pull registry #启动私有镜像仓库 docker run -itd -e REGISTRY_STORAGE_DELETE_ENABLED=true -p 5000:5000 -v /www/wwwroot/private_registry:/var/lib/registry --name docker_registry registry #私有镜像仓库可视化web仓库 docker pull konradkleine/docker-registry-frontend:v2 #启动私有镜像仓库可视化web docker run -d --restart=always -e ENV_DOCKER_REGISTRY_HOST=192.168.23.39 -e ENV_DOCKER_REGISTRY_PORT=5000 -p 9011:80 konradkleine/docker-registry-frontend:v2 修改仓库源(三台机器都需要修改) vim /etc/docker/daemon.json #增加如下代码 &quot;insecure-registries&quot;: [ &quot;192.168.23.39:5000&quot; ], 常用命令 #查看所有仓库 curl -XGET http://192.168.23.39:5000/v2/_catalog #查看某个仓库的tag curl -XGET http://192.168.23.39:5000/v2/k8s/tags/list #查看某个仓库tag的sha256码 curl --header &quot;Accept: application/vnd.docker.distribution.manifest.v2+json&quot; -I -X HEAD http://192.168.23.39:5000/v2/k8s/manifests/tagname #删除某个Tag curl -v -X DELETE http://192.168.23.39:5000/v2/k8s/manifests/sha256:sha256code 安装jenkins 安装jenkins - 基于官方文档 wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo --no-check-certificate rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key yum install -y java-11-openjdk yum install -y jenkins systemctl start jenkins systemctl daemon-reload #查看admin密码 cat /var/lib/jenkins/secrets/initialAdminPassword 初始化jenkins 访问: http://192.168.23.39:8080/ 账号:admin 密码:cat /var/lib/jenkins/secrets/initialAdminPassword 登录后选择安装推荐的插件 ( 如果因为网络原因部分失败，请点击重试 ) 安装插件 - Manage Jenkins -&gt; Manage Plugin 搜索 Authorization 安装 Role-based Authorization Strategy 和 Authorize Project - 权限管理 搜索 kubernetes 安装 kubernetes 搜索 Git Parameter 安装 Git Parameter 创建CI/CD 准备工作 #拉取环境镜像 docker pull alpine:latest #安装git yum install -y git #将jenkins添加到docker用户组 - 重要 gpasswd -a jenkins docker #重启jenkins systemctl restart jenkins 创建Pipeline 创建工作任务 - 输入任务名称 - 选择Pipeline Pipeline流水线配置推荐 pipeline { agent any stages { stage('clone') { steps { echo 'clone' // 拉取代码 } } stage('build go') { steps { echo 'build go' // 编译可执行文件 } } stage('make image') { steps { echo 'make image' // 制作代码镜像 } } stage('push image') { steps { echo 'push image' // 推送到私有仓库 } } stage('deploy') { steps { echo 'deploy' // 部署代码 } } } } 使用流水线语法工具 选择工作任务点击设置，拉到最下面，点击 流水线语法 生成git语法 - 填充到 clone 示例步骤 - 选择git 输入仓库url: https://gitee.com/lzcit/k8s.git 如需账号密码则需要 添加凭据 选择 user_name with password 填充确定 填充其他信息 生成流水线脚本 填充到 clone git credentialsId: 'gitee_userid', url: 'https://gitee.com/lzcit/k8s.git' 生成kubernetes(k8s)语法 - 填充到 deploy 准备工作 #kubernetes(k8s) 相关配置 cat /root/.kube/config #分别保存 certificate-authority-data/client-certificate-data/client-key-data的值为对应的txt文件 cat /root/.kube/config|grep certificate-authority-data |awk -F ': ' '{print $2}' &gt; certificate-authority-data.txt cat /root/.kube/config|grep client-certificate-data |awk -F ': ' '{print $2}' &gt; client-certificate-data.txt cat /root/.kube/config|grep client-key-data |awk -F ': ' '{print $2}' &gt; client-key-data.txt #生成秘钥文件 cat certificate-authority-data.txt |base64 -d &gt; ca.crt cat client-certificate-data.txt |base64 -d &gt; client.crt cat client-key-data.txt |base64 -d &gt; client.key openssl pkcs12 -export -out cert.pfx -inkey client.key -in client.crt -certfile ca.crt #Enter Export Password:输入自定义密码 #Verifying - Enter Export Password:再次输入自定义密码 #查看kubernetes(k8s)集群信息 kubectl cluster-info 示例步骤 - 选择kubeconfig 输入服务端点: kubectl cluster-info 可查看 https://192.168.23.39:6443 填充 Certificate of certificate authority - ca.crt文件内容 添加凭据类型选择Certificate 上传cert.pfx文件 输入密码为上面 自定义密码 填充其他信息 生成流水线脚本 填充到 deploy kubeconfig(caCertificate: '''-----BEGIN CERTIFICATE----- MIIC/jCCAeagAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJl cm5ldGVzMB4XDTIyMDMxOTA4MTAwM1oXDTMyMDMxNjA4MTAwM1owFTETMBEGA1UE AxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAOMy ekzc4rWutBV/5ATcWLirMI8mXPycEW8WpGsZF28nlFBHy50UlmcD0tViV/JDjc2e mj9/DEWy/H81os1a8jTcyGLI8p+TKi3avDibQGe4etUDF+eJavEn5zqWEoP98ohA HfTJijBfIaI7n/qCiHVMnwvS+2yakaMcBoNhgOCDCN9gHpNqa1xBrXIr6o1HMrv7 RQ88t26yss3e/wq3XqNApEBdk1nIkDHy/ZuFO+kTMtPPO67QBNa9LaFhKRU2/VdE /HAGk3n5JQ604Bn8hLZmDrf11p2dDbN6K9NtKbGuOLXbN0PsLnoBMCFdiRC/Ol1t RneY86zkPgk6FQEv15ECAwEAAaNZMFcwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB /wQFMAMBAf8wHQYDVR0OBBYEFLiwKGVC7HEf3goVSrzybGlpvWdSMBUGA1UdEQQO MAyCCmt1YmVybmV0ZXMwDQYJKoZIhvcNAQELBQADggEBABcXtzTpR+Oee8VzVQte gqvy3DQyTOcne5CS0q+kliyY36Tfsh9mieGhhHKRlD2esWVyl25qo6D0zgDhQOem y/QKS7/Wka3i49ygw4dxC/mJEAzMRsrCxsEFqptHXM6IMaXmsLbsil16kmMx2fLV 4g46+TKqrRmdRSYMtUTieZtl+IJU9zmQJSYxCUFLXPysknxqenGOmbqnPat9FcZ1 BkrZf7yD8fCbq50zcFtSP3d6hxiN9rbPGsNWGjkj+WXZ0EymxWVukKwX/BRuNlLP jDVgDCeR1rMCoGMkTgm1WqjynOAn/V4dl757E5da2NeOPgCfWBIuKdqOMPo4eWUV Mls= -----END CERTIFICATE-----''', credentialsId: 'kubernetes-pfx', serverUrl: 'https://192.168.23.39:6443') { --TODO } 相关 Deployment与Service配置在git仓库内go_app.yaml文件 apiVersion: apps/v1 kind: Deployment metadata: name: go-app labels: app: goweb spec: selector: matchLabels: app: goweb replicas: 10 strategy: type: RollingUpdate template: metadata: labels: app: goweb spec: containers: - name: go-app image: 192.168.23.39:5000/k8s:tag_name imagePullPolicy: Always ports: - name: http containerPort: 80 livenessProbe: httpGet: port: 80 path: /ping initialDelaySeconds: 2 periodSeconds: 60 timeoutSeconds: 3 --- apiVersion: v1 kind: Service metadata: name: go-app spec: type: ClusterIP selector: app: goweb ports: - port: 80 protocol: TCP targetPort: 80 最终流水线脚本 pipeline { agent any stages { stage('clone') { steps { echo 'clone' // 拉取代码 git credentialsId: 'gitee_userid', url: 'https://gitee.com/lzcit/k8s.git' sh &quot;git checkout master-20220331-00&quot; //切换本期对应的代码分支 } } stage('build go') { steps { echo 'build go' // 编译可执行文件 sh &quot;export GOPROXY='https://goproxy.cn' &amp;&amp; go mod tidy &amp;&amp; CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o ./run run.go&quot; sh &quot;mkdir -p work &amp;&amp; cp -a run ./work/ &amp;&amp; cp -a static ./work/&quot; } } stage('make image') { steps { echo 'make image' // 制作代码镜像 sh &quot;docker build -f Dockerfile -t 192.168.23.39:5000/k8s:tag_name .&quot; //相关Dockerfile在git上 } } stage('push image') { steps { echo 'push image' // 推送到私有仓库 sh &quot;docker push 192.168.23.39:5000/k8s:tag_name&quot; } } stage('deploy') { steps { echo 'deploy' // 部署代码 kubeconfig(caCertificate: '''-----BEGIN CERTIFICATE----- MIIC/jCCAeagAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJl cm5ldGVzMB4XDTIyMDMyOTAzMzcyOVoXDTMyMDMyNjAzMzcyOVowFTETMBEGA1UE AxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAOZO NeeVjwkKy0BoGA0QetynFk89/3Zlh2EUmbbBXMygwDkbiJ0wRGyIDXiYqQ4HniC5 q0I8DwTB7WPkwhaHBGrQItXcuoo68hxnR3sRewwfuUB4uivkkhqIyeMk2KgSvbLW 41dnX6QamWSYJLGkLMmLru+BaKkEPGe1SZQH6ognATDm19Kt5vtu70kZH5O7qH38 TOguX+inuboREDB2RpMBm0Qp5NdXm3QXFlwHkryvYYIR5JkexHnUi9jjLy3V4qdQ uDJhrcS6/w286IHeMzZ5dOaKcQ4vp7/wyk4soD+5MHnaBmttRkUIGwaTwmWWQjUp votUOjK3CAkD/EsysqMCAwEAAaNZMFcwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB /wQFMAMBAf8wHQYDVR0OBBYEFObVS5S7UkExTHiRIaJzKXtAfuiYMBUGA1UdEQQO MAyCCmt1YmVybmV0ZXMwDQYJKoZIhvcNAQELBQADggEBAEN2sVIkQhuCGaLMuxTh e+91J7LYnMEw6U/RTM3jyxm/6L0iSOx4jYh3MES7Nl7r42IRF0QxOV8cPy3AzMby MZs+KEt67EusJFNucEkRbmcJuYmokbzc3U+hxQi4rA2AHnOLUPvH9cz6A1uaRlJ5 +PqGatgLSKXeZIwYtlI+JV5a6s4Ra2fBNbvcGSm0n8IJp0Jf5kgqmF7Gy5pBKDuP 2ifb45U/ntkc7hIzXd+wJd6369W031NUjAOMCE1xovv4RGlW2BAa0PEX+XBuZ3bW UVTd0XVUVuhjoStKI+3jm7GF96d/a5Igj+JwkjeEq3POC131LMlt5gd2ohMTbcr2 MyM= -----END CERTIFICATE-----''', credentialsId: 'kubernetes-key', serverUrl: 'https://192.168.23.39:6443') { sh &quot;kubectl apply -f go_app.yaml&quot; } } } } } 执行jenkins -&gt; Build now - 结束 ","link":"https://www.vincent.ac.cn/post/Prix7QUh-/"},{"title":"使用kubeadm安装kubernetes","content":"环境配置 - VMware km - 2cpu - 4g内存 - ip - 192.168.23.39 node1 - 2cpu - 2G内存 - ip - 192.168.23.40 node1 - 2cpu - 2G内存 - ip - 192.168.23.41 安装 kubernetes 非特别说明都是3台机器同时操作 所有操作基于官方文档说明 关闭防火墙 systemctl stop firewalld &amp;&amp; systemctl disable firewalld 禁用交换分区 swapoff -a vim /etc/fstab # - 注释最后一行 增加host echo &quot;192.168.23.39 km&quot; &gt;&gt; /etc/hosts echo &quot;192.168.23.40 kn1&quot; &gt;&gt; /etc/hosts echo &quot;192.168.23.41 kn2&quot; &gt;&gt; /etc/hosts 安装kubectl curl -LO &quot;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl&quot; sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl 设置网桥参数 - 允许 iptables 检查桥接流量 cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system 安装 docker - 注: centos默认yum源版本过低，无法使用 yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine yum install -y yum-utils yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo yum install -y docker-ce docker-ce-cli containerd.io mkdir /etc/docker cat &lt;&lt;EOF | sudo tee /etc/docker/daemon.json { &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: { &quot;max-size&quot;: &quot;100m&quot; }, &quot;storage-driver&quot;: &quot;overlay2&quot; } EOF systemctl enable docker &amp;&amp; systemctl daemon-reload &amp;&amp; systemctl start docker 安装 kubeadm kubelet 和 kubectl - 使用阿里云源 cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF sudo setenforce 0 sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet 初始化kubeadm - 只在master上用 - 使用阿里云源 kubeadm config images pull --image-repository registry.aliyuncs.com/google_containers kubeadm init --image-repository=registry.aliyuncs.com/google_containers --pod-network-cidr 10.244.0.0/16 # 等待出现类似如下提示 kubeadm join 192.168.23.39:6443 --token uls8na.09040heqbwbk7e7u \\ --discovery-token-ca-cert-hash sha256:e0a2baba820581f76434dfd5b68011ce2ed2e644bb50dd73cd84bdeca00bce52 # 后续操作 rm -rf $HOME/.kube mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # 启动k8s systemctl start kubelet 安装 Pod 网络附加组件 - 建议kube-flannel.yml - 只在master上用 wget https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml kubectl apply -f kube-flannel.yml node加入结束 - 只在node节点使用上用 - 8中最后提示 kubeadm join 192.168.23.39:6443 --token uls8na.09040heqbwbk7e7u --discovery-token-ca-cert-hash sha256:e0a2baba820581f76434dfd5b68011ce2ed2e644bb50dd73cd84bdeca00bce52 简单命令 kubectl get nodes kubectl get pods --all-namespaces kubectl logs podName -n NameSpaceName ","link":"https://www.vincent.ac.cn/post/DY4viH_Fi/"},{"title":"使用CODING 自动构建部署 Hyperf项目","content":" 不是集群部署，适合个人或小公司项目使用 创建基础项目 1、先创建一个项目 2、关联代码仓库 构建计划 整体的Jenkins流程 检出分支 载入配置信息 根据分支下的 Dockerfile 生成镜像 推送镜像到 coding 的制品仓库 最后登录服务器拉取镜像进行部署 那么我们就开始编写构建计划吧 编写构建计划 创建构建计划 首先先创建一个构建计划 我们选择自定义构建过程 选择关联的代码仓库，配置来源选择使用静态配置的 Jenkinsfile 然后点击确认进来配置详情选择文本编辑器 载入配置信息并生成镜像并推送到制品仓库 pipeline { agent any stages { stage('检出') { steps { checkout([ $class: 'GitSCM', branches: [[name: GIT_BUILD_REF]], userRemoteConfigs: [[ url: GIT_REPO_URL, credentialsId: CREDENTIALS_ID ]]]) } } stage('载入配置信息') { steps { sh &quot;cp ${HYPERF_ENV_NAME} .env&quot; } } stage('构建镜像并推送到 CODING Docker 制品库') { steps { sh &quot;docker build -t ${CODING_DOCKER_IMAGE_NAME}:${DOCKER_IMAGE_VERSION} -f ${DOCKERFILE_PATH} ${DOCKER_BUILD_CONTEXT}&quot; useCustomStepPlugin(key: 'coding-public:artifact_docker_push', version: 'latest', params: [image:&quot;${CODING_DOCKER_IMAGE_NAME}:${DOCKER_IMAGE_VERSION}&quot;,repo:'hyperf',properties:'[]',project:'xuexi',username:'${PROJECT_TOKEN_GK}',password:'${PROJECT_TOKEN}']) } } } } 自动部署 pipeline { agent any stages { stage('检出') { steps { checkout([$class: 'GitSCM', branches: [[name: GIT_BUILD_REF]], userRemoteConfigs: [[ url: GIT_REPO_URL, credentialsId: CREDENTIALS_ID ]]]) } } stage('代码检测') { steps { sh 'php -v' } } stage('载入配置信息') { steps { sh &quot;cp ${HYPERF_ENV_NAME} .env&quot; } } stage('构建镜像并推送到 CODING Docker 制品库') { steps { sh 'pwd &amp;&amp; ls -l' useCustomStepPlugin(key: 'coding-public:magic-version', version: 'latest') script { readProperties(file: env.CI_ENV_FILE).each {key, value -&gt; env[key] = value } } echo &quot;${env.MAGIC_VERSION}&quot; sh &quot;docker build -t ${CODING_DOCKER_IMAGE_NAME}:${DOCKER_IMAGE_VERSION} -f ${DOCKERFILE_PATH} ${DOCKER_BUILD_CONTEXT}&quot; useCustomStepPlugin(key: 'coding-public:artifact_docker_push', version: 'latest', params: [image:&quot;${CODING_DOCKER_IMAGE_NAME}:${DOCKER_IMAGE_VERSION}&quot;,repo:'hyperf',properties:'[]',project:'xuexi',username:'${PROJECT_TOKEN_GK}',password:'${PROJECT_TOKEN}']) } } stage('部署到远端服务') { steps { sh 'pwd &amp;&amp; ls -l' script { def remoteConfig = [:] remoteConfig.name = &quot;my-remote-server&quot; remoteConfig.host = &quot;${REMOTE_HOST}&quot; remoteConfig.allowAnyHosts = true node { // 使用当前项目下的凭据管理中的 用户名 + 密码 凭据 withCredentials([usernamePassword( credentialsId: &quot;${REMOTE_CRED}&quot;, passwordVariable: 'password', usernameVariable: 'userName' )]) { // SSH 登陆用户名 remoteConfig.user = userName // SSH 登陆密码 remoteConfig.password = password // 请确保远端环境中有 Docker 环境 sshCommand( remote: remoteConfig, command: &quot;docker login -u ${CODING_DOCKER_REG_USERNAME} -p ${CODING_DOCKER_REG_PASSWORD} ${CODING_DOCKER_REG_HOST}&quot;, sudo: true, ) // 生成devops目录 sshCommand( remote: remoteConfig, command: &quot;mkdir -p /mnt/devops/${CODING_DOCKER_IMAGE_NAME}/&quot;, sudo: false, ) sshPut( remote: remoteConfig, // 本地文件或文件夹 from: '/root/workspace/deploy-devops.sh', // 远端文件或文件夹 into: &quot;/mnt/devops/${CODING_DOCKER_IMAGE_NAME}/&quot; ) // DOCKER_IMAGE_VERSION 中涉及到 GIT_LOCAL_BRANCH / GIT_TAG / GIT_COMMIT 的环境变量的使用 // 需要在本地完成拼接后，再传入到远端服务器中使用 DOCKER_IMAGE_URL = sh( script: &quot;echo ${CODING_DOCKER_REG_HOST}/${CODING_DOCKER_IMAGE_NAME}:${DOCKER_IMAGE_VERSION}&quot;, returnStdout: true ) sh( script:&quot;echo ${SERVER_PREFIX_NAME}&quot; ) sshCommand( remote: remoteConfig, command: &quot;/bin/bash /mnt/devops/${CODING_DOCKER_IMAGE_NAME}/deploy-devops.sh ${DOCKER_IMAGE_URL} ${SERVER_PREFIX_NAME} http&quot;, sudo: false, ) echo &quot;部署成功&quot; } } } } } } environment { CODING_DOCKER_REG_HOST = &quot;${CCI_CURRENT_TEAM}-docker.pkg.${CCI_CURRENT_DOMAIN}&quot; CODING_DOCKER_IMAGE_NAME = &quot;${PROJECT_NAME.toLowerCase()}/${DOCKER_REPO_NAME}/${DOCKER_IMAGE_NAME}&quot; CODING_DOCKER_REG_USERNAME = '制品仓库账号' CODING_DOCKER_REG_PASSWORD = '制品仓库密码' } } deploy-devops.sh 脚本 #!/bin/bash DOCKER_IMAGE_URL=${1} SERVER_PREFIX_NAME=${2} TASK=${3} if [ &quot;${SERVER_PREFIX_NAME}&quot; = &quot;&quot; ]; then SERVER_PREFIX_NAME=&quot;server_app&quot; fi if [ &quot;${TASK}&quot; = &quot;&quot; ]; then TASK=&quot;http&quot; fi echo &quot;DOCKER_IMAGE_URL: ${DOCKER_IMAGE_URL}&quot; echo &quot;SERVER_PREFIX_NAME: ${SERVER_PREFIX_NAME}&quot; echo &quot;TASK: ${TASK}&quot; # 检查 http服务端口 check_port() { # shellcheck disable=SC1083 code=$(curl -I -m 10 -o /dev/null -s -w %{http_code} 127.0.0.1:&quot;$1&quot;/check_port) echo &quot;$code&quot; } # 检查 socket服务端口 socket_io_check_port() { port=$1 # shellcheck disable=SC2196 TCP=$(netstat -an | egrep &quot;:${port}&quot; | awk '$1 == &quot;tcp&quot; &amp;&amp; $NF == &quot;LISTEN&quot; ' |wc -l) # shellcheck disable=SC2196 UDP=$(netstat -an | egrep &quot;:${port}&quot; | awk '$1 == &quot;udp&quot; &amp;&amp; $NF == &quot;0.0.0.0:*&quot;' |wc -l) ((Total = TCP + UDP )) if [ &quot;${Total}&quot; == 0 ]; then echo 400 else echo 200 fi } #TODO HTTP服务 随机可用端口 ports=(9791 9792) #TODO 随机API可用端口 online_port=0 reload_port=0 for i in &quot;${!ports[@]}&quot;; do code=$(check_port &quot;${ports[$i]}&quot;) # shellcheck disable=SC2053 if [[ '200' == $code ]]; then online_port=${ports[$i]} else reload_port=${ports[$i]} fi done if [[ $online_port == 0 ]]; then echo '服务未启动' reload_port=${ports[0]} echo &quot;自动分配端口 $reload_port&quot; else echo &quot;当前端口 $online_port&quot; echo &quot;重启端口 $reload_port&quot; fi if [[ $reload_port == 0 ]]; then echo '部署失败, 未获取到可用端口' exit 1; fi if [[ ${TASK} == &quot;socket&quot; ]]; then #TODO 随机socket.io可用端口 socket_io_ports=(9990 9991) socket_io_online_port=0 socket_io_reload_port=0 for i in &quot;${!socket_io_ports[@]}&quot;; do code=$(socket_io_check_port &quot;${socket_io_ports[$i]}&quot;) # shellcheck disable=SC2053 if [[ '200' == $code ]]; then socket_io_online_port=${socket_io_ports[$i]} else socket_io_reload_port=${socket_io_ports[$i]} fi done if [[ $socket_io_online_port == 0 ]]; then echo '服务未启动' socket_io_reload_port=${socket_io_ports[0]} echo &quot;socket.io自动分配端口 $socket_io_reload_port&quot; else echo &quot;socket.io当前端口 $socket_io_online_port&quot; echo &quot;socket.io重启端口 $socket_io_reload_port&quot; fi if [[ $socket_io_reload_port == 0 ]]; then echo '部署失败, 未获取到可用socket.io端口' exit 1; fi fi # nginx配置文件路径 nginx_upstream='/www/server/panel/vhost/upstream/'&quot;${SERVER_PREFIX_NAME}&quot;'_upstream.conf' # 创建文件 if [ ! -f &quot;$nginx_upstream&quot; ]; then touch $nginx_upstream upstream_default=' upstream '&quot;${SERVER_PREFIX_NAME}&quot;'_upstream { server 127.0.0.1:'&quot;$reload_port&quot;'; } upstream '&quot;${SERVER_PREFIX_NAME}&quot;'_upstream_socket_io { server 127.0.0.1:'&quot;$socket_io_reload_port&quot;'; } ' echo &quot;$upstream_default&quot; &gt; $nginx_upstream fi # shellcheck disable=SC2016 if [[ ${TASK} == &quot;socket&quot; ]]; then upstream=' upstream '&quot;${SERVER_PREFIX_NAME}&quot;'_upstream { server 127.0.0.1:'&quot;$reload_port&quot;'; } upstream '&quot;${SERVER_PREFIX_NAME}&quot;'_upstream_socket_io { server 127.0.0.1:'&quot;$socket_io_reload_port&quot;'; } ' else upstream=' upstream '&quot;${SERVER_PREFIX_NAME}&quot;'_upstream { server 127.0.0.1:'&quot;$reload_port&quot;'; } ' fi docker pull $DOCKER_IMAGE_URL if [[ ${TASK} == &quot;socket&quot; ]]; then echo &quot;docker run -p $reload_port:9501 -p $socket_io_reload_port:9510 --name &quot;${SERVER_PREFIX_NAME}&quot;_$reload_port_$socket_io_reload_port -dit $DOCKER_IMAGE_URL&quot; docker run -p &quot;$reload_port&quot;:9501 -p $socket_io_reload_port:9510 --name &quot;${SERVER_PREFIX_NAME}&quot;_&quot;$reload_port&quot;_&quot;$socket_io_reload_port&quot; -dit $DOCKER_IMAGE_URL docker_container_name=&quot;${SERVER_PREFIX_NAME}&quot;_&quot;$reload_port&quot;_&quot;$socket_io_reload_port&quot; old_docker_container_name=&quot;${SERVER_PREFIX_NAME}&quot;_&quot;$online_port&quot;_&quot;$socket_io_online_port&quot; else echo &quot;docker run -p $reload_port:9501 --name &quot;${SERVER_PREFIX_NAME}&quot;_$reload_port -dit $DOCKER_IMAGE_URL&quot; docker run -p &quot;$reload_port&quot;:9501 --name &quot;${SERVER_PREFIX_NAME}&quot;_&quot;$reload_port&quot; -dit $DOCKER_IMAGE_URL docker_container_name=&quot;${SERVER_PREFIX_NAME}&quot;_&quot;$reload_port&quot; old_docker_container_name=&quot;${SERVER_PREFIX_NAME}&quot;_&quot;$online_port&quot; fi echo &quot;新容器名称: &quot;$docker_container_name echo &quot;旧容器名称: &quot;$old_docker_container_name while : do reload=$(check_port &quot;$reload_port&quot;) echo &quot;check ${SERVER_PREFIX_NAME}_$reload_port 服务 reload $reload&quot; reloadCode=0 if [[ '200' == $reload ]]; then reloadCode=200 fi if [[ ${TASK} == &quot;socket&quot; ]]; then reloadCode=0 socket_io_reload=$(socket_io_check_port &quot;$socket_io_reload_port&quot;) echo &quot;check socket.io—port $socket_io_reload_port 服务 reload $socket_io_reload&quot; if [[ '200' == $reload &amp;&amp; '200' == $socket_io_reload ]]; then reloadCode=200 fi fi echo &quot;reloadCode: &quot;$reloadCode echo &quot;新容器名称: &quot;$docker_container_name echo &quot;旧容器名称: &quot;$old_docker_container_name # shellcheck disable=SC2053 if [[ '200' == $reloadCode ]]; then echo &quot;新服务重启成功 &quot;&quot;$docker_container_name&quot; echo &quot;$upstream&quot; &gt; $nginx_upstream nginx -s reload if [[ $online_port != 0 ]]; then # 无法探知老服务持有链接响应完成时间 sleep 5 echo &quot;停止旧服务 &quot;&quot;$old_docker_container_name&quot; # shellcheck disable=SC2027 docker stop &quot;$old_docker_container_name&quot; docker rm -f &quot;$old_docker_container_name&quot; fi echo &quot;清除docker无用镜像&quot; docker rmi -f $(docker images | grep &quot;&lt;none&gt;&quot; | awk &quot;{print \\$3}&quot;) break fi sleep 2 done 配置环境变量 配置完成后就可以构建部署项目了 ","link":"https://www.vincent.ac.cn/post/R7iWociC1/"},{"title":"Goal - 快速开始","content":"要求 - requirements go 1.17+ make (可选) 下载 - download git clone https://github.com/goal-web/goal &amp;&amp; cd goal 启动 - start make run # or go mod tidy &amp;&amp; go run main.go run goal 程序编译后运行方式是 ./goal run ，run 只是一个定义好的 goal cli 命令 访问 - visit curl localhost:8008 目录结构 app 应用代码 console 控制台相关代码 commands 定义命令行 kernel.go 默认 console 内核实现，可以在这里定义计划任务 dao 数据操作代码 events 事件定义 listeners 事件监听者 jobs 任务代码，用于投递到 queue http web相关代码 controllers 控制器目录 middlewares 中间件目录 requests 自定义请求目录 sse 服务端事件推送相关代码及示例 models 数据模型定义 policies gate策略定义 services 微服务相关代码 providers 一些应用内的服务提供者 app.go 一些基本的应用初始化代码 gate.go 用于注册gate策略 micro.go 用于注册微服务 websocket ws相关代码和示例 config 配置文件 app.go 应用配置 auth.go 用户认证配置 database.go 数据库配置 bloomfilter.go 布隆过滤器配置 cache.go 缓存配置 http.go http配置 mail.go 邮件配置 queue.go 队列配置 session.go 会话配置 micro.go 微服务配置 filesystem.go 文件系统配置 redis.go redis配置 serialization.go 序列化器配置(job需要在此文件配置) websocket.go ws 配置 routes 路由文件 api.go http路由 websocket.go ws 路由 sse.go 服务端事件推送路由 database 数据库相关 tests 测试代码 storage 存储目录 核心组件 鉴于部分朋友看到 goal 长长的组件列表后，认为 goal 是个重型框架，许多场景不适合使用。我认为有必要说明一下，goal 的组件搭配相当灵活，除了核心组件之外的其他组件都是可选的，包括除支持库外的所有主要组件。goal 允许你自由组装你的 goal 应用，例如 console + database 可以写一个数据库迁移应用，console + email 可以写一个邮件发送工具，http + database 可以写一个 CURD 应用，以此类推，你可以通过各种组合来完善你的应用，同时 goal 也提供了一个默认的 goal 应用模板 contracts - 契约 container - 容器 application - 应用 config - 配置 主要组件 supports - 各种支持库和工具库 pipeline - 洋葱模型管道 collection - 集合操作 hashing - 哈希库 ratelimiter - 限流器 bloomfilter - 布隆过滤器，支持文件和redis encryption - 加密库 serialization - 序列化库 console - 控制台库，支持计划任务、自定义命令 redis - redis组件 cache - 缓存 querybuilder - sql查询构造器 database - 数据库组件 auth - 用户认证 http - http服务，含路由、sse session - 会话服务 websocket - websocket库，依赖http库 queue - 消息队列，支持kafka、nsq驱动 email - 邮件 filesystem - 文件系统 events - 事件系统 micro - 微服务封装，基于 go-micro 第三方 SDK 支付宝sdk 微信sdk 阿里云sdk 极光推送 sdk 字节跳动 sdk QQ sdk 更多 SDK 。。。 ","link":"https://www.vincent.ac.cn/post/1Xnpj3nCM/"},{"title":"Goal-Web框架 用户认证（Auth）模块","content":"Goal-web/auth goal-web/auth goal 框架的用户认证组件，你可以在 http、websocket 或者其他环境使用，有上下文即可。 安装 - install go get github.com/goal-web/auth 使用 - usage goal 的脚手架自带了绝大多数开发一个 web 应用的所需要的功能和组件，当然这也包括了认证组件。一般情况下，我们只需要在 .env 修改自己的认证配置即可，比如 jwt 驱动的 secret、session 驱动的 session_key。 配置 - config 默认情况下，config/auth.go 配置文件像下面那样，默认添加了 jwt、session 两个守卫配置 package config import ( &quot;github.com/goal-web/auth&quot; &quot;github.com/goal-web/contracts&quot; &quot;github.com/goal-web/example/models&quot; &quot;github.com/golang-jwt/jwt&quot; ) func init() { configs[&quot;auth&quot;] = func(env contracts.Env) interface{} { return auth.Config{ Defaults: struct { Guard string User string }{ Guard: env.StringOption(&quot;auth.default&quot;, &quot;jwt&quot;), // 默认守卫 User: env.StringOption(&quot;auth.user&quot;, &quot;db&quot;), // 默认用户提供者 }, Guards: map[string]contracts.Fields{ &quot;jwt&quot;: { // 守卫名称 &quot;driver&quot;: &quot;jwt&quot;, // 驱动,目前支持jwt、session &quot;secret&quot;: env.GetString(&quot;auth.jwt.secret&quot;), // jwt 签名所需的 secret，不同的守卫建议不同的secret &quot;method&quot;: jwt.SigningMethodHS256, // jwt 签名方法 &quot;lifetime&quot;: 60 * 60 * 24, // token有效时长，单位：秒 &quot;provider&quot;: &quot;db&quot;, // 用户提供者名 }, &quot;session&quot;: { // 守卫名称 &quot;driver&quot;: &quot;session&quot;, // 驱动名 &quot;provider&quot;: &quot;db&quot;, // 用户提供者名 // session驱动所需的参数，如果应用需要配置多个session驱动的守卫，那么需要配置不一样的 session_key &quot;session_key&quot;: env.StringOption(&quot;auth.session.key&quot;, &quot;auth_session&quot;), }, }, Users: map[string]contracts.Fields{ // 用户提供者，目前只支持 db &quot;db&quot;: { // 用户提供者名称 &quot;driver&quot;: &quot;db&quot;, // 驱动名称 &quot;model&quot;: models.UserModel, // 用户模型 }, }, } } } .env 的数据库相关配置 # 默认连接 auth.jwt.secret=jwt_secret auth.default=jwt 定义模型 - define a model app/models/user.go 文件 package models import ( &quot;github.com/goal-web/database/table&quot; &quot;github.com/goal-web/supports/class&quot; ) var ( UserModel = table.NewModel(class.Make(new(User)), &quot;users&quot;) ) func UserQuery() *table.Table { return table.FromModel(UserModel) } type User struct { Id string `json:&quot;id&quot;` NickName string `json:&quot;name&quot;` } // GetId 实现了 contracts.Authenticatable 接口，此方法必不可少 func (u User) GetId() string { return u.Id } 用法 - method of use package controllers import ( &quot;github.com/goal-web/contracts&quot; &quot;github.com/goal-web/example/models&quot; ) func LoginExample(guard contracts.Guard) contracts.Fields { // 这是伪代码 user := models.UserQuery().First().(models.User) return contracts.Fields{ &quot;token&quot;: guard.Login(user), // jwt 返回 token，session 返回 true } } func GetCurrentUser(guard contracts.Guard) interface{} { return contracts.Fields{ &quot;user&quot;: guard.User(), // 已登录返回用户模型，否则返回 nil } } 使用中间件 package routes import ( &quot;github.com/goal-web/auth&quot; &quot;github.com/goal-web/contracts&quot; &quot;github.com/goal-web/example/app/http/controllers&quot; &quot;github.com/goal-web/session&quot; ) func ApiRoutes(router contracts.Router) { v1 := router.Group(&quot;&quot;, session.StartSession) // 直接应用在路由上 v1.Get(&quot;/myself&quot;, controllers.GetCurrentUser, auth.Guard(&quot;jwt&quot;)) // 应用在路由组上 authRouter := v1.Group(&quot;&quot;, auth.Guard(&quot;jwt&quot;)) authRouter.Get(&quot;/myself&quot;, controllers.GetCurrentUser, auth.Guard(&quot;jwt&quot;)) } 守卫 API - guard api type Guard interface { Once(user Authenticatable) User() Authenticatable GetId() string Check() bool Guest() bool Login(user Authenticatable) interface{} } ","link":"https://www.vincent.ac.cn/post/KiNHX9G7r/"},{"title":"Goal-Web框架 洋葱模型的管道实现，你还在愁 go 没有好用的中间件吗？","content":"Goal-web/pipeline goal-web/pipeline 这是一个管道库，实现了 和 laravel 一样的管道功能，如果你很熟悉 laravel 的管道或者中间件，那你一定对这个库很有亲切感。 安装 - install go get github.com/goal-web/pipeline 使用 - usage 得益于 goal 强大的容器，你可以在管道 (pipe) 和目的地 (destination) 任意注入容器中存在的实例 对管道不熟悉的同学，可以把 pipe 理解为中间件，destination 就是控制器方法 package tests import ( &quot;fmt&quot; &quot;github.com/goal-web/container&quot; &quot;github.com/goal-web/contracts&quot; &quot;github.com/goal-web/pipeline&quot; &quot;github.com/pkg/errors&quot; &quot;testing&quot; ) type User struct { Id int Name string } func TestPipeline(t *testing.T) { pipe := pipeline.New(container.New()) pipe.Send(User{Id: 1, Name: &quot;goal&quot;}). Through( func(user User, next pipeline.Pipe) interface{} { fmt.Println(&quot;中间件1-start&quot;) result := next(user) fmt.Println(&quot;中间件1-end&quot;) return result }, func(user User, next pipeline.Pipe) interface{} { fmt.Println(&quot;中间件2-start&quot;) result := next(user) fmt.Println(&quot;中间件2-end&quot;) return result }, ). Then(func(user User) { fmt.Println(&quot;then&quot;, user) }) } // TestPipelineException 测试异常情况 func TestPipelineException(t *testing.T) { defer func() { recover() }() pipe := pipeline.New(container.New()) pipe.Send(User{Id: 1, Name: &quot;goal&quot;}). Through( func(user User, next pipeline.Pipe) interface{} { fmt.Println(&quot;中间件1-start&quot;) result := next(user) fmt.Println(&quot;中间件1-end&quot;, result) return result }, func(user User, next pipeline.Pipe) interface{} { fmt.Println(&quot;中间件2-start&quot;) result := next(user) fmt.Println(&quot;中间件2-end&quot;, result) return result }, ). Then(func(user User) { panic(errors.New(&quot;报个错&quot;)) }) } // TestStaticPipeline 测试调用magical函数 func TestStaticPipeline(t *testing.T) { // 应用启动时就准备好的中间件和控制器函数，在大量并发时用 StaticPipeline 可以提高性能 middlewares := []contracts.MagicalFunc{ container.NewMagicalFunc(func(user User, next pipeline.Pipe) interface{} { fmt.Println(&quot;中间件1-start&quot;) result := next(user) fmt.Println(&quot;中间件1-end&quot;, result) return result }), container.NewMagicalFunc(func(user User, next pipeline.Pipe) interface{} { fmt.Println(&quot;中间件2-start&quot;) result := next(user) fmt.Println(&quot;中间件2-end&quot;, result) return result }), } controller := container.NewMagicalFunc(func(user User) int { fmt.Println(&quot;then&quot;, user) return user.Id }) pipe := pipeline.Static(container.New()) result := pipe.SendStatic(User{Id: 1, Name: &quot;goal&quot;}). ThroughStatic(middlewares...). ThenStatic(controller) fmt.Println(&quot;穿梭结果&quot;, result) /** 中间件1-start 中间件2-start then {1 goal} 中间件2-end [1] 中间件1-end [1] 穿梭结果 [1] */ } // TestPurePipeline 测试纯净的 pipeline func TestPurePipeline(t *testing.T) { // 如果你的应用场景对性能要求极高，不希望反射影响你，那么你可以试试下面这个纯净的管道 pipe := pipeline.Pure() result := pipe.SendPure(User{Id: 1, Name: &quot;goal&quot;}). ThroughPure( func(user interface{}, next pipeline.Pipe) interface{} { fmt.Println(&quot;中间件1-start&quot;) result := next(user) fmt.Println(&quot;中间件1-end&quot;, result) return result }, func(user interface{}, next pipeline.Pipe) interface{} { fmt.Println(&quot;中间件2-start&quot;) result := next(user) fmt.Println(&quot;中间件2-end&quot;, result) return result }, ). ThenPure(func(user interface{}) interface{} { fmt.Println(&quot;then&quot;, user) return user.(User).Id }) fmt.Println(&quot;穿梭结果&quot;, result) /** 中间件1-start 中间件2-start then {1 goal} 中间件2-end 1 中间件1-end 1 穿梭结果 1 */ } 在 goal 之外的框架使用 - use in frameworks other than goal 这个库并不会限制你在哪个框架使用它，所以你可以在任意 go 环境使用这个管道库 ","link":"https://www.vincent.ac.cn/post/4F-DbyJRx/"},{"title":"Goal-Web框架 数据库组件","content":"Goal-web/collection goal-web/database goal 框架的数据库组件，当然你也可以在 goal 之外的框架使用他。 目前数据库组件暂时不能使用关联关系，你可以用 WhereExists 来代替 安装 - install go get github.com/goal-web/database 使用 - usage goal 的脚手架自带了绝大多数开发一个 web 应用的所需要的功能和组件，当然包括了数据库组件。一般情况下，我们只需要在 .env 修改自己的数据库配置即可，添加数据库连接可以 config/database.go 修改 Connections 属性。 配置 - config 默认情况下，config/database.go 配置文件像下面那样，默认添加了 sqlite、MySQL、postgresSql 三个数据库连接的配置 和 Laravel 不同的是，goal 把 redis 配置独立出去了，因为 redis 也是一个独立的模块，不想让 redis 依赖 database package config import ( &quot;github.com/goal-web/contracts&quot; &quot;github.com/goal-web/database&quot; ) func init() { configs[&quot;database&quot;] = func(env contracts.Env) interface{} { return database.Config{ Default: env.StringOption(&quot;db.connection&quot;, &quot;mysql&quot;), Connections: map[string]contracts.Fields{ &quot;sqlite&quot;: { &quot;driver&quot;: &quot;sqlite&quot;, &quot;database&quot;: env.GetString(&quot;sqlite.database&quot;), }, &quot;mysql&quot;: { &quot;driver&quot;: &quot;mysql&quot;, &quot;host&quot;: env.GetString(&quot;db.host&quot;), &quot;port&quot;: env.GetString(&quot;db.port&quot;), &quot;database&quot;: env.GetString(&quot;db.database&quot;), &quot;username&quot;: env.GetString(&quot;db.username&quot;), &quot;password&quot;: env.GetString(&quot;db.password&quot;), &quot;unix_socket&quot;: env.GetString(&quot;db.unix_socket&quot;), &quot;charset&quot;: env.StringOption(&quot;db.charset&quot;, &quot;utf8mb4&quot;), &quot;collation&quot;: env.StringOption(&quot;db.collation&quot;, &quot;utf8mb4_unicode_ci&quot;), &quot;prefix&quot;: env.GetString(&quot;db.prefix&quot;), &quot;strict&quot;: env.GetBool(&quot;db.struct&quot;), &quot;max_connections&quot;: env.GetInt(&quot;db.max_connections&quot;), &quot;max_idles&quot;: env.GetInt(&quot;db.max_idles&quot;), }, &quot;pgsql&quot;: { &quot;driver&quot;: &quot;postgres&quot;, &quot;host&quot;: env.GetString(&quot;db.pgsql.host&quot;), &quot;port&quot;: env.GetString(&quot;db.pgsql.port&quot;), &quot;database&quot;: env.GetString(&quot;db.pgsql.database&quot;), &quot;username&quot;: env.GetString(&quot;db.pgsql.username&quot;), &quot;password&quot;: env.GetString(&quot;db.pgsql.password&quot;), &quot;charset&quot;: env.StringOption(&quot;db.pgsql.charset&quot;, &quot;utf8mb4&quot;), &quot;prefix&quot;: env.GetString(&quot;db.pgsql.prefix&quot;), &quot;schema&quot;: env.StringOption(&quot;db.pgsql.schema&quot;, &quot;public&quot;), &quot;sslmode&quot;: env.StringOption(&quot;db.pgsql.sslmode&quot;, &quot;disable&quot;), &quot;max_connections&quot;: env.GetInt(&quot;db.pgsql.max_connections&quot;), &quot;max_idles&quot;: env.GetInt(&quot;db.pgsql.max_idles&quot;), }, }, } } } .env 的数据库相关配置 # 默认连接 db.connection=sqlite sqlite.database=/Users/qbhy/project/go/goal-web/goal/example/database/db.sqlite db.host=localhost db.port=3306 db.database=goal db.username=root db.password=password db.pgsql.host=localhost db.pgsql.port=55433 db.pgsql.database=postgres db.pgsql.username=postgres db.pgsql.password=123456 定义模型 - define a model app/models/user.go 文件 package models import ( &quot;github.com/goal-web/database/table&quot; &quot;github.com/goal-web/supports/class&quot; ) // UserClass 这个类变量，以后大有用处 var UserClass = class.Make(new(User)) // UserModel 返回 table 实例，继承自查询构造器并且实现了所有 future func UserModel() *table.Table { return table.Model(UserClass, &quot;users&quot;) } // User 模型结构体 type User struct { Id int64 `json:&quot;id&quot;` NickName string `json:&quot;name&quot;` } 用法 - method of use package tests import ( &quot;fmt&quot; &quot;github.com/goal-web/contracts&quot; &quot;github.com/goal-web/database/table&quot; &quot;github.com/goal-web/example/models&quot; &quot;github.com/stretchr/testify/assert&quot; &quot;testing&quot; ) func getQuery(name string) contracts.QueryBuilder { // 测试用例环境下的简易 goal 应用启动 app := initApp(&quot;/Users/qbhy/project/go/goal-web/goal/tests&quot;) //return table.Query(&quot;users&quot;) 返回 table 实例，使用默认连接 //tx, _ := app.Get(&quot;db&quot;).(contracts.DBConnection).Begin() //return table.WithTX(&quot;users&quot;, tx) // 事物环境下执行 //return table.WithConnection(name, &quot;sqlite&quot;) // 返回指定连接的 table 实例，使用连接名 return table.WithConnection(name, app.Get(&quot;db&quot;).(contracts.DBConnection)) // 也可以指定连接实例 } // TestTableQuery 测试不带模型的 table 查询，类似 laravel 的 DB::table() func TestTableQuery(t *testing.T) { getQuery(&quot;users&quot;).Delete() // 不设置模型的情况下，返回 contracts.Fields user := getQuery(&quot;users&quot;).Create(contracts.Fields{ &quot;name&quot;: &quot;qbhy&quot;, }).(contracts.Fields) fmt.Println(user) userId := user[&quot;id&quot;].(int64) // 判断插入是否成功 assert.True(t, userId &gt; 0) // 获取数据总量 assert.True(t, getQuery(&quot;users&quot;).Count() == 1) // 修改数据 num := getQuery(&quot;users&quot;).Where(&quot;name&quot;, &quot;qbhy&quot;).Update(contracts.Fields{ &quot;name&quot;: &quot;goal&quot;, }) assert.True(t, num == 1) // 判断修改后的数据 user = getQuery(&quot;users&quot;).Where(&quot;name&quot;, &quot;goal&quot;).First().(contracts.Fields) err := getQuery(&quot;users&quot;).Chunk(10, func(collection contracts.Collection, page int) error { assert.True(t, collection.Len() == 1) fmt.Println(collection.ToJson()) return nil }) assert.Nil(t, err) assert.True(t, user[&quot;id&quot;] == userId) assert.True(t, user[&quot;name&quot;] == &quot;goal&quot;) assert.True(t, getQuery(&quot;users&quot;).Find(userId).(contracts.Fields)[&quot;id&quot;] == userId) assert.True(t, getQuery(&quot;users&quot;).Where(&quot;id&quot;, userId).Delete() == 1) assert.Nil(t, getQuery(&quot;users&quot;).Find(userId)) } func TestModel(t *testing.T) { initApp(&quot;/Users/qbhy/project/go/goal-web/goal/tests&quot;) fmt.Println(&quot;用table查询：&quot;, getQuery(&quot;users&quot;).Get().Map(func(user contracts.Fields) { fmt.Println(&quot;用table查询&quot;, user) }).ToJson()) // query 返回 Collection&lt;contracts.Fields&gt; user := models.UserModel().Create(contracts.Fields{ &quot;name&quot;: &quot;qbhy&quot;, }).(models.User) fmt.Println(&quot;创建后返回模型&quot;, user) fmt.Println(&quot;用table查询：&quot;, getQuery(&quot;users&quot;).Get().Map(func(user contracts.Fields) { fmt.Println(&quot;用table查询&quot;, user) }).ToJson()) // query 返回 Collection&lt;contracts.Fields&gt; // 用模型查询 fmt.Println(models.UserModel(). // model 返回 Collection&lt;models.User&gt; Get(). Map(func(user models.User) { fmt.Println(&quot;id:&quot;, user.Id) }).ToJson()) fmt.Println(models.UserModel().Where(&quot;id&quot;, &quot;&gt;&quot;, 0).Delete()) } 更多查询构造器用法请移步 goal-web/querybuilder ","link":"https://www.vincent.ac.cn/post/harkE6PNG/"},{"title":"docker运行hyperf 出现  Access denied for user 'root'@'172.16.10.3' (using password: YES)报错","content":"今天新开发的项目部署到测试环境后发现 hyperf 在操作数据库的时候出现了一下报错 Access denied for user 'root'@'172.16.10.3' (using password: YES) 原因 刚开始以为是root账号的密码错了，在仔细比对重启后发现不是密码错误的问题！查阅了一下资料发现是因为root默认是限制本地登录，而我是在docker容器里访问宿主机的mysql 所以不属于本地登录，访问就被拒绝了 解决办法 给账号开放指定ip网段访问 在本地通过命令进入mysql mysql -u root -p 打开mysql库 use mysql; 创建用户 mysql8.0以前的版本可以使用grant在授权的时候隐式的创建用户，8.0以后已经不支持，所以必须先创建用户，然后再授权 CREATE USER '用户名'@'172.16.10.%' IDENTIFIED BY '密码'; 设置权限 grant all PRIVILEGES on 数据库名.数据库表 to '用户名'@'172.16.10.%'; 刷新权限 flush privileges; ","link":"https://www.vincent.ac.cn/post/LGhYKiytt/"},{"title":"Goal-Web框架 collection 库","content":"Goal-web/collection 这是一个神奇的仓库 goal-web/collection 安装 - install go get github.com/goal-web/collection 使用 package tests import ( &quot;errors&quot; &quot;fmt&quot; &quot;github.com/goal-web/collection&quot; &quot;github.com/goal-web/contracts&quot; &quot;github.com/shopspring/decimal&quot; &quot;github.com/stretchr/testify/assert&quot; &quot;testing&quot; ) func TestNew(t *testing.T) { collect, err := collection.New(1) assert.Nil(t, collect) assert.Error(t, err, err) // 使用 MustNew 的时候，如果参数不是 array 或者 slice 的话，将会 panic collect, err = collection.New([]int{1}) assert.NotNil(t, collect) assert.Nil(t, err) } func TestArray(t *testing.T) { intCollection := collection.MustNew([]interface{}{ 1, 2, 3, true, &quot;字符串&quot;, &quot;true&quot;, }) fmt.Println(intCollection.ToFloat64Array()) assert.True(t, intCollection.Len() == 6) // 第二个参数是数据索引 intCollection.Map(func(data, index int) { fmt.Println(fmt.Sprintf(&quot;第 %d 个，值：%d&quot;, index, data)) }) // 第三个参数是所有数据集合 intCollection.Map(func(data, index int, allData []interface{}) { if index == 0 { fmt.Println(&quot;allData&quot;, allData) } fmt.Println(fmt.Sprintf(&quot;第 %d 个，值：%d&quot;, index, data)) }) // 甚至可以直接转换成你想要的类型 intCollection.Map(func(data string, index int) { fmt.Println(fmt.Sprintf(&quot;第 %d 个，值：%s&quot;, index, data)) }) intCollection.Map(func(data bool, index int) { fmt.Println(fmt.Sprintf(&quot;第 %d 个，值：%v&quot;, index, data)) }) // 不返回任何值表示只遍历 intCollection.Map(func(data int) { fmt.Println(&quot;只遍历: &quot;, data) }) fmt.Println(intCollection.ToIntArray()) // 返回一个值会生成一个新的 collection fmt.Println(intCollection.Map(func(data int) int { if data &gt; 0 { return 1 } return 0 }).ToIntArray()) } type User struct { id int Name string Money float64 } func TestStructArray(t *testing.T) { users := collection.MustNew([]User{ {id: 1, Name: &quot;qbhy&quot;}, {id: 2, Name: &quot;goal&quot;}, }) users.Map(func(user User) { fmt.Printf(&quot;user: id:%d Name:%s \\n&quot;, user.id, user.Name) }) // 使用 fields 接收的时候，未导出字段默认是 nil users.Map(func(user contracts.Fields) { fmt.Printf(&quot;user: id:%v Name:%s \\n&quot;, user[&quot;id&quot;], user[&quot;name&quot;]) }) // 使用 map 修改数据后在用 where 筛选 assert.True(t, users.Map(func(user User) User { if user.id == 1 { user.Money = 100 } return user }).Where(&quot;money&quot;, 100).Len() == 1) } func TestFilterArray(t *testing.T) { users := collection.MustNew([]User{ {id: 1, Name: &quot;qbhy&quot;, Money: 10000000}, {id: 2, Name: &quot;goal&quot;, Money: 10}, }) fmt.Println(&quot;第一个数据&quot;, users.ToInterfaceArray()[0]) richUsers := users.Filter(func(user User) bool { return user.Money &gt; 100 }) assert.True(t, richUsers.Len() == 1) fmt.Println(richUsers.ToInterfaceArray()) poorUsers := users.Skip(func(user User) bool { return user.Money &gt; 100 }) assert.True(t, poorUsers.Len() == 1) fmt.Println(poorUsers.ToInterfaceArray()) qbhyUsers := users.Where(&quot;name&quot;, &quot;qbhy&quot;) assert.True(t, qbhyUsers.Len() == 1) fmt.Println(qbhyUsers.ToInterfaceArray()) assert.True(t, users.WhereLte(&quot;money&quot;, 50).Len() == 1) assert.True(t, users.Where(&quot;money&quot;, &quot;&lt;=&quot;, 50).Len() == 1) } // TestAggregateArray 聚合函数测试 func TestAggregateArray(t *testing.T) { users := collection.MustNew([]User{ {id: 1, Name: &quot;qbhy&quot;, Money: 10000000000000000}, {id: 2, Name: &quot;goal&quot;, Money: 10000000000000000}, {id: 3, Name: &quot;collection&quot;, Money: 0.645624123}, }).(*collection.Collection) // SafeSum、SafeAvg、SafeMax、SafeMin 等方法需要 *collection.Collection 类型 fmt.Println(&quot;Sum&quot;, users.SafeSum(&quot;money&quot;)) fmt.Println(&quot;Avg&quot;, users.SafeAvg(&quot;money&quot;)) fmt.Println(&quot;Max&quot;, users.SafeMax(&quot;money&quot;)) fmt.Println(&quot;Min&quot;, users.SafeMin(&quot;money&quot;)) sum, _ := decimal.NewFromString(&quot;20000000000000000.645624123&quot;) avg, _ := decimal.NewFromString(&quot;6666666666666666.8818747076666667&quot;) max, _ := decimal.NewFromString(&quot;10000000000000000&quot;) min, _ := decimal.NewFromString(&quot;0.645624123&quot;) assert.True(t, users.SafeSum(&quot;money&quot;).Equal(sum)) assert.True(t, users.SafeAvg(&quot;money&quot;).Equal(avg)) assert.True(t, users.SafeMax(&quot;money&quot;).Equal(max)) assert.True(t, users.SafeMin(&quot;money&quot;).Equal(min)) users = collection.MustNew([]User{ {id: 1, Name: &quot;qbhy&quot;, Money: 1}, {id: 2, Name: &quot;goal&quot;, Money: 2}, {id: 3, Name: &quot;collection&quot;, Money: 0}, }).(*collection.Collection) assert.True(t, users.Sum(&quot;money&quot;) == 3) assert.True(t, users.Avg(&quot;money&quot;) == 1) assert.True(t, users.Max(&quot;money&quot;) == 2) assert.True(t, users.Min(&quot;money&quot;) == 0) assert.True(t, users.Count() == 3) } // TestSortArray 测试排序功能 func TestSortArray(t *testing.T) { users := collection.MustNew([]User{ {id: 1, Name: &quot;qbhy&quot;, Money: 12}, {id: 2, Name: &quot;goal&quot;, Money: 1}, {id: 2, Name: &quot;goal&quot;, Money: 15}, {id: 2, Name: &quot;goal99&quot;, Money: 99}, {id: 3, Name: &quot;collection&quot;, Money: -5}, {id: 3, Name: &quot;移动&quot;, Money: 10086}, }) fmt.Println(users.ToInterfaceArray()) // 暂不支持转成 contracts.Fields usersOrderByMoneyDesc := users.Sort(func(user User, next User) bool { return user.Money &gt; next.Money }) fmt.Println(usersOrderByMoneyDesc.ToInterfaceArray()) assert.True(t, usersOrderByMoneyDesc.ToInterfaceArray()[0].(User).Money == 10086) usersOrderByMoneyAsc := users.Sort(func(user User, next User) bool { return user.Money &lt; next.Money }) fmt.Println(usersOrderByMoneyAsc.ToInterfaceArray()) assert.True(t, usersOrderByMoneyAsc.ToInterfaceArray()[0].(User).Money == -5) numbers := collection.MustNew([]interface{}{ 8, 0, 1, 2, 0.6, 4, 5, 6, -0.2, 7, 9, 3, &quot;10086&quot;, }) sortedNumbers := numbers.Sort(func(i, j float64) bool { return i &gt; j }).ToFloat64Array() fmt.Println(sortedNumbers) assert.True(t, sortedNumbers[0] == 10086) } // TestCombine 测试组合集合功能 func TestCombine(t *testing.T) { users := collection.MustNew([]User{ {id: 1, Name: &quot;qbhy&quot;, Money: 12}, }) users = users.Push(User{id: 2, Name: &quot;goal&quot;, Money: 1000}) //users = users.Prepend(User{id: 2, Name: &quot;goal&quot;, Money: 1000}) // 插入到开头 assert.True(t, users.Len() == 2) fmt.Println(users.ToInterfaceArray()) others := collection.MustNew([]User{ {id: 3, Name: &quot;马云&quot;, Money: 100000000}, }) all := others.Merge(users).Sort(func(pre User, next User) bool { return pre.Money &gt; next.Money }) assert.True(t, all.Len() == 3) fmt.Println(all.ToInterfaceArray()) fmt.Println(all.Only(&quot;money&quot;, &quot;name&quot;).ToArrayFields()) assert.True(t, all.First(&quot;name&quot;) == &quot;马云&quot;) // 最有钱还是马云 normalUsers := all.Where(&quot;money&quot;, &quot;&gt;&quot;, 100) assert.True(t, normalUsers.Len() == 2) // 两个普通人 assert.True(t, normalUsers.Last(&quot;name&quot;) == &quot;goal&quot;) // 筛选不影响排序，跟马云比还差了点 assert.False(t, normalUsers.IsEmpty()) // 有普通人 assert.True(t, normalUsers.Where(&quot;money&quot;, &quot;&lt;&quot;, 0).IsEmpty()) // 普通人都没有负债 randomUsers := all.Random(2) // 随机获取两个数据 assert.True(t, randomUsers.Len() == 2) fmt.Println(randomUsers.ToInterfaceArray()) assert.True(t, all.Pull().(User).Name == &quot;qbhy&quot;) // 从末尾取走一个 assert.True(t, all.Len() == 2) // 判断取走后的长度 assert.True(t, all.Shift().(User).Name == &quot;马云&quot;) // 从开头取走一个 assert.True(t, all.Len() == 1) // 判断取走后的长度 } func TestChunk(t *testing.T) { collect := collection.MustNew([]int{ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, }) err := collect.Chunk(5, func(collection contracts.Collection, page int) error { fmt.Printf(&quot;页码：%d，数量：%d %v\\n&quot;, page, collection.Len(), collection.ToInterfaceArray()) switch page { case 4: assert.True(t, collection.Len() == 4) default: assert.True(t, collection.Len() == 5) } return nil }) assert.Nil(t, err) err = collection.MustNew([]User{ {id: 1, Name: &quot;qbhy&quot;, Money: 12}, {id: 2, Name: &quot;goal&quot;, Money: 1}, {id: 2, Name: &quot;goal&quot;, Money: 15}, {id: 2, Name: &quot;goal99&quot;, Money: 99}, {id: 3, Name: &quot;collection&quot;, Money: -5}, {id: 3, Name: &quot;移动&quot;, Money: 10086}, }).Chunk(3, func(collection contracts.Collection, page int) error { assert.True(t, page == 1) assert.True(t, collection.First(&quot;name&quot;) == &quot;qbhy&quot;) assert.True(t, collection.Last(&quot;name&quot;) == &quot;goal&quot;) return errors.New(&quot;第一页退出&quot;) }) assert.Error(t, err) } ","link":"https://www.vincent.ac.cn/post/6tEe2m3il/"},{"title":"Goal-Web框架 QueryBuilder组件","content":"Goal/QueryBuilder 一个像 Laravel 那样好用的 go 语言的 SQL 查询构造器 Goal 的数据库查询构造器为创建和运行数据库查询提供了一个方便的接口。它可以用于支持大部分数据库操作，并与 Goal 支持的所有数据库系统完美运行。并且大量参考了Laravel 的查询构造器设计，你几乎可以在这个库找到所有与 Laravel 对应的方法。 Goal 的查询构造器实现了类似 PDO 参数绑定的形式，来保护您的应用程序免受 SQL 注入攻击。因此不必清理因参数绑定而传入的字符串。查询构造器会返回你想要的 SQL 语句以及绑定参数。 安装 go get github.com/goal-web/querybuilder 运行数据库查询 根据条件从表中检索出数据 你可以使用 NewQuery 方法来开始查询。该方法为给定的表返回一个查询构造器实例，允许你在查询上链式调用更多的约束，最后使用 get 方法获取结果： package querybuilder import ( &quot;fmt&quot; ) func TestSimpleQueryBuilder() { query := NewQuery(&quot;users&quot;). Where(&quot;name&quot;, &quot;qbhy&quot;). Where(&quot;age&quot;, &quot;&gt;&quot;, 18). Where(&quot;gender&quot;, &quot;!=&quot;, 0). OrWhere(&quot;amount&quot;, &quot;&gt;=&quot;, 100). WhereIsNull(&quot;avatar&quot;) fmt.Println(query.ToSql()) fmt.Println(query.GetBindings()) // select * from users where name = ? and age &gt; ? and gender != ? and avatar is null or amount &gt;= ? // [qbhy 18 0 100] } 你也可以通过 SelectSql 方法一次性获取你想要的参数。 例如：sql, bindings := NewQuery (“users”).Where (“gender”, 1).SelectSql () 插入语句 你可以通过 InsertSql 或者 CreateSql 很方便的生成插入语句。 package querybuilder import ( &quot;fmt&quot; &quot;github.com/goal-web/contracts&quot; ) // TestInsertSql 批量插入数据 func TestInsertSql() { sql, bindings := NewQuery(&quot;users&quot;).InsertSql([]contracts.Fields{ {&quot;name&quot;: &quot;qbhy&quot;, &quot;age&quot;: 18, &quot;money&quot;: 100000000000}, {&quot;name&quot;: &quot;goal&quot;, &quot;age&quot;: 18, &quot;money&quot;: 10}, }) fmt.Println(sql) fmt.Println(bindings) // insert into users (name,age,money) values (?,?,?),(?,?,?) // [qbhy 18 100000000000 goal 18 10] } // TestCreateSql 插入单个数据 func TestCreateSql() { sql, bindings := NewQuery(&quot;users&quot;).CreateSql(contracts.Fields{ &quot;name&quot;: &quot;qbhy&quot;, &quot;age&quot;: 18, &quot;money&quot;: 100000000000, }) fmt.Println(sql) fmt.Println(bindings) // insert into users (name,age,money) values (?,?,?) //[qbhy 18 100000000000] } 更新语句 你可以通过 UpdateSql 很方便的生成更新语句。 package querybuilder import ( &quot;fmt&quot; &quot;github.com/goal-web/contracts&quot; ) func TestUpdateSql() { sql, bindings := NewQuery(&quot;users&quot;).Where(&quot;id&quot;, &quot;&gt;&quot;, 1).UpdateSql(contracts.Fields{ &quot;name&quot;: &quot;qbhy&quot;, &quot;age&quot;: 18, &quot;money&quot;: 100000000000, }) fmt.Println(sql) fmt.Println(bindings) // update users set name = ?,age = ?,money = ? where id &gt; ? // [qbhy 18 100000000000 1] } 删除语句 你可以通过 DeleteSql 很方便的生成删除语句。 package querybuilder import ( &quot;fmt&quot; ) func TestDeleteSql() { sql, bindings := NewQuery(&quot;users&quot;).Where(&quot;id&quot;, &quot;&gt;&quot;, 1).DeleteSql() fmt.Println(sql) fmt.Println(bindings) // delete from users where id &gt; ? // [1] } 更多高级用法 正如开头所说，你可以在这里找到几乎所有与 Laravel 对应的查询构造器方法，也可以在 测试文件 中找到更多用法 彩蛋 ？ 正在开发一个像 laravel 那样的 Go web 开发框架，并且现在已经完成了大部分主要功能，如果你感兴趣的话，欢迎 star 持续跟踪最新动态 goal 传送门 goal/query-builder ","link":"https://www.vincent.ac.cn/post/ngpbCpPO-/"},{"title":"Linux  RabbitMQ 安装与配置","content":"在Linux上安装RabbitMQ需要先安装它对应的运行环境Erlang，我这里使用的是CentOS7 安装Erlang 准备工作，安装wget yum install -y wget 安装依赖项 yum install -y epel-release 配置安装源 wget https://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpm 导入rpm rpm -Uvh erlang-solutions-1.0-1.noarch.rpm 安装 yum install -y erlang 验证是否安装成功 erl -version 出现如下提示，证明成功了 安装RabbitMQ 配置安装源 wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.9.12/rabbitmq-server-3.9.12-1.el7.noarch.rpm 导入Key rpm --import https://www.rabbitmq.com/rabbitmq-signing-key-public.asc 安装 yum install rabbitmq-server-3.9.12-1.el7.noarch.rpm 当安装完成后，你可以使用命令来启动 rabbitmq 服务器 systemctl start rabbitmq-server RabbitMQ 设置自动启动 systemctl enable rabbitmq-server systemctl status rabbitmq-server #查看rabbitMQ运行情况 RabbitMQ 启用 Web 管理界面 安装 Web 管理界面的插件 rabbitmq-plugins enable rabbitmq_management 开放端口 iptables -I INPUT -p tcp --dport 5672 -j ACCEPT iptables -I INPUT -p tcp --dport 15672 -j ACCEPT 分别执行下面的命令 rabbitmqctl add_user admin 123456 #创建admin用户 密码为123456 rabbitmqctl set_user_tags admin administrator #针对这个用户进行赋权 rabbitmqctl set_permissions -p / admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; # systemctl restart rabbitmq-server #重启rabbitmq 当上面命令执行成功后，你可以重启你的 RabbitMQ，然后通过浏览器进行登录。UI 界面使用的端口是 15672。因此访问的 URL 为你服务器的地址 + 15672。 注意防火墙需要开放 15762端口才可正常访问 延时队列 AMQP 的延时队列，并不会根据延时时间进行排序，所以，一旦你投递了一个延时 10s 的任务，又往这个队列中投递了一个延时 5s 的任务，那么也一定会在第一个 10s 任务完成后，才会消费第二个 5s 的任务。 所以，需要根据时间设置不同的队列，如果想要更加灵活的延时队列 AMQP 需要下载 延时插件，并激活才能正常使用 wget https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/releases/download/3.9.0/rabbitmq_delayed_message_exchange-3.9.0.ez cp rabbitmq_delayed_message_exchange-3.9.0.ez /opt/rabbitmq/plugins/ rabbitmq-plugins enable rabbitmq_delayed_message_exchange ","link":"https://www.vincent.ac.cn/post/rZ7udBP47/"},{"title":"初学 Spring Boot 注解类 @FieldSame 优化","content":"多注解（List）测试与坑 ","link":"https://www.vincent.ac.cn/post/ZlxZ8D1K-/"},{"title":"初学 Spring Boot 使用hibernate validation 对参数校验","content":" Hibernate Validator是Java Validation API(JSR 303)标准的一个具体实现，用于对参数进行合法性校验。校验数据在任何应用中都是一个很常见的任务，所以JCP组织定义了一个标准来规范化这个任务操作，那就是Java Validation API。 在不使用Java Validation API之前，做校验时有人是这样写的： @Controller @RequestMapping(&quot;/order&quot;) public class OrderController { @ResponseBody @RequestMapping(value = &quot;/getOrderDetails&quot;, method = RequestMethod.POST) public OrderDetailsVo getOrderDetails(@RequestBody JSONObject json) { String token = json.optString(&quot;token&quot;); Assert.hasLength(token,1101,&quot;非法请求参数&quot;); String orderCode = json.optString(&quot;orderCode&quot;); Assert.hasLength(orderCode,1101,&quot;非法请求参数&quot;); // ....... } } 这种写法我认为有三个弊端： 用JSONObject来接收入参，取值非常麻烦，很容易就弄错字段名 如果入参非常复杂，用JSONObject的话，下一个接手的人就很难搞错清整个方法入参的JSON结构，可维护性极差 方法里校验逻辑啰嗦重复 下面我们来使用Java Validation API 实现简单的验证 在默认情况下，Spring Boot会引入Hibernate Validator机制来支持JSR-303验证规范。 特性 Spring Boot的validator校验框架有3个特性： JSR-303特性： JSR-303是一项标准,只提供规范不提供实现，规定一些校验规范即校验注解，如@Null，@NotNull，@Pattern，位于javax.validation.constraints包下。 hibernate validation特性：hibernate validation是对JSR-303规范的实现，并增加了一些其他校验注解，如@Email，@Length，@Range等等。 Spring validation：spring validation对hibernate validation进行了二次封装，在springmvc模块中添加了自动校验，并将校验信息封装进了特定的类中。 引入依赖 只需要spring-boot-starter-validation和web即可 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- validation --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt; &lt;/dependency&gt; 创建一个注册用的DTO对象 package com.example.blog.request; import lombok.Data; import org.hibernate.validator.constraints.Length; import javax.validation.constraints.Email; import javax.validation.constraints.NotNull; /** * @author vincent */ @Data public class UserCreateRequest { @NotNull(message = &quot;登录用户名不能为空&quot;) @Length(max = 10, message = &quot;登录用户名最长为10位&quot;) private String username; @NotNull(message = &quot;登录密码不能为空&quot;) @Length(min=6, max = 16,message=&quot;密码长度不能小于6位&quot;) private String password; @NotNull(message = &quot;确认登录密码不能为空&quot;) @Length(min=6, max = 16,message=&quot;密码长度不能小于6位&quot;) private String password2; @Email(message=&quot;请输入正确的邮箱&quot;) private String email; } 统一异常处理 一般项目来说抛出异常都会有约定好的格式返回错误码和错误信息，如果不处理就无法按照约定格式返回。这里我们可以通过声明全局异常处理类来拦截异常并将异常处理成前端能操作的数据格式。（这里只需要关注MethodArgumentNotValidException异常） 当传入参数不满足校验规则时，程序就会抛出MethodArgumentNotValidException异常。我们通过之前封装的Spring Boot统一异常处理，将该异常封装成规范响应格式。 package com.example.blog.exception.handler; import com.example.common.Result; import org.springframework.validation.ObjectError; import org.springframework.web.bind.MethodArgumentNotValidException; import org.springframework.web.bind.annotation.ExceptionHandler; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestControllerAdvice; /** * @author vincent */ @RestControllerAdvice public class GlobalExceptionAdvice { @ExceptionHandler(MethodArgumentNotValidException.class) @ResponseBody public Result&lt;Object&gt; handleBeanValidation(MethodArgumentNotValidException e) { ObjectError errors = e.getBindingResult().getAllErrors().get(0); return Result.fail(errors.getDefaultMessage()); } } 编写一个简单接口 package com.example.blog.controller; import com.example.blog.request.UserCreateRequest; import com.example.common.Result; import org.springframework.validation.annotation.Validated; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** * @author vincent */ @RestController @RequestMapping(&quot;/blog/auth&quot;) public class AuthController { @PostMapping(&quot;/create&quot;) public Result&lt;String&gt; create(@Validated @RequestBody UserCreateRequest userCreateRequest) { System.out.println(userCreateRequest.getPassword()); System.out.println(userCreateRequest.getUsername()); return Result.success(&quot;14124&quot;); } } 运行测试一下 POST http://localhost:8000/blog/auth/create Content-Type: application/json { &quot;password&quot;: &quot;&quot;, &quot;username&quot;: &quot;content&quot; } Validation常用注解 @Null 限制只能为null @NotNull 限制必须不为null @AssertFalse 限制必须为false @AssertTrue 限制必须为true @DecimalMax(value) 限制必须为一个不大于指定值的数字 @DecimalMin(value) 限制必须为一个不小于指定值的数字 @Digits(integer,fraction) 限制必须为一个小数，且整数部分的位数不能超过integer，小数部分的位数不能超过fraction @Future 限制必须是一个将来的日期 @Max(value) 限制必须为一个不大于指定值的数字 @Min(value) 限制必须为一个不小于指定值的数字 @Past 限制必须是一个过去的日期 @Pattern(value) 限制必须符合指定的正则表达式 @Size(max,min) 限制字符长度必须在min到max之间 @Past 验证注解的元素值（日期类型）比当前时间早 @NotEmpty 验证注解的元素值不为null且不为空（字符串长度不为0、集合大小不为0） @NotBlank 验证注解的元素值不为空（不为null、去除首位空格后长度为0），不同于@NotEmpty，@NotBlank只应用于字符串且在比较时会去除字符串的空格 @Email 验证注解的元素值是Email，也可以通过正则表达式和flag指定自定义的email格式 自定义validator注解 因为validator框架支持的注解有限，不可能方方面面都支持，故需要我们自定义注解。 比如检查用户注册时使用的密码跟确认密码是否一致。 比如手机号验证。 ...... 哪我们就先写一个手机号的validator注解。 创建一个的手机校验注解类 package com.example.blog.request.custom; import com.example.blog.request.custom.validator.PhoneValidator; import javax.validation.Constraint; import javax.validation.Payload; import java.lang.annotation.Documented; import java.lang.annotation.Retention; import java.lang.annotation.Target; import static java.lang.annotation.ElementType.*; import static java.lang.annotation.RetentionPolicy.RUNTIME; /** * @author vincent */ @Documented // 指定注解的实现类 @Constraint(validatedBy = PhoneValidator.class) @Target( { METHOD, FIELD }) @Retention(RUNTIME) public @interface Phone { String message() default &quot;请输入正确的手机号码&quot;; Class&lt;?&gt;[] groups() default { }; Class&lt;? extends Payload&gt;[] payload() default { }; @Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER }) @Retention(RUNTIME) @Documented @interface List { Phone[] value(); } } 手机号码校验注解实现类 package com.example.blog.request.custom.validator; import com.example.blog.request.custom.Phone; import javax.validation.ConstraintValidator; import javax.validation.ConstraintValidatorContext; import java.util.regex.Matcher; import java.util.regex.Pattern; /** * @author vincent */ public class PhoneValidator implements ConstraintValidator&lt;Phone, String&gt; { private static final Pattern PHONE_PATTERN = Pattern.compile( &quot;^((13[0-9])|(15[^4])|(18[0,2,3,5-9])|(17[0-8])|(147))\\\\d{8}$&quot; ); @Override public void initialize(Phone constraintAnnotation) { } /** * 校验的实现逻辑 */ @Override public boolean isValid(String value, ConstraintValidatorContext context) { if (value == null || value.length() == 0) { return true; } Matcher m = PHONE_PATTERN.matcher(value); return m.matches(); } } 注册用的DTO对象，加上手机号码校验注解 package com.example.blog.request; import com.example.blog.request.custom.Phone; // ...... /** * @author vincent */ @Data public class UserCreateRequest { // ...... @Phone private String phone; } 测试一下 类层次校验注解 回到我们的主题上，我们最终需要编写一个验证注解，实现功能：检查用户注册时使用的密码跟确认密码是否一致。在前面，我们使用和编写的都是 Filed 层次的验证注解，然而却很难实现跨字段验证。一个最高效的解决方法是：实现一个 Class 层次的注解，并且依靠反射获得对应的两个字段的值。依照这个思路，我们编写的代码如下： 创建注解类 @FieldSame package com.example.blog.request.custom; import com.example.blog.request.custom.validator.FieldSameValidator; import javax.validation.Constraint; import javax.validation.Payload; import java.lang.annotation.Documented; import java.lang.annotation.Retention; import java.lang.annotation.Target; import static java.lang.annotation.ElementType.ANNOTATION_TYPE; import static java.lang.annotation.ElementType.TYPE; import static java.lang.annotation.RetentionPolicy.RUNTIME; /** * @author vincent */ @Target({TYPE, ANNOTATION_TYPE}) @Retention(RUNTIME) @Constraint(validatedBy = FieldSameValidator.class) @Documented public @interface FieldSame { String message() default &quot;{constraints.field same.message}&quot;; Class&lt;?&gt;[] groups() default {}; Class&lt;? extends Payload&gt;[] payload() default {}; /** * 需要验证的第一字段的字段名&lt;code&gt;String password&lt;/code&gt; 中的 &lt;code&gt;password&lt;/code&gt; * * @return 第一字段的字段名 */ String first(); /** * 需要验证的第二字段的字段名&lt;code&gt;String confirmPassword&lt;/code&gt; 中的 &lt;code&gt;confirmPassword&lt;/code&gt; * * @return 第一字段的字段名 */ String second(); @Target({TYPE, ANNOTATION_TYPE}) @Retention(RUNTIME) @Documented @interface List { FieldSame[] value(); } } 验证器 FieldSameValidator package com.example.blog.request.custom.validator; import com.example.blog.request.custom.FieldSame; import org.springframework.beans.BeanWrapperImpl; import javax.validation.ConstraintValidator; import javax.validation.ConstraintValidatorContext; /** * @author vincent */ public class FieldSameValidator implements ConstraintValidator&lt;FieldSame, Object&gt; { private String firstFieldName; private String secondFieldName; @Override public void initialize(final FieldSame constraintAnnotation) { firstFieldName = constraintAnnotation.first(); secondFieldName = constraintAnnotation.second(); } @Override public boolean isValid(final Object src, final ConstraintValidatorContext context) { BeanWrapperImpl wrapper = new BeanWrapperImpl(src); Object firstObj = wrapper.getPropertyValue(firstFieldName); System.out.println(&quot;firstObj = &quot; + firstObj); Object secondObj = wrapper.getPropertyValue(secondFieldName); System.out.println(&quot;secondObj = &quot; + secondObj); return firstObj != null &amp;&amp; firstObj.equals(secondObj); } } 修改DTO package com.example.blog.request; import com.example.blog.request.custom.FieldSame; import com.example.blog.request.custom.Phone; import lombok.Data; import org.hibernate.validator.constraints.Length; import javax.validation.constraints.Email; import javax.validation.constraints.NotNull; /** * @author vincent */ @Data @FieldSame(first = &quot;password&quot;, second = &quot;password2&quot;, message = &quot;两次密码输入的不一致&quot;) public class UserCreateRequest { @NotNull(message = &quot;登录用户名不能为空&quot;) @Length(max = 10, message = &quot;登录用户名最长为10位&quot;) private String username; @NotNull(message = &quot;登录密码不能为空&quot;) @Length(min = 6, max = 16, message = &quot;密码长度不能小于6位&quot;) private String password; @NotNull(message = &quot;确认登录密码不能为空&quot;) @Length(min = 6, max = 16, message = &quot;密码长度不能小于6位&quot;) private String password2; @Email(message = &quot;请输入正确的邮箱&quot;) private String email; @Phone private String phone; } 注意我们的GlobalExceptionAdvice异常处理需要进行🤏亿点点改进来捕获FieldError错误 package com.example.blog.exception.handler; import com.example.common.Result; import org.springframework.validation.FieldError; import org.springframework.validation.ObjectError; import org.springframework.web.bind.MethodArgumentNotValidException; import org.springframework.web.bind.annotation.ExceptionHandler; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestControllerAdvice; /** * @author vincent */ @RestControllerAdvice public class GlobalExceptionAdvice { @ExceptionHandler(MethodArgumentNotValidException.class) @ResponseBody public Result&lt;Object&gt; handleBeanValidation(MethodArgumentNotValidException e) { ObjectError errors = e.getBindingResult().getAllErrors().get(0); if (errors instanceof FieldError) { //Field 上的 FieldError 类型错误 FieldError fieldError = ((FieldError) errors); return Result.fail(fieldError.getDefaultMessage()); } return Result.fail(errors.getDefaultMessage()); } } 让我们来测试一下 ","link":"https://www.vincent.ac.cn/post/9Q0e2ivav/"},{"title":"IDEA 使用@Autowired 出现警告","content":"昨天在用IDEA编写Spring Boot的时候注意到了一个提示使用Spring的依赖注入注解@Autowired后会出现如下警告 不建议使用字段注入 如上图 强迫症觉得很难受就就百度了下说可以换成 @Resource 就不会出现警告 试了一下果然如此，但是两者有什么区别呢？所以就深入了解了一下 Spring常见的DI方式 构造器注入：利用构造方法的参数注入依赖 Setter注入：调用Setter的方法注入依赖 字段注入：在字段上使用@Autowired/Resource注解 @Autowired VS @Resource 事实上，他们的基本功能都是通过注解实现依赖注入，只不过@Autowired是Spring定义的，而@Resource是JSR-250定义的。大致功能基本相同，但是还有一些细节不同： 依赖识别方式：@Autowired默认是byType可以使用@Qualifier指定Name，@Resource默认ByName如果找不到则ByType 适用对象：@Autowired可以对构造器、方法、参数、字段使用，@Resource只能对方法、字段使用 提供方：@Autowired是Spring提供的，@Resource是JSR-250提供的 各种DI方式的优缺点 参考Spring官方文档，建议了如下的使用场景： 构造器注入：强依赖性（即必须使用此依赖），不变性（各依赖不会经常变动） Setter注入：可选（没有此依赖也可以工作），可变（依赖会经常变动） Field注入：大多数情况下尽量少使用字段注入，一定要使用的话，@Resource相对@Autowired对IoC容器的耦合更低 Field注入的缺点 不能像构造器那样注入不可变的对象 依赖对外部不可见，外界可以看到构造器和setter，但无法看到私有字段，自然无法了解所需依赖 会导致组件与IoC容器紧耦合（这是最重要的原因，离开了IoC容器去使用组件，在注入依赖时就会十分困难） 导致单元测试也必须使用IoC容器，原因同上 依赖过多时不够明显，比如我需要10个依赖，用构造器注入就会显得庞大，这时候应该考虑一下此组件是不是违反了单一职责原则 那么为什么IDEA只对@Autowired警告 Field注入虽然有很多缺点，但它的好处也不可忽略：那就是太方便了。使用构造器或者Setter注入需要写更多业务无关的代码，十分麻烦，而字段注入大幅简化了它们。并且绝大多数情况下业务代码和框架就是强绑定的，完全松耦合只是一件理想上的事，牺牲了敏捷度去过度追求松耦合反而得不偿失。那么问题来了，为什么IDEA只对@Autowired警告，却对@Resource视而不见呢？ 或许是因为@Autowired是Spring提供的，它是特定IoC提供的特定注解，这就导致了应用与框架的强绑定，一旦换用了其他的IoC框架，是不能够支持注入的。而@Resource是JSR-250提供的，它是Java标准，我们使用的IoC容器应当去兼容它，这样即使更换容器，也可以正常工作。 ","link":"https://www.vincent.ac.cn/post/O5fXCJqaC/"},{"title":"初学 Spring Boot 封装接口统一响应结果并运行","content":"接着上文 写一个简单的接口并启动运行 Spring Boot 接口统一响应结果封装 这里我们用到了一个Result的类，这个用于我们的异步统一返回的结果封装。一般来说，结果里面有几个要素必要的 code 是否成功，可用code表示（如200表示成功，400表示异常） message 结果消息 data 结果数据 这里我们使用泛型 代码如下 package com.example.common; import lombok.Data; import java.io.Serializable; /** * @author vincent */ @Data public class Result&lt;T&gt; implements Serializable { private int code; private String msg; private T data; public static&lt;T&gt; Result&lt;T&gt; success(T data) { Result&lt;T&gt; m = new Result&lt;T&gt;(); m.setCode(200); m.setData(data); m.setMsg(&quot;操作成功&quot;); return m; } public static&lt;T&gt; Result&lt;T&gt; success(String mess, T data) { Result&lt;T&gt; m = new Result&lt;T&gt;(); m.setCode(200); m.setData(data); m.setMsg(mess); return m; } public static&lt;T&gt; Result&lt;T&gt; fail(String mess) { Result&lt;T&gt; m = new Result&lt;T&gt;(); m.setCode(0); m.setData(null); m.setMsg(mess); return m; } public static&lt;T&gt; Result&lt;T&gt; fail(String mess, T data) { Result&lt;T&gt; m = new Result&lt;T&gt;(); m.setCode(0); m.setData(data); m.setMsg(mess); return m; } } 在UserController中写个 show 方法 package com.example.blog.controller; import com.example.blog.entity.UserEntity; import com.example.blog.service.UserService; import com.example.common.Result; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** * &lt;p&gt; * 前端控制器 * &lt;/p&gt; * * @author vincent * @since 2021-12-29 */ @RestController @RequestMapping(&quot;/blog/user-entity&quot;) public class UserController { @Autowired private UserService userService; @GetMapping(&quot;/show/{id}&quot;) public Result&lt;UserEntity&gt; show(@PathVariable(&quot;id&quot;) Long id) { return Result.success(userService.getById(id)); } } 启动 Spring Boot 右键文件 Demo2Application.java -&gt; 运行Demo2Application，开始启动应用，当出现如下信息的时候，就说明应用启动成功了，默认启动端口是8080。 打开浏览器，访问：http://localhost:8080/blog/user-entity/show/1 获得结果如下，整合成功！ 开发环境调试 如果每次修改代码之后都需要重新启动WEB应用，还是有点麻烦的，Spring Boot支持热启动，修改之后可以实时生效，开发的时候打开还是可以提供一些便利性的。 打开POM文件，在dependencies标签下添加spring-boot-devtools依赖，并修改build标签下的spring-boot-maven-plugin的fork属性为true即可。 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 启动端口修改 Spring Boot默认的启动端口是8080，如果需要修改，需要修改配置文件。 打开application.yml文件，在其中添加如下内容，配置启动端口号。 #...... server: port: 8000 #...... 重新启动应用，查看控制台启动信息，我们发现启动端口已经变成8000了。 ","link":"https://www.vincent.ac.cn/post/UQkhpWrWQ/"},{"title":"初学 Spring Boot 创建项目并整合Mybatis Plus ","content":" 学习java总是绕不开 spring 的 Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。简而言之，Spring Boot通过提供默认配置的方式整合了所有的框架，让我们可以更加简单、快速、方便地构建应用程序。 为什么要用Spring Boot? Spring Boot包含以下几个特性: 默认提供了大部分框架的使用方式，方便进行快速集成 Spring Boot应用可以独立运行，符合微服务的开发理念 Spring Boot内置WEB容器，无需部署WAR包即可运行 提供了各种生产就绪型功能，如指标，健康检查和外部配置 Spring Boot通过网站提供了项目模板，方便项目的初始化 通过以上这些非常优秀的特性，Spring Boot可以帮助我们非常简单、快速的构建起我们的项目，并能够非常方便进行后续开发、测试和部署。 然后数据层，我们常用的是Mybatis，易上手，方便维护。但是单表操作比较困难，特别是添加字段或减少字段的时候，比较繁琐，所以这里我推荐使用Mybatis Plus，为简化开发而生，只… CRUD 操作，从而节省大量时间。 多说无益，实践为上。接下来，就来建立起我们的第一个Spring Boot项目。 新建Spring Boot项目 为方便我们初始化项目，Spring Boot给我们提供一个项目模板生成网站。 打开浏览器，访问：https://start.spring.io/ 根据页面提示，选择构建工具，开发语言，项目信息等。 点击 Generate the project，生成项目模板，生成之后会将压缩包下载到本地。 使用IDE导入项目，我这里使用IDEA，通过导入Maven项目的方式导入。 不过这里，我们使用IDEA来直接创建我们项目 打开IDEA点击新建项目 选择 Spring Initializr 填写名称、位置、组、工件、软件包 语言选择 Java 类型选择 Maven 因为我这里的SDK是1.8版本 所以Java选择 8 打包选 Jar 点下一步 选择 Spring Boot 版本这里我直接选了最新版 2.6.2 以及勾选需要的依赖点击完成即可(依赖也可不勾选后续在手动增加) 项目结构说明 如上图所示，Spring Boot 的项目结构比较简单，只包含三个文件夹。 src/main/java 放置程序开发代码 src/main/resources 放置配置文件 src/test/java 放置测试程序代码 而在其下，包含以下主要文件。 Demo3Application.java 应用的启动类，包含MAIN方法，是程序的入口 application.properties 一个空的配置文件，后续可以配置数据源等信息 Demo3ApplicationTests.java 一个简单的单元测试类 pom.xml Maven的配置文件，这个应该不用多作介绍了吧 引入Maven依赖 编辑 pox.xml文件增加下列代码 (编辑该文件后IDEA右上角会出现一个 Maven 的小图标 点击刷新即可将新增的依赖引入到项目中) &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- lombok简化代码 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; web:Spring Boot Web依赖。 devtools：项目的热加载重启插件 lombok：简化代码的工具 整合 Mybatis Plus 接下来，我们来整合 Mybatis Plus，让项目能完成基本的增删改查操作 步骤很简单：可以去官网看看 https://baomidou.com/ 第一步：引入Maven依赖 pom.xml中导入 Mybatis Plus的jar包，因为后面会涉及到代码生成，所以我们还需要导入页面模板引擎，这里我们用的是freemarker。 编辑 pox.xml文件增加下列代码 (编辑该文件后IDEA右上角会出现一个 Maven 的小图标 点击刷新即可将新增的依赖引入到项目中) &lt;!--Mybatis-Plus begin --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!--Mybatis-Plus 代码生成器--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-extension&lt;/artifactId&gt; &lt;version&gt;3.4.3.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mybatis-Plus end --&gt; 第二步：然后去写配置文件 这里我们用yml格式来配置 在 src/main/resources目录下创建一个 application.yml 配置文件 # DataSource Config spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/blog?useUnicode=true&amp;useSSL=false&amp;characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai username: root password: admin111 第三步：编写快速生成代码 那么现在就已经可以使用Mybatis Plus了，官方给我们提供了一个代码生成器，然后我写上自己的参数之后，就可以直接根据数据库表信息生成entity、service、mapper等接口和实现类。 首先在数据库中创建两张表 SET FOREIGN_KEY_CHECKS=0; -- ---------------------------- -- Table structure for m_blog -- ---------------------------- DROP TABLE IF EXISTS `m_blog`; CREATE TABLE `m_blog` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `user_id` bigint(20) NOT NULL, `title` varchar(255) NOT NULL, `description` varchar(255) NOT NULL, `content` longtext, `created` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP, `status` tinyint(4) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=15 DEFAULT CHARSET=utf8mb4; -- ---------------------------- -- Records of m_blog -- ---------------------------- -- ---------------------------- -- Table structure for m_user -- ---------------------------- DROP TABLE IF EXISTS `m_user`; CREATE TABLE `m_user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `username` varchar(64) DEFAULT NULL, `avatar` varchar(255) DEFAULT NULL, `email` varchar(64) DEFAULT NULL, `password` varchar(64) DEFAULT NULL, `status` int(5) NOT NULL, `created` datetime DEFAULT NULL, `last_login` datetime DEFAULT NULL, PRIMARY KEY (`id`), KEY `UK_USERNAME` (`username`) USING BTREE ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; -- ---------------------------- -- Records of m_user -- ---------------------------- INSERT INTO `m_user` VALUES ('1', 'vincent', 'https://qingfengzui-1259530817.cos.ap-shanghai.myqcloud.com/uPic/2021_12_30/hPBC1H.png', null, '96e79218965eb72c92a549dd5a330112', '0', '2020-04-20 10:44:01', null); 在 src/main/java/com/example/demo3 创建 CodeGenerator.java 文件 package com.example.demo2; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.generator.FastAutoGenerator; import com.baomidou.mybatisplus.generator.config.OutputFile; import com.baomidou.mybatisplus.generator.config.rules.DateType; import com.baomidou.mybatisplus.generator.config.rules.NamingStrategy; import com.baomidou.mybatisplus.generator.engine.FreemarkerTemplateEngine; import java.util.Collections; /** * 代码生成器 ，先修改下面的常量配置参数，然后执行 main方法 * * @author vincent */ public class CodeGenerator { // 数据库连接配置 private static final String JDBC_URL = &quot;jdbc:mysql://localhost:3306/blog?useUnicode=true&amp;useSSL=false&amp;characterEncoding=utf8&amp;serverTimezone=UTC&quot;; private static final String JDBC_USER_NAME = &quot;root&quot;; private static final String JDBC_PASSWORD = &quot;admin111&quot;; // 包名和模块名 /** * */ private static final String PACKAGE_NAME = &quot;com.example&quot;; private static final String MODULE_NAME = &quot;blog&quot;; // 表名，多个表使用英文逗号分割 private static final String[] TBL_NAMES = {&quot;m_user&quot;, &quot;m_blog&quot;}; // 表名的前缀，从表生成代码时会去掉前缀 /** * */ private static final String TABLE_PREFIX = &quot;m_&quot;; // 生成代码入口main方法 /** * */ public static void main(String[] args) { //获取项目路径 String projectPath = System.getProperty(&quot;user.dir&quot;); FastAutoGenerator.create(JDBC_URL, JDBC_USER_NAME, JDBC_PASSWORD) .globalConfig(builder -&gt; { builder.author(&quot;vincent&quot;)// 设置注释的作者 .fileOverride()// 覆盖已生成文件 .disableOpenDir() // 不打开生成文件目录 .enableSwagger() // 开启 swagger 模式 .commentDate(&quot;yyyy-MM-dd&quot;)// 设置注释的日期格式 .dateType(DateType.TIME_PACK)// 使用java8新的时间类型 .outputDir(projectPath + &quot;/src/main/java&quot;);// 指定输出目录,注意使用反斜杠\\ }) .packageConfig(builder -&gt; { builder.parent(PACKAGE_NAME)// 设置父包名 .moduleName(MODULE_NAME)// 设置父包模块名 .entity(&quot;entity&quot;)// 设置MVC下各个模块的包名 .mapper(&quot;dao&quot;) .service(&quot;service&quot;) .serviceImpl(&quot;service.impl&quot;) .controller(&quot;controller&quot;) .other(&quot;other&quot;) .pathInfo(Collections.singletonMap(OutputFile.mapperXml, projectPath + &quot;/src/main/resources/mapper&quot;)); // 设置mapperXml生成路径 }) .strategyConfig(builder -&gt; { builder.enableCapitalMode() .enableSkipView() .disableSqlFilter() .addInclude(TBL_NAMES)// 设置需要生成的表名 .addTablePrefix(TABLE_PREFIX) .entityBuilder() .enableTableFieldAnnotation()// 生成实体时生成字段的注解，包括@TableId注解等 .naming(NamingStrategy.underline_to_camel) .columnNaming(NamingStrategy.underline_to_camel)// 数据库表和字段映射到实体的命名策略，为下划线转驼峰 .idType(IdType.NONE)// 全局主键类型为None .formatFileName(&quot;%sEntity&quot;)// 实体名称格式化为XXXEntity // 开启生成@RestController控制器 .controllerBuilder() .enableRestStyle() // 格式化service接口和实现类的文件名称，去掉默认的ServiceName前面的I .serviceBuilder() .formatServiceFileName(&quot;%sService&quot;) .formatServiceImplFileName(&quot;%sServiceImpl&quot;) // 格式化 mapper文件名,格式化xml实现类文件名称 .mapperBuilder() .formatMapperFileName(&quot;%sDao&quot;) .formatXmlFileName(&quot;%sDao&quot;);// 设置过滤表前缀 }) // 使用Freemarker引擎模板，默认的是Velocity引擎模板 .templateEngine(new FreemarkerTemplateEngine()) .execute(); } } 第四步：代码生成 执行 CodeGenerator 的 main方法 通过连接MySQL数据库，生成对应的代码框架如下 简洁！方便！经过上面的步骤，基本上我们已经把 Mybatis Plus框架集成到项目中了。 第五步：映射 Dao 目录 编辑 Demo2Application.java 项目启动文件 package com.example; import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; /** * @author vincent */ @SpringBootApplication @MapperScan(&quot;com.example.blog.dao&quot;) public class Demo2Application { public static void main(String[] args) { SpringApplication.run(Demo2Application.class, args); } } ","link":"https://www.vincent.ac.cn/post/rqke6QAba/"},{"title":"swoole学习笔记 进程 二","content":"并发编程 【php多进程编程 linux】全手动实习 一点区别没有 多进程开发方面的比较全面的资料 c++ 并发编程 用的多线程方案是最多的 服务器通信领域【socket 网络编程，多线程性能最高，并发最好】 1 php pcntl 扩展 2 swoole process fork/clone exec / exit/ 中断信号的函数 kill/alarm ... 信号集 信号屏蔽字 阻塞信号集，信号递达，阻塞 进程 swoole封装的进程模块 [没有回收机制wait] 2434 bin/bash /bin/sh 控制进程 bash进程 sh进程 sh进程2434进程：php process1.php sh读取字符串【php process1.php】然后创建一个子进程[docker容器51] [3763宿主机],sh进程调用wait4阻塞 2434 具体 来说就是Linux终端 2434 [00007f57b1823885] open(&quot;/root/.ash_history&quot;, O_WRONLY|O_CREAT|O_APPEND, 0600) = 3 &lt;0.000039&gt; 2434 [00007f57b1826911] lseek(3, 0, SEEK_END) = 516 &lt;0.000015&gt; 2434 [00007f57b1823885] write(3, &quot;php process1.php \\n&quot;, 18) = 18 &lt;0.000024&gt; 2434 [00007f57b1823885] close(3) = 0 &lt;0.000019&gt; 2434 [00007f57b180d4ec] fork() = 51 &lt;0.000917&gt; 2434 [00007f57b1826bf0] setpgid(51, 51) = 0 &lt;0.000015&gt; 51=3763 [docker容器] [3763宿主机] 2434 [00007f57b1823885] wait4(-1, &lt;unfinished ...&gt; 3763 [00007f57b1826bf0] setpgid(0, 51) = 0 &lt;0.000014&gt; /usr/bin/php ELF 文件 3763 [00007f57b180d2a7] execve(&quot;/usr/bin/php&quot;, [&quot;php&quot;, &quot;process1.php&quot;], 0x55699530ac98 /* 10 vars */) = 0 &lt;0.000661&gt; 3763 [00007f58245aff84] open(&quot;process1.php&quot;, O_RDONLY) = 4 &lt;0.000427&gt; 3763 [00007f58245aeed6] readv(4, [{iov_base=&quot;&lt;?php\\r\\n/**\\r\\n * Created by PhpStorm.\\r\\n * User: Administrator\\r\\n * Date: 2021/6/7 0007\\r\\n * Time: \\344\\270\\213\\345\\215\\210 9:57\\r\\n */\\r\\n\\r\\nuse Swoole\\\\Process;\\r\\n\\r\\nfunction showPId()\\r\\n{\\r\\n echo \\&quot;pid=\\&quot;.posix_getpid().\\&quot;\\\\r\\\\n\\&quot;;\\r\\n\\r\\n\\r\\n}\\r\\n\\r\\nshowPId();\\r\\n\\r\\n\\r\\n$prcoess = new Process(function(){\\r\\n\\r\\n showPId();\\r\\n});\\r\\n\\r\\n$prcoess-&gt;start()&quot;, iov_len=303}, {iov_base=&quot;;&quot;, iov_len=1024}], 2) = 304 &lt;0.000130&gt; 3763 [00007f58245aedeb] close(4) = 0 &lt;0.000074&gt; 3763 [00007f58245bc885] write(1, &quot;pid=51\\r\\n&quot;, 8) = 8 &lt;0.000079&gt; unix socket 双向通信文件 双工通信 unix 匿名 socket 文件 有名 [4,5]是一个数组，可以对4，5进行读写实现进程间通信 有血缘的进程间通信 【父子进程，兄弟进程】多进程编程 3763 [00007f58245a3f68] socketpair(AF_UNIX, SOCK_DGRAM, 0, [4, 5]) = 0 &lt;0.000467&gt; 网络编程[go/rust/java] linux 3763 [00007f5824585af7] fcntl(4, F_GETFL) = 0x2 (flags O_RDWR) &lt;0.000068&gt; 3763 [00007f5824585af7] fcntl(4, F_SETFL, O_RDWR) = 0 &lt;0.000074&gt; 3763 [00007f5824585af7] fcntl(5, F_GETFL) = 0x2 (flags O_RDWR) &lt;0.000065&gt; 3763 [00007f5824585af7] fcntl(5, F_SETFL, O_RDWR) = 0 &lt;0.000065&gt; 3763 [00007f58245a64ec] fork( &lt;unfinished ...&gt; 3763 进程在执行系统调用fork，执行了一半 3764 [00007f58245a6503] gettid( &lt;unfinished ...&gt; 3763 [00007f58245a64ec] &lt;... fork resumed&gt;) = 52 &lt;0.000874&gt; [docker 容器里的进程52] [宿主机的进程是3764] 3764 [00007f58245a6503] &lt;... gettid resumed&gt;) = 52 &lt;0.000132&gt; 3763 [00007f5824585710] exit_group(0) = ? 3763 进程退出 2434 [00007f57b1823885] &lt;... wait4 resumed&gt;[{WIFEXITED(s) &amp;&amp; WEXITSTATUS(s) == 0}], WSTOPPED, NULL) = 51 &lt;0.309871&gt; sh进程回收 当子进程退出时【3763】会向父进程发送中断信号，SIGCHLD 2434 [00007f57b1823885] --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=51, si_uid=0, si_status=0, si_utime=4, si_stime=9} 2434 [00007f57b1823885] wait4(-1, 0x7ffdd8ada64c, WNOHANG|WSTOPPED, NULL) = -1 ECHILD (No child processes) &lt;0.000014&gt; 3764 [00007f58245bf852] getpid() = 52 &lt;0.000016&gt; 3764 [00007f58245bf852] getpid() = 52 &lt;0.000014&gt; 3764 [00007f58245bc885] write(1, &quot;pid=52\\r\\n&quot;, 8) = 8 &lt;0.000054&gt; 3764 [00007f58245aedeb] close(0) = 0 &lt;0.000018&gt; 3764 [00007f5824585710] exit_group(0) = ? 3764 [????????????????] +++ exited with 0 +++ 这个3764死了没人收尸 服务器内存资源被占用大堆，然后你就说swoole不行啊，各种问题，各种bug fork会复制父进程当前的内存空间 此时，子进程就可以读取父进程所有的内容，但是如果子进程写【写内存，比如定义变量】它就会创建一块新内存给当前进程使用，不会影响父进程，并且 父进程不能读取子进程的新内容 进程组 原生的写法 2434 [00007f57b180d4ec] fork() = 83 &lt;0.000164&gt; 创建一个新进程 16922 2434 [00007f57b1826bf0] setpgid(83, 83) = 0 &lt;0.000758&gt; 16922 [00007f57b180d503] gettid() = 83 &lt;0.000091&gt; 2434 [00007f57b1823885] wait4(-1, &lt;unfinished ...&gt; 16922 [00007f57b180d2a7] execve(&quot;/usr/bin/php&quot;, [&quot;php&quot;, &quot;pcntl.php&quot;], 0x55699530ac98 /* 10 vars */) = 0 &lt;0.000622&gt; 16922 [00007efcd247ef84] open(&quot;pcntl.php&quot;, O_RDONLY) = 4 &lt;0.000061&gt; 16922 [00007efcd247ded6] readv(4, [{iov_base=&quot;&lt;?php\\r\\n/**\\r\\n * Created by PhpStorm.\\r\\n * User: Administrator\\r\\n * Date: 2021/6/7 0007\\r\\n * Time: \\344\\270\\213\\345\\215\\210 10:00\\r\\n */\\r\\n\\r\\nfunction showPId()\\r\\n{\\r\\n echo \\&quot;pid=\\&quot;.posix_getpid().\\&quot;\\\\r\\\\n\\&quot;;\\r\\n\\r\\n\\r\\n}\\r\\n\\r\\n\\r\\n\\r\\n$pid = pcntl_fork();\\r\\n\\r\\nif($pid==0){\\r\\n\\r\\n showPId();\\r\\n exit(0);\\r\\n}\\r\\n\\r\\nshowPId()&quot;, iov_len=275}, {iov_base=&quot;;&quot;, iov_len=1024}], 2) = 276 &lt;0.000019&gt; 16922 [00007efcd248b885] fcntl(3, F_SETLKW, {l_type=F_WRLCK, l_whence=SEEK_SET, l_start=0, l_len=1}) = 0 &lt;0.000016&gt; 16922 [00007efcd2454af7] fcntl(3, F_SETLK, {l_type=F_UNLCK, l_whence=SEEK_SET, l_start=0, l_len=1}) = 0 &lt;0.000016&gt; 16922 [00007efcd247ddeb] close(4) = 0 &lt;0.000019&gt; 16922 [00007efcd247c9c1] rt_sigprocmask(SIG_BLOCK, ~[], [], 8) = 0 &lt;0.000014&gt; 16922 [00007efcd24754ec] fork() = 84 &lt;0.000535&gt; 创建一个新进程 16923 16923 [00007efcd248b885] write(1, &quot;pid=84\\r\\n&quot;, 8 &lt;unfinished ...&gt; 新进程做的第一件事情 16922 [00007efcd248e852] getpid( &lt;unfinished ...&gt; 16923 [00007efcd248b885] &lt;... write resumed&gt;) = 8 &lt;0.000095&gt; 16922 [00007efcd248e852] &lt;... getpid resumed&gt;) = 83 &lt;0.000502&gt; 16923 [00007efcd247ddeb] close(0 &lt;unfinished ...&gt; 16922 [00007efcd248b885] write(1, &quot;pid=83\\r\\n&quot;, 8) = 8 &lt;0.000030&gt; 16923 [00007efcd2454710] exit_group(0) = ? 16922 [00007efcd2454710] exit_group(0) = ? 2434 [00007f57b1823885] &lt;... wait4 resumed&gt;[{WIFEXITED(s) &amp;&amp; WEXITSTATUS(s) == 0}], WSTOPPED, NULL) = 83 &lt;0.261776&gt; 2434 [00007f57b1823885] --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=83, si_uid=0, si_status=0, si_utime=5, si_stime=4} swoole封装的进程模块 [有wait函数] 第一步 bin/sh控制进程创建一个子进程 【docker 89==宿主机进程17057】 2434 [00007f57b180d4ec] fork() = 89 &lt;0.000333&gt; 2434 [00007f57b1826bf0] setpgid(89, 89) = 0 &lt;0.000019&gt; 第二步 调用 wait4函数阻塞在此 2434 [00007f57b1823885] wait4(-1, &lt;unfinished ...&gt; 第三步 17057新进程执行process1.php程序 17057 [00007f57b180d2a7] execve(&quot;/usr/bin/php&quot;, [&quot;php&quot;, &quot;process1.php&quot;], 0x55699530ac98 /* 10 vars */) = 0 &lt;0.000756&gt; 17057 [00007fbb0c0fcf84] open(&quot;process1.php&quot;, O_RDONLY) = 4 &lt;0.000080&gt; 17057 [00007fbb0c0fbed6] readv(4, [{iov_base=&quot;&lt;?php\\r\\n/**\\r\\n * Created by PhpStorm.\\r\\n * User: Administrator\\r\\n * Date: 2021/6/7 0007\\r\\n * Time: \\344\\270\\213\\345\\215\\210 9:57\\r\\n */\\r\\n\\r\\nuse Swoole\\\\Process;\\r\\n\\r\\nfunction showPId()\\r\\n{\\r\\n echo \\&quot;pid=\\&quot;.posix_getpid().\\&quot;\\\\r\\\\n\\&quot;;\\r\\n\\r\\n\\r\\n}\\r\\n\\r\\nshowPId();\\r\\n\\r\\n\\r\\n$prcoess = new Process(function(){\\r\\n\\r\\n showPId();\\r\\n});\\r\\n\\r\\n$prcoess-&gt;start();\\r\\n\\r\\n$status = Process::wait();\\r\\n\\r\\nprint_r($status)&quot;, iov_len=354}, {iov_base=&quot;;&quot;, iov_len=1024}], 2) = 355 &lt;0.000071&gt; 17057 [00007fbb0c109885] fcntl(3, F_SETLKW, {l_type=F_WRLCK, l_whence=SEEK_SET, l_start=0, l_len=1}) = 0 &lt;0.000071&gt; 17057 [00007fbb0c0d2af7] fcntl(3, F_SETLK, {l_type=F_UNLCK, l_whence=SEEK_SET, l_start=0, l_len=1}) = 0 &lt;0.000069&gt; 17057 [00007fbb0c0fbdeb] close(4) = 0 &lt;0.000385&gt; 17057 [00007fbb0c10c852] getpid() = 89 &lt;0.000102&gt; 第四步 17057进程向终端打印pid=89 同时创建unix socket 数组文件 17057 [00007fbb0c109885] write(1, &quot;pid=89\\r\\n&quot;, 8) = 8 &lt;0.000159&gt; 17057 [00007fbb0c0f0f68] socketpair(AF_UNIX, SOCK_DGRAM, 0, [4, 5]) = 0 &lt;0.000191&gt; 17057 [00007fbb0c0d2af7] fcntl(4, F_GETFL) = 0x2 (flags O_RDWR) &lt;0.000067&gt; 17057 [00007fbb0c0d2af7] fcntl(4, F_SETFL, O_RDWR) = 0 &lt;0.000100&gt; 17057 [00007fbb0c0d2af7] fcntl(5, F_GETFL) = 0x2 (flags O_RDWR) &lt;0.000081&gt; 17057 [00007fbb0c0d2af7] fcntl(5, F_SETFL, O_RDWR) = 0 &lt;0.000076&gt; 17057 [00007fbb0c0f0e1e] setsockopt(5, SOL_SOCKET, SO_SNDBUF, [8388608], 4) = 0 &lt;0.000069&gt; 17057 [00007fbb0c0f0e1e] setsockopt(5, SOL_SOCKET, SO_RCVBUF, [8388608], 4) = 0 &lt;0.000067&gt; 17057 [00007fbb0c0f0e1e] setsockopt(4, SOL_SOCKET, SO_SNDBUF, [8388608], 4) = 0 &lt;0.000093&gt; 17057 [00007fbb0c0f0e1e] setsockopt(4, SOL_SOCKET, SO_RCVBUF, [8388608], 4) = 0 &lt;0.000081&gt; 第五步 17057 调用 fork函数调用 子进程 17058 17057 [00007fbb0c0f34ec] fork( &lt;unfinished ...&gt; 17057 [00007fbb0c0f34ec] &lt;... fork resumed&gt;) = 90 &lt;0.000859&gt; 第六步 17057调用wait4阻塞 17057 [00007fbb0c109885] wait4(-1, &lt;unfinished ...&gt; four wait for wait4 17058 [00007fbb0c10c852] getpid() = 90 &lt;0.000109&gt; 第七步 17058进程执行write 17058 [00007fbb0c109885] write(1, &quot;pid=90\\r\\n&quot;, 8) = 8 &lt;0.000190&gt; 第八步 17058子进程退出 退出状态码=0 17058 [00007fbb0c0d2710] exit_group(0) = ? 17058 [????????????????] +++ exited with 0 +++ 第九步 17057 【17058和17057是父子进程】 已经回收退出的子进程为17058 17057 [00007fbb0c109885] &lt;... wait4 resumed&gt;[{WIFEXITED(s) &amp;&amp; WEXITSTATUS(s) == 0}], 0, NULL) = 90 &lt;0.013855&gt; 17057 [00007fbb0c109885] --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=90, si_uid=0, si_status=0, si_utime=0, si_stime=0} 第十步 17057 打印数据 17057 [00007fbb0c109885] write(1, &quot;Array\\n(\\n [pid] =&gt; 90\\n [code] =&gt; 0\\n [signal] =&gt; 0\\n)\\n&quot;, 60) = 60 &lt;0.000285&gt; 第十一步 17057退出 17057 [00007fbb0c0d2710] exit_group(0) = ? 17057 [????????????????] +++ exited with 0 +++ 最后一步 2434 bin/sh进程回收17057进程 2434 [00007f57b1823885] &lt;... wait4 resumed&gt;[{WIFEXITED(s) &amp;&amp; WEXITSTATUS(s) == 0}], WSTOPPED, NULL) = 89 &lt;0.448712&gt; 2434 [00007f57b1823885] --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=89, si_uid=0, si_status=0, si_utime=4, si_stime=11} --- fd目录 从小到大 shell编程 exportSocket[socketpair(AF_UNIX, SOCK_DGRAM, 0, [4, 5]) = 0 &lt;0.000191&gt;]方法存在的原因 第一步：bin/sh控制进程收到php process2.php 数据字符串 【linux终端如何启动一个程序详细过程】【crud 3,4混过来的，摸鱼混的】 2434 [00007f57b1823885] write(3, &quot;php process2.php\\n&quot;, 17) = 17 &lt;0.000090&gt; 第二步：bin/sh进程调用fork系统调用创建一个新进程 【在docker容器里是92，在宿主机上是17338】 2434 [00007f57b180d4ec] fork() = 92 &lt;0.000234&gt; 2434 [00007f57b1826bf0] setpgid(92, 92 &lt;unfinished ...&gt; 第三步：bin/sh进程调用wait4阻塞在此 2434 [00007f57b1823885] wait4(-1, &lt;unfinished ...&gt; 第四步：cpu切换到17338进程干活 1 调用execve系统函数加载ELF文件 【linux系统如何加载一个程序】 后面的是参数是命令行参数 和环境参数 $argv / main(int argc,char *argv[]) go 2 调用open函数打开process2.php并读取此文件的内容【其实是text文件，并不是什么源码，只不过有些所谓的大佬称为PHP源码】 3 调用socketpair/fcntl/setsockopt 创建unix socket 双向通信的文件 【4，5】 unix socket file 它的类型是SOCK_STREAM 字节流 4 调用fork函数创建一个子进程 【93 17339】 5 调用epoll_create 创建epoll file 文件，文件标识是6 17338 [00007f57b180d2a7] execve(&quot;/usr/bin/php&quot;, [&quot;php&quot;, &quot;process2.php&quot;], 0x55699530ac98 /* 10 vars */) = 0 &lt;0.000328&gt; 17338 [00007f81f84e6f84] open(&quot;process2.php&quot;, O_RDONLY) = 4 &lt;0.000062&gt; 17338 [00007f81f84e5ed6] readv(4, [{iov_base=&quot;&lt;?php\\r\\n/**\\r\\n * Created by PhpStorm.\\r\\n * User: Administrator\\r\\n * Date: 2021/6/8 0008\\r\\n * Time: \\344\\270\\213\\345\\215\\210 9:17\\r\\n */\\r\\nuse Swoole\\\\Process;\\r\\nuse function Swoole\\\\Coroutine\\\\run;\\r\\n\\r\\n$proc1 = new Process(function (Process $proc) {\\r\\n $socket = $proc-&gt;exportSocket();\\r\\n echo $socket-&gt;recv();\\r\\n $socket-&gt;send(\\&quot;hello master\\\\n\\&quot;);\\r\\n echo \\&quot;proc1 stop\\\\n\\&quot;;\\r\\n}, false, 1, true);\\r\\n\\r\\n$proc1-&gt;start();\\r\\n\\r\\n\\r\\nrun(function() use ($proc1) {\\r\\n $socket = $proc1-&gt;exportSocket();\\r\\n $socket-&gt;send(\\&quot;hello pro1\\\\n\\&quot;);\\r\\n var_dump($socket-&gt;recv());\\r\\n});\\r\\n\\r\\n\\r\\nProcess::wait(true);\\r&quot;, iov_len=562}, {iov_base=&quot;\\n&quot;, iov_len=1024}], 2) = 563 &lt;0.000019&gt; unix 匿名 socket 文件命名 17338 [00007f81f84daf68] socketpair(AF_UNIX, SOCK_STREAM, 0, [4, 5]) = 0 &lt;0.000626&gt; 17338 [00007f81f84bcaf7] fcntl(4, F_GETFL) = 0x2 (flags O_RDWR) &lt;0.000016&gt; 17338 [00007f81f84bcaf7] fcntl(4, F_SETFL, O_RDWR) = 0 &lt;0.000015&gt; 17338 [00007f81f84bcaf7] fcntl(5, F_GETFL) = 0x2 (flags O_RDWR) &lt;0.000015&gt; 17338 [00007f81f84bcaf7] fcntl(5, F_SETFL, O_RDWR) = 0 &lt;0.000059&gt; 17338 [00007f81f84dae1e] setsockopt(5, SOL_SOCKET, SO_SNDBUF, [8388608], 4) = 0 &lt;0.000018&gt; 17338 [00007f81f84dae1e] setsockopt(5, SOL_SOCKET, SO_RCVBUF, [8388608], 4) = 0 &lt;0.000016&gt; 17338 [00007f81f84dae1e] setsockopt(4, SOL_SOCKET, SO_SNDBUF, [8388608], 4) = 0 &lt;0.000017&gt; 17338 [00007f81f84dae1e] setsockopt(4, SOL_SOCKET, SO_RCVBUF, [8388608], 4) = 0 &lt;0.000016&gt; 17338 [00007f81f84dd4ec] fork( &lt;unfinished ...&gt; 17338 [00007f81f84dd4ec] &lt;... fork resumed&gt;) = 93 &lt;0.000852&gt; 17338 [00007f81f84bf4ce] epoll_create1(0) = 6 &lt;0.000021&gt; 第五步：17338进程调用系统函数dup 复制创建一个新的文件为7 【5==7】 指针 引用【php,go,c++,java 】 17338 [00007f81f84f631a] dup(5) = 7 &lt;0.000047&gt; 17338 [00007f81f84bcaf7] fcntl(7, F_GETFL) = 0x2 (flags O_RDWR) &lt;0.000024&gt; 第六步：把7文件设置为非阻塞 【非阻塞IO] 17338 [00007f81f84bcaf7] fcntl(7, F_SETFL, O_RDWR|O_NONBLOCK) = 0 &lt;0.000019&gt; 第七步：向unix socket 7写入 &quot;hello pro1&quot; 17338 [00007f81f84f3885] sendto(7, &quot;hello pro1\\n&quot;, 11, 0, NULL, 0) = 11 &lt;0.000046&gt; [实质是向5发送数据 的] 1 因为这个unix socket 7已经是非阻塞IO，执行操作的时候不会发生进程挂起的问题，不管有没有返回数据，执行的系统函数会立马返回 你看下我的网络编程 17338 [00007f81f84f3885] recvfrom(7, 0x7f81f817a018, 65536, 0, NULL, NULL) = -1 EAGAIN (Resource temporarily unavailable) &lt;0.000012&gt; 2 把7添加到epoll内核事件表中，监听的事件是EPOLLIN 读事件 【IO事件，中断信号事件，定时事件】 17338 [00007f81f84bf50b] epoll_ctl(6, EPOLL_CTL_ADD, 7, {EPOLLIN, {u32=147362272, u64=94669816500704}}) = 0 &lt;0.000016&gt; 3 17338在此阻塞在epoll_wait系统函数 17338 [00007f81f84bf52d] epoll_pwait(6, &lt;unfinished ...&gt; 17339 [00007f81f84f6852] getpid() = 93 &lt;0.000017&gt; 第八步：17339进程调用epoll_create = 6 17339 [00007f81f84bf4ce] epoll_create1(0) = 6 &lt;0.000020&gt; 第九步：复制一个新的unix socket 文件为7 17339 [00007f81f84f631a] dup(4) = 7 &lt;0.000014&gt; 17339 [00007f81f84bcaf7] fcntl(7, F_GETFL) = 0x2 (flags O_RDWR) &lt;0.000014&gt; 17339 [00007f81f84bcaf7] fcntl(7, F_SETFL, O_RDWR|O_NONBLOCK) = 0 &lt;0.000014&gt; 第十步：从7接收数据 【从4接收】 17339 [00007f81f84f3885] recvfrom(7, &quot;hello pro1\\n&quot;, 65536, 0, NULL, NULL) = 11 &lt;0.000023&gt; 1 把接收到的数据向终端打印输出 17339 [00007f81f84f3885] write(1, &quot;hello pro1\\n&quot;, 11) = 11 &lt;0.000049&gt; 2 向 7 【4】 写入 &quot;hello master&quot;字符串数据 17339 [00007f81f84f3885] sendto(7, &quot;hello master\\n&quot;, 13, 0, NULL, 0) = 13 &lt;0.000060&gt; 3 17338进程调用的epoll_wait产生了可读事件 17338 [00007f81f84bf52d] &lt;... epoll_pwait resumed&gt;[{EPOLLIN, {u32=147362272, u64=94669816500704}}], 4096, 60000, NULL, 8) = 1 &lt;0.028337&gt; 4 cpu切换到17339进程 向终端输出proc1 stop字符串，并且关闭 epoll 文件 17339 [00007f81f84f3885] write(1, &quot;proc1 stop\\n&quot;, 11) = 11 &lt;0.000025&gt; 17339 [00007f81f84f3885] close(6) = 0 &lt;0.000019&gt; 17339 [00007f81f84e5deb] close(0) = 0 &lt;0.000015&gt; 5 进程17339调用close(7==4) 执行了一半【实际上这个函数内部的指令可能很多条】 17339 [00007f81f84f3885] close(7 &lt;unfinished ...&gt; 6 将7 ==5 移除epoll内核事件表 17338 [00007f81f84bf50b] epoll_ctl(6, EPOLL_CTL_DEL, 7, NULL &lt;unfinished ...&gt; 17339 [00007f81f84f3885] &lt;... close resumed&gt;) = 0 &lt;0.000074&gt; 17339 [00007f81f84bcaf7] fcntl(3, F_SETLK, {l_type=F_UNLCK, l_whence=SEEK_SET, l_start=0, l_len=0} &lt;unfinished ...&gt; 17338 [00007f81f84bf50b] &lt;... epoll_ctl resumed&gt;) = 0 &lt;0.000228&gt; 17339 [00007f81f84bcaf7] &lt;... fcntl resumed&gt;) = 0 &lt;0.000053&gt; 7 17338进程调用recvfrom 7==5 17338 [00007f81f84f3885] recvfrom(7, &quot;hello master\\n&quot;, 65536, 0, NULL, NULL) = 13 &lt;0.000021&gt; 17338 [00007f81f84f3885] write(1, &quot;string(13) \\&quot;&quot;, 12) = 12 &lt;0.000051&gt; 17338 [00007f81f84f3885] write(1, &quot;hello master\\n&quot;, 13) = 13 &lt;0.000054&gt; 17338 [00007f81f84f3885] write(1, &quot;\\&quot;\\n&quot;, 2) = 2 &lt;0.000244&gt; 17338 [00007f81f84f3885] close(6) = 0 &lt;0.000057&gt; 17338调用wait4阻塞 17338 [00007f81f84f3885] wait4(-1, &lt;unfinished ...&gt; 17339 [00007f81f84bc710] exit_group(0) = ? 17339 [????????????????] +++ exited with 0 +++ 17338 [00007f81f84f3885] &lt;... wait4 resumed&gt;[{WIFEXITED(s) &amp;&amp; WEXITSTATUS(s) == 0}], 0, NULL) = 93 &lt;0.013920&gt; 17338 [00007f81f84f3885] --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=93, si_uid=0, si_status=0, si_utime=0, si_stime=2} --- 17338 [00007f81f84f3885] close(7) = 0 &lt;0.000074&gt; 17338 [00007f81f84bc710] exit_group(0) = ? 17338 [????????????????] +++ exited with 0 +++ 2434 [00007f57b1823885] &lt;... wait4 resumed&gt;[{WIFEXITED(s) &amp;&amp; WEXITSTATUS(s) == 0}], WSTOPPED, NULL) = 92 &lt;0.297692&gt; 2434 [00007f57b1823885] --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=92, si_uid=0, si_status=0, si_utime=7, si_stime=5} --- 进程执行流程图 swoole 进程exportSocket通信流程图 swoole 进程池【多进程】 $pool = new Swoole\\Process\\Pool(2, SWOOLE_IPC_SOCKET); $pool-&gt;on(&quot;Message&quot;, function ($pool, $message) { echo &quot;Message: {$message}\\n&quot;; $pool-&gt;write(&quot;hello &quot;); $pool-&gt;write(&quot;world &quot;); $pool-&gt;write(&quot;\\n&quot;); }); $pool-&gt;listen('0.0.0.0', 9501); $pool-&gt;start(); 单核的时候，多进程的并发是模拟执行的【是cpu进行多次切换模拟并发执行】 linux 操作系统是把进程，线程当作 任务的 一个进程启动以后，操作系统会默默的启动一个主线程并执行代码 操作系统导论这本书 单击鼠标 1秒做了10万次调用 第一步：bin/sh进程调用fork()系统函数创建了新进程 [1242==32984],同时调用wait4阻塞等待子进程退出 2434 [00007f57b180d4ec] fork() = 1242 &lt;0.000119&gt; [1242==32984] 2434 [00007f57b1823885] wait4(-1, &lt;unfinished ...&gt; 产生进程切换 32984 [00007f57b180d2a7] execve(&quot;/usr/bin/php&quot;, [&quot;php&quot;, &quot;process3.php&quot;], 0x55699530ac98 /* 10 vars */) = 0 &lt;0.000639&gt; 32984 [00007fc619831f84] open(&quot;process3.php&quot;, O_RDONLY) = 4 &lt;0.000087&gt; 32984 [00007fc619830ed6] readv(4, [{iov_base=&quot;&lt;?php\\r\\n/**\\r\\n * Created by PhpStorm.\\r\\n * User: Administrator\\r\\n * Date: 2021/6/9 0009\\r\\n * Time: \\344\\270\\213\\345\\215\\210 9:20\\r\\n */\\r\\n$pool = new Swoole\\\\Process\\\\Pool(2, SWOOLE_IPC_SOCKET);\\r\\n\\r\\n$pool-&gt;on(\\&quot;Message\\&quot;, function ($pool, $message) {\\r\\n echo \\&quot;Message: {$message}\\\\n\\&quot;;\\r\\n $pool-&gt;write(\\&quot;hello \\&quot;);\\r\\n $pool-&gt;write(\\&quot;world \\&quot;);\\r\\n $pool-&gt;write(\\&quot;\\\\n\\&quot;);\\r\\n});\\r\\n\\r\\n$pool-&gt;listen('0.0.0.0', 9501);\\r\\n$pool-&gt;start();\\r\\n\\r&quot;, iov_len=397}, {iov_base=&quot;\\n&quot;, iov_len=1024}], 2) = 398 &lt;0.000159&gt; 第二步 32984 调用socket 系统函数创建IPV4 的TCP 套接字 设置相关选项并绑定【命名】并监听服务 32984 [00007fc619825e9d] socket(AF_INET, SOCK_STREAM|SOCK_CLOEXEC, IPPROTO_IP) = 4 &lt;0.000129&gt; 32984 [00007fc619825e1e] setsockopt(4, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0 &lt;0.000105&gt; 32984 [00007fc619820e8d] bind(4, {sa_family=AF_INET, sin_port=htons(9501), sin_addr=inet_addr(&quot;0.0.0.0&quot;)}, 16) = 0 &lt;0.000071&gt; 32984 [00007fc619823870] listen(4, 2048) = 0 &lt;0.000075&gt; 第三步 调用wait4阻塞当前进程，并 32984 [00007fc61983e885] wait4(-1, &lt;unfinished ...&gt; 32984 [00007fc61983e885] &lt;... wait4 resumed&gt;0x7ffc1355cf58, 0, NULL) = ? ERESTARTSYS (To be restarted if SA_RESTART is set) &lt;7.812490&gt; 第四步：创建新进程 [1243=32985] [1244=32986] 32985,32986 [fork系统函数] proc/PID/fd 32984 [00007fc6198284ec] fork() = 1243 &lt;0.000620&gt; [1243=32985] 32984 [00007fc6198284ec] fork( &lt;unfinished ...&gt; 32984 [00007fc6198284ec] &lt;... fork resumed&gt;) = 1244 &lt;0.000494&gt; [1244=32986] // 32985,32986 两主进程【主线程】 同时在执行accept4接收函数 // 一台机器，网卡可能多张，也有可能只有一张网卡 当网卡收到数据时，它会把数据写入内存，同时发起中断请求cpu，这个时候cpu去执行中断处理程序 //它会拿到数据 【网络帧】 【源物理地址mac|目的物理地址mac|数据|其它】 【网络编程】数据链路层，网络层【IP协议 】，传输层【TCP,UDP】，应用层 // 到达上层解析时，会得到IP+PORT【程序会通过端口号找到对应的进程，最终会找到对应的socket文件，会把数据写入socket文件的接收缓冲区，同时唤醒当前进程】 32985 [00007fc61983e885] accept4(4, &lt;unfinished ...&gt; [processor 3] 32985 [00007fc61983e885] &lt;... accept4 resumed&gt;{sa_family=AF_INET, sin_port=htons(42200), sin_addr=inet_addr(&quot;172.17.0.1&quot;)}, [120-&gt;16], SOCK_CLOEXEC) = 5 &lt;4.985028&gt; 1 首先先取4个字节，得到数据5 在此处执行Message事件回调函数 32985 [00007fc61983e885] recvfrom(5, &quot;\\0\\0\\0\\5&quot;, 4, MSG_WAITALL, NULL, NULL) = 4 &lt;0.000050&gt; 2 再取后面的5个字节拿到数据hello 32985 [00007fc61983e885] recvfrom(5, &quot;hello&quot;, 5, MSG_WAITALL, NULL, NULL) = 5 &lt;0.000021&gt; 32985 [00007fc61983e885] write(1, &quot;Message: hello\\n&quot;, 15) = 15 &lt;0.000052&gt; 32985 [00007fc61983e885] sendto(5, &quot;\\0\\0\\0\\r&quot;, 4, 0, NULL, 0) = 4 &lt;0.000141&gt; 32985 [00007fc61983e885] sendto(5, &quot;hello world \\n&quot;, 13, 0, NULL, 0) = 13 &lt;0.000037&gt; 3 打印接收到的数据并关闭客户端连接 32985 [00007fc61983e885] close(5) = 0 &lt;0.000051&gt; // 中断信号系统 【中断系统调用|可重入函数】 php多进程编程 32986 [00007fc61983e885] &lt;... accept4 resumed&gt;0x5578fe93b594, [120], SOCK_CLOEXEC) = ? ERESTARTSYS (To be restarted if SA_RESTART is set) &lt;7.812289&gt; 32985 [00007fc61983e885] &lt;... accept4 resumed&gt;0x5578fe93b554, [120], SOCK_CLOEXEC) = ? ERESTARTSYS (To be restarted if SA_RESTART is set) &lt;2.824239&gt; //32986 确实是进程 【但是该进程会有一个主线程的】 socket 惊群效应 【】 type a struct{ Name int Test int } 内存|指针了解一些 32986 [00007fc61983e885] accept4(4, &lt;unfinished ...&gt; [processor 2] 32986 [00007fc61982fa17] &lt;... kill resumed&gt;) = 0 &lt;0.000035&gt; //当在终端 bin/sh 进程中按ctrl+c 此时产生中断信号 这个信号的名字是SIGINT，此时系统会给32985，32986两个子进程发送此信号 //这个中断信号的默认动作是终止进程 每个中断信号都有自己的动作【默认，DEF,忽略IGN 信号捕捉函数=信号处理函数=中断信号处理程序】 32985 [00007fc61982fa17] kill(1243, SIGINT &lt;unfinished ...&gt; 32984 [00007fc61982fa17] kill(1242, SIGINT &lt;unfinished ...&gt; 你的多进程编程知识为0，你就得好好补充一下基础知识 32986 [00007fc61982fa17] --- SIGINT {si_signo=SIGINT, si_code=SI_USER, si_pid=1244, si_uid=0} --- 32985 [00007fc61982fa17] &lt;... kill resumed&gt;) = 0 &lt;0.000034&gt; 32984 [00007fc61982fa17] &lt;... kill resumed&gt;) = 0 &lt;0.000035&gt; 32985 [00007fc61982fa17] --- SIGINT {si_signo=SIGINT, si_code=SI_USER, si_pid=1243, si_uid=0} --- 32984 [00007fc61982fa17] --- SIGINT {si_signo=SIGINT, si_code=SI_USER, si_pid=1242, si_uid=0} --- 32986 [????????????????] +++ killed by SIGINT +++ 32984 [????????????????] +++ killed by SIGINT +++ 32985 [????????????????] +++ killed by SIGINT +++ 这3个进程被 中断信号 SIGINT 给终止 2434 [00007f57b1823885] &lt;... wait4 resumed&gt;[{WIFSIGNALED(s) &amp;&amp; WTERMSIG(s) == SIGINT}], WSTOPPED, NULL) = 1242 &lt;8.210335&gt; 2434 [00007f57b1823885] --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_KILLED, si_pid=1242, si_uid=0, si_status=SIGINT, si_utime=3, si_stime=12} --- 进程池带listen的工作流程图 当前进程是被 哪个cpu【核 4核】执行的 ps -eF processor 核心 top taskset c 源码多进程测试示例 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;sys/wait.h&gt; int main(){ pid_t pid = fork(); if (pid==0){ while(1){ printf(&quot;pid=%d doing\\r\\n&quot;,getpid()); } exit(0); } pid = fork(); if (pid==0){ while(1){ printf(&quot;pid=%d doing\\r\\n&quot;,getpid()); } exit(0); } int status=0; int exitSum=0; while(1){ pid = wait(&amp;status); if (pid&gt;0){ exitSum+=1; printf(&quot;pid=%d exit\\r\\n&quot;,pid); } if(exitSum&gt;=2){ break; } } exit(0); } ","link":"https://www.vincent.ac.cn/post/Owh8LqeOM/"},{"title":"swoole学习笔记 进程","content":" 进程 一个程序启动之后就是一个进程了，操作系统也会启动一个主线程，主线程会执行起来 多线程 这个多线程它们是共享一个进程的地址空间 swoole 协程 进程/多进程 多线程 【并发编程】 并发：当线程数量小于或等于cpu核数时 swoole 进程树 swoole 主进程fd目录下的文件说明 阻塞与非阻塞 非阻塞的文件描述符号：非阻塞IO 异步 ajax [前端] 回调 epoll内核事件表 【红黑树】 swoole 各进程/线程的工作流程 16810 主进程/主线程 【7，8】互相通信 [1] 9 epoll file监听到客户端连接事件 16810 [00007efdb24b552d] epoll_pwait(9, [{EPOLLIN, {u32=2612761472, u64=94788246016896}}], 4096, 999, NULL, 8) = 1 &lt;0.934321&gt; [2] 调用accept 系统函数得到客户端的连接文件描述符号为12 16810 [00007efdb24e9885] accept4(4, {sa_family=AF_INET, sin_port=htons(59874), sin_addr=inet_addr(&quot;172.17.0.1&quot;)}, [120-&gt;16], SOCK_CLOEXEC|SOCK_NONBLOCK) = 12 &lt;0.000511&gt; 16810 [00007efdb24b2af7] fcntl(7, F_GETFL) = 0x802 (flags O_RDWR|O_NONBLOCK) &lt;0.000015&gt; [3] 把unix socket 文件描述符7 设置为非阻塞方式 16810 [00007efdb24b2af7] fcntl(7, F_SETFL, O_RDWR|O_NONBLOCK) = 0 &lt;0.000015&gt; [4] 向unix socket 文件7 写入40个字节 通知 我收到客户端连接上来了 16810 [00007efdb24e9885] sendto(7, &quot;\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\17\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;, 40, 0, NULL, 0) = 40 &lt;0.000200&gt; swoole 开发人员 16812 主线程 【5，6】互相通信 16812 [00007efdb24e9885] &lt;... read resumed&gt;&quot;\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\17\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;, 425952) = 40 &lt;0.000285&gt; 16812 [00007efdb24b550b] epoll_ctl(11, EPOLL_CTL_ADD, 12, {EPOLLIN, {u32=2611736352, u64=94788244991776}}) = 0 &lt;0.000151&gt; [5] 调用writev 系统函数向unix socket 文件描述符6写入40个字节 16812 [00007efdb24e9885] writev(6, [{iov_base=&quot;\\1\\0\\0\\0\\0\\0\\0\\0\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\4\\0\\4\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;, iov_len=40}], 1) = 40 &lt;0.000039&gt; 【7】 监听到12 客户端连接socket 文件描述上的读事件产生 16812 [00007efdb24b552d] epoll_pwait(11, [{EPOLLIN, {u32=2611736352, u64=94788244991776}}], 4096, -1, NULL, 8) = 1 &lt;0.000016&gt; 16812 [00007efdb24b8abd] brk(0x56359bc08000) = 0x56359bc08000 &lt;0.000416&gt; 16812 [00007efdb24e9885] recvfrom(12, &quot;GET /index HTTP/1.1\\r\\nUser-Agent: curl/7.29.0\\r\\nHost: 127.0.0.1:9501\\r\\nAccept: */*\\r\\n\\r\\n&quot;, 65536, 0, NULL, NULL) = 83 &lt;0.000018&gt; [8] 把收到的数据写入unix socket 6 文件 16812 [00007efdb24e9885] writev(6, [{iov_base=&quot;\\1\\0\\0\\0\\0\\0\\0\\0\\2\\0\\0\\0\\0\\0\\0\\0S\\0\\0\\0\\0\\0\\0\\0\\4\\0\\0\\0\\0\\0\\0\\0\\354\\277|\\247\\212.\\330A&quot;, iov_len=40}, {iov_base=&quot;GET /index HTTP/1.1\\r\\nUser-Agent: curl/7.29.0\\r\\nHost: 127.0.0.1:9501\\r\\nAccept: */*\\r\\n\\r\\n&quot;, iov_len=83}], 2) = 123 &lt;0.000022&gt; [10] 接收worker 进程处理好的数据 unix socket 8 16812 [00007efdb24b552d] epoll_pwait(11, [{EPOLLIN, {u32=2611735040, u64=94788244990464}}], 4096, -1, NULL, 8) = 1 &lt;0.000857&gt; 16812 [00007efdb24e9885] read(8, &quot;\\1\\0\\0\\0\\0\\0\\0\\0\\1\\0\\0\\0\\0\\0\\0\\0[\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0Server: GET /index HTTP/1.1\\r\\nUser-Agent: curl/7.29.0\\r\\nHost: 127.0.0.1:9501\\r\\nAccept: */*\\r\\n\\r\\n&quot;, 425952) = 131 &lt;0.000020&gt; [11] 把worker进程的数据发送给客户端 16812 [00007efdb24e9885] sendto(12, &quot;Server: GET /index HTTP/1.1\\r\\nUser-Agent: curl/7.29.0\\r\\nHost: 127.0.0.1:9501\\r\\nAccept: */*\\r\\n\\r\\n&quot;, 91, 0, NULL, 0) = 91 &lt;0.000116&gt; [12] 客户端主动关闭产生了EPOLLIN事件，此时调用recvfrom 系统函数返回的值是0 【网络编程】 16812 [00007efdb24b552d] &lt;... epoll_pwait resumed&gt;[{EPOLLIN, {u32=2611736352, u64=94788244991776}}], 4096, -1, NULL, 8) = 1 &lt;1.155510&gt; 16812 [00007efdb24e9885] recvfrom(12, &quot;&quot;, 65536, 0, NULL, NULL) = 0 &lt;0.000426&gt; 表示对端已经关闭 把12客户端连接移除epoll 内核事件表 16812 [00007efdb24b550b] epoll_ctl(11, EPOLL_CTL_DEL, 12, NULL) = 0 &lt;0.000045&gt; 【13】 向unix socket 6 写入40个字节的数据 16812 [00007efdb24e9885] writev(6, [{iov_base=&quot;\\1\\0\\0\\0\\0\\0\\0\\0\\3\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\\4\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;, iov_len=40}], 1) = 40 &lt;0.000051&gt; 彻底的关闭客户端连接了 16812 [00007efdb24b552d] epoll_pwait(11, [{EPOLLIN, {u32=2611735040, u64=94788244990464}}], 4096, -1, NULL, 8) = 1 &lt;0.000653&gt; 16812 [00007efdb24e9885] read(8, &quot;\\1\\0\\0\\0\\0\\0\\0\\0\\2\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;, 425952) = 40 &lt;0.000025&gt; 16812 [00007efdb24e9885] read(8, 0x7efda639a020, 425952) = -1 EAGAIN (Resource temporarily unavailable) &lt;0.000015&gt; 最后一步 已经收到worker进程的响应了【表示worker已经执行了close事件回调函数了，我可以放心的close(12)】 16812 [00007efdb24e9885] close(12) = 0 &lt;0.000250&gt; 16813 进程 16813 [00007efdb24b552d] epoll_pwait(9, [{EPOLLIN, {u32=2611727744, u64=94788244983168}}], 4096, -1, NULL, 8) = 1 &lt;21.262930&gt; [6] worker进程从unix socket 5 读取40个字节 并且调用connect事件回调函数 16813 [00007efdb24e9885] recvfrom(5, &quot;\\1\\0\\0\\0\\0\\0\\0\\0\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\4\\0\\4\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;, 40, MSG_PEEK, NULL, NULL) = 40 &lt;0.000029&gt; 16813 [00007efdb24e9885] write(1, &quot;Client: Connect.\\n&quot;, 17) = 17 &lt;0.000509&gt; 【9】 从unix sockeet 5 读取123个字节的数据 16813 [00007efdb24e9885] read(5, &quot;\\1\\0\\0\\0\\0\\0\\0\\0\\2\\0\\0\\0\\0\\0\\0\\0S\\0\\0\\0\\0\\0\\0\\0\\4\\0\\0\\0\\0\\0\\0\\0\\354\\277|\\247\\212.\\330AGET /index HTTP/1.1\\r\\nUser-Agent: curl/7.29.0\\r\\nHost: 127.0.0.1:9501\\r\\nAccept: */*\\r\\n\\r\\n&quot;, 425952) = 123 &lt;0.000018&gt; 调用receive 事件回调函数 16813 [00007efdb24e9885] write(1, &quot;\\346\\224\\266\\345\\210\\260\\346\\225\\260\\346\\215\\256GET /index HTTP/1.1\\r\\nUser-Agent: curl/7.29.0\\r\\nHost: 127.0.0.1:9501\\r\\nAccept: */*\\r\\n\\r\\n\\r\\n&quot;, 97) = 97 &lt;0.000043&gt; 在receive 事件回调函数处理完相关业务后，返回 unix socket 7 16813 [00007efdb24e9885] writev(7, [{iov_base=&quot;\\1\\0\\0\\0\\0\\0\\0\\0\\1\\0\\0\\0\\0\\0\\0\\0[\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;, iov_len=40}, {iov_base=&quot;Server: GET /index HTTP/1.1\\r\\nUser-Agent: curl/7.29.0\\r\\nHost: 127.0.0.1:9501\\r\\nAccept: */*\\r\\n\\r\\n&quot;, iov_len=91}], 2) = 131 &lt;0.000051&gt; [14] unix socket 5产生读事件接收到了40个字节 16813 [00007efdb24b552d] epoll_pwait(9, [{EPOLLIN, {u32=2611727744, u64=94788244983168}}], 4096, -1, NULL, 8) = 1 &lt;1.157044&gt; 16813 [00007efdb24e9885] recvfrom(5, &quot;\\1\\0\\0\\0\\0\\0\\0\\0\\3\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\\4\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;, 40, MSG_PEEK, NULL, NULL) = 40 &lt;0.000018&gt; 16813 [00007efdb24e9885] read(5, &quot;\\1\\0\\0\\0\\0\\0\\0\\0\\3\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\\4\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;, 425952) = 40 &lt;0.000018&gt; 调用Close事件回调函数 16813 [00007efdb24e9885] write(1, &quot;Client: Close.\\n&quot;, 15) = 15 &lt;0.000071&gt; 16813 [00007efdb24cad59] munmap(0x7efda5d1d000, 2101248) = 0 &lt;0.000033&gt; 16813 [00007efdb24e9885] writev(7, [{iov_base=&quot;\\1\\0\\0\\0\\0\\0\\0\\0\\2\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&quot;, iov_len=40}], 1) = 40 &lt;0.000029&gt; http协议 GET /index HTTP/1.1\\r\\nUser-Agent: curl/7.29.0\\r\\nHost: 127.0.0.1:9501\\r\\nAccept: */*\\r\\n\\r\\n swoole 各进程以及事件回调函数解释 swoole http 协议简单说明 ","link":"https://www.vincent.ac.cn/post/DpMO3vgV-/"},{"title":"转载 - 你心中最高大上最牛X的技术到底是什么","content":" 高以下为基，贵以贱为本 互联网技术的核心根基就是TCP/IP,TCP/IP的实现依赖于Linux socket API【我们的项目大部分运行在上面】 没有它们各种高大上牛逼的技术就无从建立起来。而这根基对大家所用的java,go,py,php,c,c++,nodejs...都是一样的，只不过是基于Linux api做了各种各样的封装百家争鸣，百花齐放，跟易经里的阴阳构成64卦一样，当你刚开始撸程序时，可能并不会觉得基础的重要性，甚至可能几年内一直是框架crud boy,你并不会察觉到基础核心Linux socket api【一般来说linux内核的api很少变动，比较稳定，国内linux内核开发工程师估计也不会天天没事干，天天修改linux内核api】! 每天被各种新技术词汇遮蔽双眼，而基础知识你一直的错失和鄙视低估，就想一步飞龙在天，达到九五爻之位，并没有“以下为基” “以贱为本” 甚至对于其它知识点你都持“下贱之态”只想与天齐名，从不脚踏实地从坤做起。 先给总结图 你再看下面的内容 下面就是要告诉你所谓的牛逼技术到底是什么回事！！！ 我们测试一下数据库，java,python,go,c/c++,php,redis,docker进行测试【测完你会发现点东西】 然后你再看图比较好 mysql 先测试数据库接收数据时是不是用了Linux网络 socket API 好启动了，没有什么可说的，ELF文件启动。 .ibd是创建数据表时生成的文件，没啥可说的，DBA专业都知道 我画线的地方调用了ACCEPT SOCKET API函数 调用了SENDTO,RECVFROM SOCKET API 函数 mysql怎么实现我们管不着，但是数据来回的传输依赖于LINUX SOCKET API，这些都是网络接口API 调用了系统其它API函数库，我们看一下accept,sendto,recvfrom,setsockopt,getsockopt read,write,epoll相关函数 redis 数据库 启动redis 测试 epoll_wait 得到就绪的文件描述符读事件返回，然后调用read，其实跟RECVFROM功能一样它的数据是：3rn$3rnsetrn4rnbfzsrn5rn10000rn 这一堆数据被各种大佬称为 redis的二进制通信请求协议！！！返回是+OKrn 它们的数据来回传输大部分用read,write函数来实现 docker dockerd服务ELF文件调用的linux api相关函数库 启动docker服务，跟mysql一样默认启动一堆进程和线程 相关命令运行【对不起，我不喜欢背东西，你要是面试我时，问我docker有哪些命令选项，对不起我回家种地放牛了】 来用下测试 运行过程 都在调用connect,socket,getpeerame,setsockopt,getsockopt,accept,sendto等LINUX SOCKET API函数 docker调用的LINUX API 函数库 go语言写个网络程序 我直接复制粘粘给你运行对不起我背不了函数,要用就直接复制粘粘就好了 go ELF 文件 来运行那个大家认为的源码文件 先运行哪个函数，你自己看着办哦 重点 熟悉的一批，socket 创建socket文件描述符，然后命名【把ip,端口绑定到此文件上】，然后监听，并阻塞在accept函数上 好了，go就这样子，它封装的比较骚，go elf编译器封装的牛逼，语法换了一套就称为编译型语言了。 python语言也写个网络程序测试下 py的语法就是好，随便一撸就可以了，简直是粗暴又骚，语法嘛就这样，长得跟少妇一样 来先认识一下python elf文件 毕竟好多爬虫大佬可能没有见过 .php .py .go .java里的东西只是个文本内容，你们嘛叫源码，我没有文化，只能叫ascii text _ 启动测试 有没有发现，熟悉的一批 好了，到这里够意思了。 这么简单的语言，你去学语法就行了，简单又粗暴谁不喜欢呢。我都喜欢。 _ java 语言网络程序测试 测试源码 cat GreetingServer.java import java.net.*; import java.io.*; public class GreetingServer extends Thread { private ServerSocket serverSocket; public GreetingServer(int port) throws IOException { serverSocket = new ServerSocket(port); serverSocket.setSoTimeout(100000000); } public void run() { while(true) { try { System.out.println(&quot;等待远程连接，端口号为：&quot; + serverSocket.getLocalPort() + &quot;...&quot;); Socket server = serverSocket.accept(); System.out.println(&quot;远程主机地址：&quot; + server.getRemoteSocketAddress()); DataInputStream in = new DataInputStream(server.getInputStream()); System.out.println(in.readUTF()); DataOutputStream out = new DataOutputStream(server.getOutputStream()); out.writeUTF(&quot;谢谢连接我：&quot; + server.getLocalSocketAddress() + &quot;\\nGoodbye!&quot;); server.close(); }catch(SocketTimeoutException s) { System.out.println(&quot;Socket timed out!&quot;); break; }catch(IOException e) { e.printStackTrace(); break; } } } public static void main(String [] args) { int port = Integer.parseInt(args[0]); try { Thread t = new GreetingServer(port); t.run(); }catch(IOException e) { e.printStackTrace(); } } } 看一下java elf文件，我相信java大佬肯定知道我就不费话了 编译一下 我没有学过java,但是看一下报错就知道了，对不对，这么明显的提示，我phper都晓得 _ 编译ok 编译好是啥文件 启动java程序开始测试 有没有发现，熟悉的一批 好了，就这么多就行了，没有必要再截图了。 看接下，我们撸c[c++一样] 你们应该看出点熟悉的地方了 int main(int argc,char *argv[]) { if(argc&lt;=2){ printf(&quot;useage:%s ip_address port_number\\n&quot;,basename(argv[0])); return 1; } const char *ip = argv[1]; int port = atoi(argv[2]); int ret = 0; struct sockaddr_in address; bzero(&amp;address,sizeof(address)); address.sin_family = AF_INET; inet_pton(AF_INET,ip,&amp;address.sin_addr); address.sin_port = htons(port); int listenfd = socket(PF_INET,SOCK_STREAM,0); assert(listenfd&gt;=0); ret = bind(listenfd,(struct sockaddr*)&amp;address,sizeof(address)); assert(ret!=-1); ret = listen(listenfd,5); assert(ret!=-1); bzero(&amp;address,sizeof(address)); address.sin_family = AF_INET; inet_pton(AF_INET,ip,&amp;address.sin_addr); address.sin_port = htons(port); int udpfd = socket(PF_INET,SOCK_DGRAM,0); assert(udpfd&gt;=0); ret = bind(udpfd,(struct sockaddr*)&amp;address,sizeof(address)); assert(ret!=-1); struct epoll_event events[MAX_EVENT_NUMBER]; int epollfd = epoll_create(5); assert(epollfd!=-1); addfd(epollfd,listenfd); addfd(epollfd,udpfd); while(1){ int number = epoll_wait(epollfd,events,MAX_EVENT_NUMBER,-1); if(number&lt;0){ printf(&quot;epoll failre\\n&quot;); break; } for(int i=0;i&lt;number;i++){ int sockfd = events[i].data.fd; if(sockfd ==listenfd){ struct sockaddr_in client_address; socklen_t client_addrlength = sizeof(client_address); int connfd = accept(listenfd,(struct sockaddr*)&amp;client_address,&amp;client_addrlength); addfd(epollfd,connfd); } else if(sockfd == udpfd){ char buf[UDP_BUFFER_SIZE]; memset(buf,0,UDP_BUFFER_SIZE); struct sockaddr_in client_address; socklen_t client_addrlength = sizeof(client_address); ret = recvfrom(udpfd,buf,UDP_BUFFER_SIZE-1,0,(struct sockaddr*)&amp;client_address,&amp;client_addrlength); if(ret&gt;0){ sendto(udpfd,buf,UDP_BUFFER_SIZE-1,0,(struct sockaddr*)&amp;client_address,client_addrlength); } } else if(events[i].events &amp; EPOLLIN){ char buf[TCP_BUFFER_SIZE]; while(1){ memset(buf,0,TCP_BUFFER_SIZE); ret = recv(sockfd,buf,TCP_BUFFER_SIZE-1,0); if(ret&lt;0){ if((errno==EAGAIN)||(errno=EWOULDBLOCK)){ break; } close(sockfd); break; } else if(ret==0){ close(sockfd); } else{ send(sockfd,buf,ret,0); } } }else{ printf(&quot;something else happened\\n&quot;); } } } close(listenfd); return 0; } 然后编译，编译好就这样 测试 好了，都不用我废话了，接下来还是测试下php吧，我觉得，虽然有的朋友觉得php咋样咋样，拍黄片嘛，在打黄打非的压力之下当然没啥好名声了。 php 网络程序测试 看下php elf文件 启动并测试跟踪 好了，不用我废话，大家也知道是怎么回事了。 这些api函数怎么用呢？ man socket linux socket api 是所有语言，数据库等应用的核心低层技术知识，你框架掌握的再6，没有多少意义，语言掌握得再6也只是工具 分布式，集群，高大上的技术都要TCP/IP支持，而它的实现就是网络编程，各语言写法不同，但是核心基础知识没有变化，正所谓天下大事必作于细天下难事必作于易，一上来撸c/c++,java如果不合适你，那么上来就撸PHP掌握了共通的知识再换语言又何妨呢？ ———————————————— 版权声明：本文为博主「北风之神」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。 原文链接：https://segmentfault.com/a/1190000038782113 ","link":"https://www.vincent.ac.cn/post/c1-aEdImo/"},{"title":"Redis击穿、 穿透、 雪崩是什么？","content":"击穿 发生了高并发请求，访问某一个key到redis，但是刚刚好这么一瞬间key消失了（过期、LRU、LFU...），此时key的消失造成并发访问DB。 解决方案 redis是一个单进程单实例的。所以并发请求都死排着队进入redis的，所以分为以下几个步骤： 第一个请求进来发现没有key，立刻使用setNx(相当于一把锁)； 如果设置成功访问数据库，失败则睡眠一会再访问； 当然上面的方法会产生死锁的可能（如果第一个请求挂了），解决方法： 设置锁的同时添加过期时间，如果超时自动释放锁资源； 这里也存在一个问题那就是过期时间设置大小的问题，设置大了，如果第一个请求挂了，会导致后面的大量请求等待时间过长而超时，如果设置时间过短，自己没处理完别的请求进来了，这样循环下去，这也会存在一定的并发请求。 解决过期时间长短问题： 可以开启一个守护线程来监控数据有没有从DB中获取出来放入缓存，如果没有完成则给锁续时间； 可以使用已经封装好的 Redisson； 同时也看到了redis实现分布式锁的复杂性，所以这里你也可以使用zookeeper来实现分布式锁； 穿透 从业务接受查询的，是系统根本不存在的数据，redis中没有，DB中也没有，这样请求就直接打到DB了 解决方案 使用布隆过滤器，这里你可以有几种集成的方案： 直接放在客户端算法+bitmap； 客户端只包含布隆算法，把bitmap放在redis中； redis集成布隆模块； 当然布隆过滤器存在一个问题，就是只能添加不能删除，如果你可以容忍这个问题，ok 直接使用没问题，如果不能容忍，可以使用布谷鸟等其他过滤器来替换 雪崩 大量的key同时失效或者redis故障宕机，间接造成大量的访问打到DB 解决方案 不同的诱因，应对的策略也会不同 大量数据同时过期 针对大量数据同时过期而引发的缓存雪崩问题，常见的应对方法有下面这几种： 均匀设置过期时间； 互斥锁； 双 key 策略； 后台更新缓存； redis 故障宕机 针对 redis 故障宕机而引发的缓存雪崩问题，常见的应对方法有下面这几种： 服务熔断或请求限流机制； 构建 redis 缓存高可靠集群； 总结 无论是redis的击穿、穿透还是雪崩，他们产生的前提都是存在并发请求，并且redis都未拦截到请求，导致大量的请求到达数据库，从整体的一个角度看我们主要解决的就是阻止大量的并发请求同时到达数据库。 ","link":"https://www.vincent.ac.cn/post/WKbkebv18/"},{"title":"PHP 并发场景的几种解决方案","content":" 在秒杀，抢购等并发场景下，可能会出现超卖的现象，在 PHP 语言中并没有原生提供并发的解决方案，因此就需要借助其他方式来实现并发控制。 列出常见的解决方案有： 使用队列，额外起一个进程处理队列，并发请求都放到队列中，由额外进程串行处理，并发问题就不存在了，但是要额外进程支持以及处理延迟严重，本文不先不讨论这种方法。 利用数据库事务特征，做原子更新，此方法需要依赖数据库的事务特性。 借助文件排他锁，在处理下单请求的时候，用 flock 锁定一个文件，成功拿到锁的才能处理订单。 利用 Redis 事务特征 redis 事务是原子操作，可以保证订单处理的过程中数据没有被其它并发的进程修改。 示例代码： &lt;?php $http = new swoole_http_server(&quot;0.0.0.0&quot;, 9509); // 监听 9509 $http-&gt;set(array( 'reactor_num' =&gt; 2, //reactor thread num 'worker_num' =&gt; 4 //worker process num )); $http-&gt;on('request', function (swoole_http_request $request, swoole_http_response $response) { $uniqid = uniqid('uid-', TRUE); // 模拟唯一用户ID $redis = new Redis(); $redis-&gt;connect('127.0.0.1', 6379); // 连接 redis $redis-&gt;watch('rest_count'); // 监测 rest_count 是否被其它的进程更改 $rest_count = intval($redis-&gt;get(&quot;rest_count&quot;)); // 模拟唯一订单ID if ($rest_count &gt; 0){ $value = &quot;{$rest_count}-{$uniqid}&quot;; // 表示当前订单，被当前用户抢到了 // do something ... 主要是模拟用户抢到单后可能要进行的一些密集运算 $rand = rand(100, 1000000); $sum = 0; for ($i = 0; $i &lt; $rand; $i++) {$sum += $i;} // redis 事务 $redis-&gt;multi(); $redis-&gt;lPush('uniqids', $value); $redis-&gt;decr('rest_count'); $replies = $redis-&gt;exec(); // 执行以上 redis 事务 // 如果 rest_count 的值被其它的并发进程更改了，以上事务将回滚 if (!$replies) { echo &quot;订单 {$value} 回滚&quot; . PHP_EOL; } } $redis-&gt;unwatch(); }); $http-&gt;start(); 使用 ab 测试 ab -t 20 -c 10 http://127.0.0.1:9509/ ...... Concurrency Level: 10 Time taken for tests: 20.005 seconds Complete requests: 17537 Failed requests: 0 Total transferred: 2578380 bytes HTML transferred: 0 bytes Requests per second: 876.62 [#/sec] (mean) Time per request: 11.407 [ms] (mean) Time per request: 1.141 [ms] (mean, across all concurrent requests) Transfer rate: 125.86 [Kbytes/sec] received ...... 利用文件排他锁 (阻塞模式) 阻塞模式下，如果进程在获取文件排他锁时，其它进程正在占用锁的话，此进程会挂起等待其它进程释放锁后，并自己获取到锁后，再往下执行。 示例代码： &lt;?php $http = new swoole_http_server(&quot;0.0.0.0&quot;, 9510); $http-&gt;set(array( 'reactor_num' =&gt; 2, //reactor thread num 'worker_num' =&gt; 4 //worker process num )); $http-&gt;on('request', function (swoole_http_request $request, swoole_http_response $response) { $uniqid = uniqid('uid-', TRUE); $redis = new Redis(); $redis-&gt;connect('127.0.0.1', 6379); $fp = fopen(&quot;lock.txt&quot;, &quot;w+&quot;); // 阻塞(等待)模式， 要取得独占锁定（写入的程序） if (flock($fp,LOCK_EX)) { //锁定当前指针 // 成功取得锁后，放心处理订单 $rest_count = intval($redis-&gt;get(&quot;rest_count&quot;)); $value = &quot;{$rest_count}-{$uniqid}&quot;; if ($rest_count &gt; 0) { // do something ... $rand = rand(100, 1000000); $sum = 0; for ($i = 0; $i &lt; $rand; $i++) {$sum += $i;} $redis-&gt;lPush('uniqids', $value); $redis-&gt;decr('rest_count'); } // 订单处理完成后，再释放锁 flock($fp, LOCK_UN); } fclose($fp); }); $http-&gt;start(); 使用 ab 测试 ab -t 20 -c 10 http://127.0.0.1:9510/ ...... Concurrency Level: 10 Time taken for tests: 20.003 seconds Complete requests: 8205 Failed requests: 0 Total transferred: 1206282 bytes HTML transferred: 0 bytes Requests per second: 410.19 [#/sec] (mean) Time per request: 24.379 [ms] (mean) Time per request: 2.438 [ms] (mean, across all concurrent requests) Transfer rate: 58.89 [Kbytes/sec] received ...... 利用文件排他锁 (非阻塞模式) 非阻塞模式下，如果进程在获取文件排他锁时，其它进程正在占用锁的话，此进程会马上判断获取锁失败，并且继续往下执行。 示例代码： &lt;?php $http = new swoole_http_server(&quot;0.0.0.0&quot;, 9511); $http-&gt;set(array( 'reactor_num' =&gt; 2, //reactor thread num 'worker_num' =&gt; 4 //worker process num )); $http-&gt;on('request', function (swoole_http_request $request, swoole_http_response $response) { $uniqid = uniqid('uid-', TRUE); $redis = new Redis(); $redis-&gt;connect('127.0.0.1', 6379); $fp = fopen(&quot;lock.txt&quot;, &quot;w+&quot;); // 非阻塞模式， 如果不希望 flock() 在锁定时堵塞，则给 lock 加上 LOCK_NB if(flock($fp,LOCK_EX | LOCK_NB)) //锁定当前指针 { // 成功取得锁后，放心处理订单 $rest_count = intval($redis-&gt;get(&quot;rest_count&quot;)); $value = &quot;{$rest_count}-{$uniqid}&quot;; if($rest_count &gt; 0){ // do something ... $rand = rand(100, 1000000); $sum=0; for ($i=0;$i&lt;$rand;$i++){ $sum+=$i; } $redis-&gt;lPush('uniqids', $value); $redis-&gt;decr('rest_count'); } // 订单处理完成后，再释放锁 flock($fp,LOCK_UN); } else { // 如果获取锁失败，马上进入这里执行 echo &quot;{$uniqid} - 系统繁忙，请稍后再试&quot;.PHP_EOL; } fclose($fp); }); $http-&gt;start(); 使用 ab 测试 ab -t 20 -c 10 http://127.0.0.1:9511/ ...... Concurrency Level: 10 Time taken for tests: 20.002 seconds Complete requests: 8616 Failed requests: 0 Total transferred: 1266846 bytes HTML transferred: 0 bytes Requests per second: 430.77 [#/sec] (mean) Time per request: 23.214 [ms] (mean) Time per request: 2.321 [ms] (mean, across all concurrent requests) Transfer rate: 61.85 [Kbytes/sec] received ...... 经测试结果对比，redis 事务方式优于文件排他锁方式，而文件排他锁方式中，非阻塞模式优于阻塞模式。 ","link":"https://www.vincent.ac.cn/post/PJQuX6IBZ/"},{"title":"php二分查找的定义","content":"原理 二分查找也成为折半查找，是一种高效率的查找方法 折半查找要求线性表必须采用顺序存储结构，而且表中元素按关键字有序排列 步骤 确定要查找的区间 确定要二分的参照点 区间内选取二分点 根据二分点的值，综合左右间情况以及求见的目的，舍去一般无用的区间 继续在有效区间重复上面的步骤 实现 function binary_search($arr, $number) { if (!is_empty($arr) || empty($arr)) { return -1; } // 初始变量值 $len = count($arr); $lower = 0; $high = $len - 1; // 最低点比最高点大就退出 while ($lower &lt;= $high) { // 以中间点作为参照点比较 $middle = intval(($lower + $high) / 2); if ($arr[$middle] &gt; $number) { // 查找数比参照点小，舍去右边 $high = $middle - 1; } elseif ($arr[$middle] &lt; $number) { // 查找树比参照点大，舍去左边 $lower = $middle + 1; } else { return $middle; } } return -1; } /** * @param array $arr * @param int $number * @param int $lower * @param int $hith */ function binary_search_recursion(&amp;$arr, $number, $lower, $high) { $middle = intval(($lower + $high) / 2); if ($lower &gt; $high) { return -1; } if ($number &gt; $arr[$middle]) { return __FUNCTION__($arr, $number, $middle, $high); } elseif ($number &lt; $arr[$middle]) { return __FUNCTION__($arr, $number, $lower, $middle - 1); } else { return $middle; } } 时间复杂度 有序数组中如果使用暴力的算法去查找，也就是逐个遍历比较，那么时间复杂度是 O (n) 但是，用二分查找后，因为每次可以舍去一半查找区间，所以会将时间复杂度减少到 O (logn)，算法更优。 ","link":"https://www.vincent.ac.cn/post/znewu8Toy/"},{"title":"安利 Slidev - 用Markdown的方式来做PPT","content":" 也许你是代码高手、Markdown写作高手、但你是PPT高手吗？你的成绩有没有被PPT高手抢走过呢？不会作精美PPT是不是很头疼呢? Slidev使用了一种扩展的Markdown格式，使得用户可以仅仅使用纯文本的形式也完成PPT的制作，尤其对于开发者来说，Slidev可以通过代码支持 HTML 和 Vue 组件，可以现场根据演示效果进行编码和修改，开发者可以将精力更多的集中在内容实现上 简单来说，Slidev有如下的功能特点： 📝 Markdown 支持 —— 使用你最喜欢的编辑器和工作流编写 Markdown 文件 🧑‍💻 开发者友好 —— 内置代码高亮、实时编码等功能 🎨 可定制主题 —— 以 npm 包的形式共享、使用主题 🌈 灵活样式 —— 使用 Windi CSS 按需使用的实用类和易用的内嵌样式表 🤹 可交互 —— 无缝嵌入 Vue 组件 🎙 演讲者模式 —— 可以使用另一个窗口，甚至是你的手机来控制幻灯片 🎨 绘图 - 在你的幻灯片上进行绘图和批注 🧮 LaTeX 支持 —— 内置了对 LaTeX 数学公示的支持 📰 图表支持 —— 使用文本描述语言创建图表 🌟 图标 —— 能够直接从任意图标库中获取图标 💻 编辑器 —— 集成的编辑器，或者使用 VS Code 扩展 🎥 演讲录制 —— 内置录制功能和摄像头视图 📤 跨平台 —— 能够导出 PDF、PNG 文件，甚至是一个可以托管的单页应用 ⚡️ 快速 —— 基于 Vite 的即时重载 🛠 可配置 —— 支持使用 Vite 插件、Vue 组件以及任何的 npm 包 repo地址：slidevjs/slidev 文档：Slidev 安装 这个工具是用vue开发的，所以可以通过npm安装： 首先安装14.0以上的node.js：Node.js 然后用npm安装 npm init slidev 过程中会自动安装依赖包，并在当前目录下创建一个slidev的目录，里边有一个slides.md，就在这里边写我们的markdown内容，安装完成后，会自动运行npx slidev ，打开 http://localhost:3030 ，渲染展示slides.md的内容。 ","link":"https://www.vincent.ac.cn/post/rAOhONMqv/"},{"title":"Mac 安装 Jenkins","content":"安装Jenkins 这里使用 brew 命令安装 brew install jenkins Updating Homebrew... ==&gt; Processing wxmac formula rename to wxwidgets ==&gt; Unlinking wxmac ==&gt; Moving wxmac versions to /usr/local/Cellar/wxwidgets ==&gt; Relinking wxwidgets Warning: wxwidgets is outdated! To avoid broken installations, as soon as possible please run: brew upgrade Or, if you're OK with a less reliable fix: brew upgrade wxwidgets ==&gt; Downloading https://mirrors.aliyun.com/homebrew/homebrew-bottles/openjdk%401 ######################################################################## 100.0% ==&gt; Downloading https://mirrors.aliyun.com/homebrew/homebrew-bottles/jenkins-2.3 curl: (22) The requested URL returned error: 404 Warning: Bottle missing, falling back to the default domain... ==&gt; Downloading https://ghcr.io/v2/homebrew/core/jenkins/manifests/2.325 ######################################################################## 100.0% ==&gt; Downloading https://ghcr.io/v2/homebrew/core/jenkins/blobs/sha256:21be7ef923 ==&gt; Downloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh ######################################################################## 100.0% ==&gt; Installing dependencies for jenkins: openjdk@11 ==&gt; Installing jenkins dependency: openjdk@11 ==&gt; Pouring openjdk@11-11.0.12.big_sur.bottle.tar.gz 🍺 /usr/local/Cellar/openjdk@11/11.0.12: 679 files, 297.9MB ==&gt; Installing jenkins ==&gt; Pouring jenkins--2.325.all.bottle.tar.gz ==&gt; Caveats Note: When using launchctl the port will be 8080. To restart jenkins after an upgrade: brew services restart jenkins Or, if you don't want/need a background service you can just run: /usr/local/opt/openjdk@11/bin/java -Dmail.smtp.starttls.enable=true -jar /usr/local/opt/jenkins/libexec/jenkins.war --httpListenAddress=127.0.0.1 --httpPort=8080 ==&gt; Summary 🍺 /usr/local/Cellar/jenkins/2.325: 8 files, 73.6MB ==&gt; Caveats ==&gt; jenkins Note: When using launchctl the port will be 8080. To restart jenkins after an upgrade: brew services restart jenkins Or, if you don't want/need a background service you can just run: /usr/local/opt/openjdk@11/bin/java -Dmail.smtp.starttls.enable=true -jar /usr/local/opt/jenkins/libexec/jenkins.war --httpListenAddress=127.0.0.1 --httpPort=8080 按照提示 执行命令 brew services restart jenkins 来启动 Jenkins brew services restart jenkins ==&gt; Successfully started `jenkins` (label: homebrew.mxcl.jenkins) 相关启动、停止、重启命令 brew services restart jenkins // 重启 brew services start jenkins // 启动 brew services stop jenkins // 停止 初始化 在浏览器打开 localhost:8080 进入解锁页面 密钥这里用命令行的方式获取 cat /Users/vincent/.jenkins/secrets/initialAdminPassword fxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 填写密钥继续 进入插件安装界面 选择安装推荐的插件，等待插件安装完成 如果失败了 就 重试一下，确定网络连接正常就能继续自动安装插件了。 进入管理员账户设定页面 设置完成 点击 【保存并完成】 进入 实例配置页面 到此初始化 jenkins 成功 ","link":"https://www.vincent.ac.cn/post/6DJtUGYm5/"},{"title":"PHP组合模式构建决策树排它网关模式 (三) ","content":"构建决策树 构建年龄与性别的决策器 DecisionData &lt;?php declare(strict_types=1); namespace DecisionTree\\Tree; use DecisionTree\\Model\\Tree\\NodeDecision; class DecisionData { public function age_0_12(): NodeDecision { return new NodeDecision(1, '0-12', 'age', 'between', [0, 12]); } public function age_13_18(): NodeDecision { return new NodeDecision(2, '13-18', 'age', 'between', [13, 18]); } public function age_19_33(): NodeDecision { return new NodeDecision(3, '19-33', 'age', 'between', [19, 33]); } public function age_34_99(): NodeDecision { return new NodeDecision(4, '34-99', 'age', 'between', [34, 99]); } public function gender_man(): NodeDecision { return new NodeDecision(5, '性别男', 'gender', 'eq', 'man'); } public function gender_woman(): NodeDecision { return new NodeDecision(6, '性别女', 'gender', 'eq', 'woman'); } } 构建决策树 LeafTree &lt;?php declare(strict_types=1); namespace DecisionTree\\Tree; use DecisionTree\\Tree\\DecisionData; use DecisionTree\\Model\\Tree\\NextNode; use DecisionTree\\Model\\Tree\\Node; class LeafTree { /** * @var DecisionData|mixed */ private $decisionObj; public function __construct() { $this-&gt;decisionObj = new DecisionData(); } public function get(?Node $parentTreeNode = null): Node { //根节点 $rootNode = new Node(1, 'branch', '根节点'); if ($parentTreeNode) { $rootNode-&gt;setParentId($parentTreeNode-&gt;getId()); } $rootChildOne = new Node(11, 'branch', '男', '男'); $rootChildOne-&gt;setParentId($rootNode-&gt;getId()); $rootChildOne-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;gender_man()); $rootNode-&gt;setChildMap($rootChildOne); // 根节点绑定指向决策1 $rootNextNode1 =new NextNode($rootNode-&gt;getId(), $rootChildOne-&gt;getId()); $rootNextNode1-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;gender_man()); $rootNode-&gt;setNextNodeMap($rootNextNode1); $rootChildOne1 = new Node(111, 'leaf', '男-0-12', '二次元'); $rootChildOne1-&gt;setParentId($rootChildOne-&gt;getId()); $rootChildOne1-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_0_12()); $rootChildOne-&gt;setChildMap($rootChildOne1); // 子节点1绑定指向决策 $rootChildNextNode1 = new NextNode($rootChildOne-&gt;getId(), $rootChildOne1-&gt;getId()); $rootChildNextNode1-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_0_12()); $rootChildOne-&gt;setNextNodeMap($rootChildNextNode1); $rootChildOne2 = new Node(112, 'leaf', '男-13-18', '学习文具'); $rootChildOne2-&gt;setParentId($rootChildOne-&gt;getId()); $rootChildOne2-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_13_18()); $rootChildOne-&gt;setChildMap($rootChildOne2); // 子节点1绑定指向决策 $rootChildNextNode2 = new NextNode($rootChildOne-&gt;getId(), $rootChildOne2-&gt;getId()); $rootChildNextNode2-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_13_18()); $rootChildOne-&gt;setNextNodeMap($rootChildNextNode2); $rootChildOne3 = new Node(113, 'leaf', '男-19-33', '金融杂志'); $rootChildOne3-&gt;setParentId($rootChildOne-&gt;getId()); $rootChildOne3-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_19_33()); $rootChildOne-&gt;setChildMap($rootChildOne3); // 子节点1绑定指向决策 $rootChildNextNode3 = new NextNode($rootChildOne-&gt;getId(), $rootChildOne3-&gt;getId()); $rootChildNextNode3-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_19_33()); $rootChildOne-&gt;setNextNodeMap($rootChildNextNode3); $rootChildOne4 = new Node(114, 'leaf', '男-34-99', '秃头救星'); $rootChildOne4-&gt;setParentId($rootChildOne-&gt;getId()); $rootChildOne4-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_34_99()); $rootChildOne-&gt;setChildMap($rootChildOne4); // 子节点1绑定指向决策 $rootChildNextNode4 = new NextNode($rootChildOne-&gt;getId(), $rootChildOne4-&gt;getId()); $rootChildNextNode4-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_34_99()); $rootChildOne-&gt;setNextNodeMap($rootChildNextNode4); $rootChildTwo = new Node(12, 'branch', '女', '女'); $rootChildTwo-&gt;setParentId($rootNode-&gt;getId()); $rootChildTwo-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;gender_woman()); $rootNode-&gt;setChildMap($rootChildTwo); // 根节点绑定指向决策2 $rootNextNode2 =new NextNode($rootNode-&gt;getId(), $rootChildTwo-&gt;getId()); $rootNextNode2-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;gender_woman()); $rootNode-&gt;setNextNodeMap($rootNextNode2); $rootChildTwo1 = new Node(121, 'branch', '女-0-12', '芭比娃娃'); $rootChildTwo1-&gt;setParentId($rootChildTwo-&gt;getId()); $rootChildTwo1-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_0_12()); $rootChildTwo-&gt;setChildMap($rootChildTwo1); // 子节点2绑定指向决策 $rootChildNextNode21 = new NextNode($rootChildTwo-&gt;getId(), $rootChildTwo1-&gt;getId()); $rootChildNextNode21-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_0_12()); $rootChildTwo-&gt;setNextNodeMap($rootChildNextNode1); $rootChildTwo2 = new Node(122, 'branch', '女-13-18', '学习用品'); $rootChildTwo2-&gt;setParentId($rootChildTwo-&gt;getId()); $rootChildTwo2-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_13_18()); $rootChildTwo-&gt;setChildMap($rootChildTwo2); // 子节点2绑定指向决策 $rootChildNextNode22 = new NextNode($rootChildTwo-&gt;getId(), $rootChildTwo2-&gt;getId()); $rootChildNextNode22-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_13_18()); $rootChildTwo-&gt;setNextNodeMap($rootChildNextNode22); $rootChildTwo3 = new Node(123, 'branch', '女-19-33', '美妆'); $rootChildTwo3-&gt;setParentId($rootChildTwo-&gt;getId()); $rootChildTwo3-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_19_33()); $rootChildTwo-&gt;setChildMap($rootChildTwo3); // 子节点2绑定指向决策 $rootChildNextNode23 = new NextNode($rootChildTwo-&gt;getId(), $rootChildTwo3-&gt;getId()); $rootChildNextNode23-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_19_33()); $rootChildTwo-&gt;setNextNodeMap($rootChildNextNode23); $rootChildTwo4 = new Node(124, 'branch', '女-34-99', '母婴'); $rootChildTwo4-&gt;setParentId($rootChildTwo-&gt;getId()); $rootChildTwo4-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_34_99()); $rootChildTwo-&gt;setChildMap($rootChildTwo4); // 子节点2绑定指向决策 $rootChildNextNode24 = new NextNode($rootChildTwo-&gt;getId(), $rootChildTwo4-&gt;getId()); $rootChildNextNode24-&gt;setNodeDecisionMap($this-&gt;decisionObj-&gt;age_34_99()); $rootChildTwo-&gt;setNextNodeMap($rootChildNextNode24); return $rootNode; } } TopSdk &lt;?php date_default_timezone_set('Asia/Shanghai'); if (!defined(&quot;TOP_AUTOLOADER_PATH&quot;)) { define(&quot;TOP_AUTOLOADER_PATH&quot;, dirname(__FILE__)); } /** * 注册autoLoader,此注册autoLoader只加载top文件 * 不要删除，除非你自己加载文件。 **/ require(&quot;Autoloader.php&quot;); 测试 test.php &lt;?php include &quot;./src/TopSdk.php&quot;; use DecisionTree\\Service\\ExclusiveService; use DecisionTree\\Tree\\LeafTree; $run = new ExclusiveService(); $node = (new LeafTree())-&gt;get(); $userData = [ 'id' =&gt; 1, 'age' =&gt; &quot;33&quot;, &quot;gender&quot; =&gt; &quot;man&quot; ]; $result = $run-&gt;process($node, $userData); $userData = [ 'id' =&gt; 2, 'age' =&gt; &quot;33&quot;, &quot;gender&quot; =&gt; &quot;woman&quot; ]; $result = $run-&gt;process($node, $userData); $userData = [ 'id' =&gt; 3, 'age' =&gt; &quot;11&quot;, &quot;gender&quot; =&gt; &quot;woman&quot; ]; $result = $run-&gt;process($node, $userData); $userData = [ 'id' =&gt; 4, 'age' =&gt; &quot;11&quot;, &quot;gender&quot; =&gt; &quot;man&quot; ]; $result = $run-&gt;process($node, $userData); $userData = [ 'id' =&gt; 5, 'age' =&gt; &quot;13&quot;, &quot;gender&quot; =&gt; &quot;woman&quot; ]; $result = $run-&gt;process($node, $userData); $userData = [ 'id' =&gt; 6, 'age' =&gt; &quot;13&quot;, &quot;gender&quot; =&gt; &quot;man&quot; ]; $result = $run-&gt;process($node, $userData); $userData = [ 'id' =&gt; 7, 'age' =&gt; &quot;66&quot;, &quot;gender&quot; =&gt; &quot;woman&quot; ]; $result = $run-&gt;process($node, $userData); $userData = [ 'id' =&gt; 8, 'age' =&gt; &quot;66&quot;, &quot;gender&quot; =&gt; &quot;man&quot; ]; $result = $run-&gt;process($node, $userData); 测试结果 [Running] php &quot;/Users/vincent/LocalProject/DecisionTreeDemo/test.php&quot; string(91) &quot;用户id：1，当前节点id：1，下一节点id：11，决策名：男，决策值：男&quot; string(108) &quot;用户id：1，当前节点id：11，下一节点id：113，决策名：男-19-33，决策值：金融杂志&quot; string(91) &quot;用户id：2，当前节点id：1，下一节点id：12，决策名：女，决策值：女&quot; string(102) &quot;用户id：2，当前节点id：12，下一节点id：123，决策名：女-19-33，决策值：美妆&quot; string(91) &quot;用户id：3，当前节点id：1，下一节点id：12，决策名：女，决策值：女&quot; string(91) &quot;用户id：4，当前节点id：1，下一节点id：11，决策名：男，决策值：男&quot; string(104) &quot;用户id：4，当前节点id：11，下一节点id：111，决策名：男-0-12，决策值：二次元&quot; string(91) &quot;用户id：5，当前节点id：1，下一节点id：12，决策名：女，决策值：女&quot; string(108) &quot;用户id：5，当前节点id：12，下一节点id：122，决策名：女-13-18，决策值：学习用品&quot; string(91) &quot;用户id：6，当前节点id：1，下一节点id：11，决策名：男，决策值：男&quot; string(108) &quot;用户id：6，当前节点id：11，下一节点id：112，决策名：男-13-18，决策值：学习文具&quot; string(91) &quot;用户id：7，当前节点id：1，下一节点id：12，决策名：女，决策值：女&quot; string(102) &quot;用户id：7，当前节点id：12，下一节点id：124，决策名：女-34-99，决策值：母婴&quot; string(91) &quot;用户id：8，当前节点id：1，下一节点id：11，决策名：男，决策值：男&quot; string(108) &quot;用户id：8，当前节点id：11，下一节点id：114，决策名：男-34-99，决策值：秃头救星&quot; [Done] exited with code=0 in 0.149 seconds 组合模式结构 ","link":"https://www.vincent.ac.cn/post/wlSst96pj/"},{"title":"PHP组合模式构建决策树排它网关模式 (二) ","content":" 上篇文章简单介绍了组合模式、原理、定义了模型接下来就开始写 决策逻辑吧 决策器 决策器接口 &lt;?php declare(strict_types=1); namespace DecisionTree\\Interfaces; use DecisionTree\\Model\\Tree\\NodeDecision; interface LogicDecisionInterface { /** * 获取决策值 * * @param array $data 用户数据 * * @return string */ public function getDecisionValue(array $data): string; /** * 过滤出节点决策. * * @param string $decisionValue * @param NodeDecision $treeNodeDecision * * @return bool */ public function filterDecisionNode(string $decisionValue, NodeDecision $treeNodeDecision): bool; } 基础决策器 &lt;?php declare(strict_types=1); namespace DecisionTree\\Model\\Logic; use DecisionTree\\Interfaces\\LogicDecisionInterface; use DecisionTree\\Model\\Tree\\NodeDecision; abstract class AbstractLogic implements LogicDecisionInterface { protected string $key; public function __construct(string $key) { $this-&gt;key = $key; } /** * 过滤出节点决策. * * @param string $decisionValue * @param NodeDecision $treeNodeDecision * * @return bool */ public function filterDecisionNode( string $decisionValue, NodeDecision $treeNodeDecision ): bool { return $this-&gt;filterDecisionByType($decisionValue, $treeNodeDecision); } /** * @param string $decisionValue 决策值 * @param NodeDecision $treeNodeDecision 节点决策 * * @return bool */ public function filterDecisionByType( string $decisionValue, NodeDecision $treeNodeDecision ): bool { switch ($treeNodeDecision-&gt;getType()) { case 'eq': $decision = $decisionValue == $treeNodeDecision-&gt;getValue(); break; case 'gt': $decision = $decisionValue &gt; $treeNodeDecision-&gt;getValue(); break; case 'gte': $decision = $decisionValue &gt;= $treeNodeDecision-&gt;getValue(); break; case 'lt': $decision = $decisionValue &lt; $treeNodeDecision-&gt;getValue(); break; case 'lte': $decision = $decisionValue &lt;= $treeNodeDecision-&gt;getValue(); break; case 'between': $decision = $decisionValue &gt;= $treeNodeDecision-&gt;getValue()[0] &amp;&amp; $decisionValue &lt;= $treeNodeDecision-&gt;getValue()[1]; break; default: $decision = false; break; } return $decision; } } 性别决策器 &lt;?php declare(strict_types=1); namespace DecisionTree\\Model\\Logic; class AgeLogic extends AbstractLogic { public function getDecisionValue(array $data): string { return $data['age']; } } 年龄决策器 &lt;?php declare(strict_types=1); namespace DecisionTree\\Model\\Logic; class GenderLogic extends AbstractLogic { public function getDecisionValue(array $data): string { return $data['gender']; } } 决策验证器 决策验证器服务接口 ImplementInterface &lt;?php declare(strict_types=1); namespace DecisionTree\\Interfaces; interface ImplementInterface { public function process(array $treeNodeDecisionList, $data): bool; public function getLogicDecision(?string $decisionKey = null): LogicDecisionInterface; } 决策验证器基础服务 AbstractImplementService &lt;?php declare(strict_types=1); namespace DecisionTree\\Service\\Implement; use DecisionTree\\Interfaces\\ImplementInterface; use DecisionTree\\Interfaces\\LogicDecisionInterface; use Exception; abstract class AbstractImplementService implements ImplementInterface { protected array $logicDecisionMap; protected string $decisionKey = 'default'; protected array $logicDecisions; public function __construct(array $logic) { $this-&gt;logicDecisionMap = $logic; } public function getLogicDecision(?string $decisionKey = null): LogicDecisionInterface { $decisionKey = $decisionKey ?? $this-&gt;defaultDecisionKey(); if (empty($this-&gt;logicDecisionMap[$decisionKey])) { throw new Exception(&quot;Does not support this LogicDecision driver&quot;, 500); } return $this-&gt;logicDecisions[$decisionKey] ?? $this-&gt;logicDecisions[$decisionKey] = new $this-&gt;logicDecisionMap[$decisionKey]($decisionKey); } protected function defaultDecisionKey(): string { return $this-&gt;decisionKey; } } 默认决策验证器 DefaultService &lt;?php declare(strict_types=1); namespace DecisionTree\\Service\\Implement; use DecisionTree\\Model\\Tree\\NodeDecision; class DefaultService extends AbstractImplementService { public function process(array $treeNodeDecisionList, $data): bool { /** @var NodeDecision $treeNodeDecision */ foreach ($treeNodeDecisionList as $treeNodeDecision) { $logicDecision = $this-&gt;getLogicDecision($treeNodeDecision-&gt;getKey()); //获取需要决策的值 $decisionValue = $logicDecision-&gt;getDecisionValue($data); if ($logicDecision-&gt;filterDecisionNode($decisionValue, $treeNodeDecision)) { continue; } return false; } return true; } } 决策树 决策树服务接口 &lt;?php declare(strict_types=1); namespace DecisionTree\\Interfaces; use DecisionTree\\Model\\Tree\\Node; use DecisionTree\\Model\\Tree\\Result; /** * 决策树服务接口. */ interface DecisionTreeInterface { public function process($node, $data): Result; public function runNode($node, $data, &amp;$resultNode): bool; public function findNextNode(Node $node, $data): ?Node; } 决策树基础服务 &lt;?php declare(strict_types=1); namespace DecisionTree\\Service; use DecisionTree\\Interfaces\\DecisionTreeInterface; use DecisionTree\\Interfaces\\ImplementInterface; use DecisionTree\\Model\\Tree\\Node; abstract class AbstractDecisionService implements DecisionTreeInterface { protected ImplementInterface $implement; /** * AbstractBiGuard constructor. */ public function __construct( ImplementInterface $implement ) { $this-&gt;implement = $implement; } /** * 执行节点. * * @param Node $node * @param array $data * @param array $resultNode * * @return bool */ public function runNode($node, $data, &amp;$resultNode): bool { while ($node !== null) { if (! empty($node-&gt;getNodeDecisionMap()) &amp;&amp; ! $this-&gt;getImplement()-&gt;process($node-&gt;getNodeDecisionMap(), $data) ) { break; } if (! empty($node-&gt;getLabelId())) { $resultNode[$node-&gt;getLabelId()] = $node-&gt;getLabelId(); } $node = $this-&gt;findNextNode($node, $data); } return true; } public function findNextNode(?Node $node = null, $data = []): ?Node { $i = 0; $treeNode = null; $nextNode = $node ? $node-&gt;getNextNode($i) : null; while ($treeNode == null &amp;&amp; $nextNode != null) { ++$i; if (! empty($nextNode-&gt;getNodeDecisionMap()) &amp;&amp; ! $this-&gt;getImplement()-&gt;process($nextNode-&gt;getNodeDecisionMap(), $data) ) { $nextNode = $node-&gt;getNextNode($i); continue; } $treeNode = $node-&gt;getChild($nextNode-&gt;getNextNodeId()); $nextNode = $node-&gt;getNextNode($i); } return $treeNode; } /** * @return ImplementInterface */ public function getImplement(): ImplementInterface { return $this-&gt;implement; } } 决策树服务 &lt;?php declare(strict_types=1); namespace DecisionTree\\Service; use DecisionTree\\Model\\Tree\\Result; use DecisionTree\\Service\\Implement\\DefaultService; class ExclusiveService extends AbstractDecisionService { /** * AbstractBiGuard constructor. */ public function __construct() { $implement = new DefaultService([ 'gender' =&gt; \\DecisionTree\\Model\\Logic\\GenderLogic::class, 'age' =&gt; \\DecisionTree\\Model\\Logic\\AgeLogic::class, ]); parent::__construct($implement); } public function process($node, $data): Result { $resultNode = []; $this-&gt;runNode($node, $data, $resultNode); return new Result($data['id'], $node-&gt;getId(), $resultNode); } } ","link":"https://www.vincent.ac.cn/post/-Jm04jY55/"},{"title":"PHP组合模式构建决策树排它网关模式 (一) ","content":" 组合模式，将对象组合成树形结构以表示“部分-整体”的层次结构。 组合模式优缺点 优点 可以利用多态和递归机制更方便地使用复杂树结构。 开闭原则：无需更改现有代码，就可以在应用中添加新元素，使其成为对象树的一部分。 缺点 对于功能差异较大的类，提供公共接口会有困难。在特定情况下，需要过渡一般化组件接口，使其变得令人难以理解。 应用实例 决策树实现精准化运营 场景 `目前就以该场景来实现组合场景。` 实现 节点：包含 节点ID、节点值、节点策略列表、去向节点策略列表 去向节点：包含 节点策略、去向节点ID、来源节点ID 节点策略：包含 决策ID、决策类型（大于、等于等条件）、决策数据变量key、决策值 大概的数据结构如下 { &quot;id&quot;: &quot;节点ID&quot;, &quot;type&quot;: &quot;节点类型&quot;, &quot;name&quot;: &quot;节点名称&quot;, &quot;parentId&quot;: &quot;父级节点ID&quot;, &quot;labelId&quot;: &quot;节点标签值&quot;, &quot;childMap&quot;: { &quot;节点ID&quot;: {} }, &quot;nodeDecisionMap&quot;: [ { &quot;id&quot;: &quot;决策ID&quot;, &quot;name&quot;: &quot;决策名称&quot;, &quot;key&quot;: &quot;决策key&quot;, &quot;type&quot;: &quot;决策类型&quot;, &quot;value&quot;: &quot;决策值&quot; } ], &quot;nextNodeDecisionMap&quot;: [ { &quot;NodeDecision&quot;: { &quot;id&quot;: &quot;决策ID&quot;, &quot;name&quot;: &quot;决策名称&quot;, &quot;key&quot;: &quot;决策key&quot;, &quot;type&quot;: &quot;决策类型&quot;, &quot;value&quot;: &quot;决策值&quot; }, &quot;nextNodeId&quot;: &quot;去向节点ID&quot;, &quot;formNodeId&quot;: &quot;来源节点ID&quot; } ] } 执行遍历步骤： 判断是否存在节点策略列表 不存在则跳过执行下一步。 存在执行策略列表来判断是否满足该节点不满足则退出遍历结束 判断该节点是否存在节点值，存在写入结果变量 遍历去向节点策略列表 根据策略数据判断满足哪个去向节点策略。 根据满足的去向节点策略 去子节点中获取下一个节点执行上述步骤。 当发现节点为叶子节点，返回结果变量，遍历结束。 目录结构 ├── src │ ├── Autoloader.php │ ├── Interfaces │ │ ├── DecisionTreeInterface.php │ │ ├── ImplementInterface.php │ │ └── LogicDecisionInterface.php │ ├── Model │ │ ├── Logic │ │ │ ├── AbstractLogic.php │ │ │ ├── AgeLogic.php │ │ │ └── GenderLogic.php │ │ └── Tree │ │ ├── NextNode.php │ │ ├── Node.php │ │ ├── NodeDecision.php │ │ └── Result.php │ ├── Service │ │ ├── AbstractDecisionService.php │ │ ├── ExclusiveService.php │ │ └── Implement │ │ ├── AbstractImplementService.php │ │ └── DefaultService.php │ ├── TopSdk.php │ └── Tree │ ├── DecisionData.php │ └── LeafTree.php └── test.php 定义结构模型 节点模型 &lt;?php declare(strict_types=1); namespace DecisionTree\\Model\\Tree; /** * 无限级节点模型. */ class Node { /** * 节点ID. * * @var int */ private int $id; /** * 节点类型. * * @var string */ private string $type; /** * 节点名称. * * @var string */ private string $name; /** * 父级节点id. * * @var int */ private int $parentId; /** * 节点值-绑定的标签ID. * * @var string */ private string $labelId; /** * 子节点数据. * * @var array&lt;Node&gt; */ private array $childMap; /** * 决策规则集. 绑定的决策. * @var array&lt;NodeDecision&gt; */ private array $nodeDecisionMap; /** * 去向节点决策集. * @var array&lt;NextNode&gt; */ private array $nextNodeMap; public function __construct(int $id, string $type, string $name, ?string $labelId = null) { $this-&gt;setId($id); $this-&gt;setType($type); $this-&gt;setName($name); $labelId = $labelId ?? ''; $this-&gt;setLabelId($labelId); } public function getId(): int { return $this-&gt;id; } public function setId(int $id) { $this-&gt;id = $id; } public function getType(): string { return $this-&gt;type; } public function setType(string $type) { $this-&gt;type = $type; } public function getName(): string { return $this-&gt;name; } public function setName($name) { $this-&gt;name = $name; } public function getParentId(): int { return $this-&gt;parentId; } public function setParentId($parentId) { $this-&gt;parentId = $parentId; } public function getLabelId(): string { return $this-&gt;labelId; } public function setLabelId($labelId) { $this-&gt;labelId = $labelId; } /** * @return array&lt;Node&gt; */ public function getChildMap(): array { return empty($this-&gt;childMap) ? [] : $this-&gt;childMap; } /** * @param int $nodeId * * @return null|Node */ public function getChild(int $nodeId): ?Node { return ! empty($this-&gt;getChildMap()[$nodeId]) ? $this-&gt;getChildMap()[$nodeId] : null ; } public function setChildMap(Node $childMap) { $this-&gt;childMap[$childMap-&gt;getId()] = $childMap; } public function getNodeDecisionMap(): array { return empty($this-&gt;nodeDecisionMap) ? [] : $this-&gt;nodeDecisionMap; } public function setNodeDecisionMap(NodeDecision $treeNodeDecision) { $this-&gt;nodeDecisionMap[$treeNodeDecision-&gt;getId()] = $treeNodeDecision; } /** * @return NextNode[] */ public function getNextNodeMap(): array { return empty($this-&gt;nextNodeMap) ? [] : $this-&gt;nextNodeMap; } public function getNextNode(int $key): ?NextNode { return ! empty($this-&gt;getNextNodeMap()[$key]) ? $this-&gt;getNextNodeMap()[$key] : null; } /** * @param NextNode $nextNode * * @return Node */ public function setNextNodeMap(NextNode $nextNode): Node { $this-&gt;nextNodeMap[] = $nextNode; return $this; } } 去向节点模型 &lt;?php declare(strict_types=1); namespace DecisionTree\\Model\\Tree; class NextNode { /** * 来源节点ID. * @var int */ private int $fromNodeId; /** * 去向节点ID. * @var int */ private int $nextNodeId; /** * 决策规则列表. 绑定的决策. * @var array&lt;NodeDecision&gt; */ private array $nodeDecisionMap; public function __construct(int $fromNodeId, int $nextNodeId) { $this-&gt;setFromNodeId($fromNodeId); $this-&gt;setNextNodeId($nextNodeId); } /** * @return int */ public function getFromNodeId(): int { return $this-&gt;fromNodeId; } /** * @param int $fromNodeId * * @return NextNode */ public function setFromNodeId(int $fromNodeId): NextNode { $this-&gt;fromNodeId = $fromNodeId; return $this; } /** * @return int */ public function getNextNodeId(): int { return $this-&gt;nextNodeId; } /** * @param int $nextNodeId * * @return NextNode */ public function setNextNodeId(int $nextNodeId): NextNode { $this-&gt;nextNodeId = $nextNodeId; return $this; } /** * @return NodeDecision[] */ public function getNodeDecisionMap(): array { return $this-&gt;nodeDecisionMap; } /** * @param NodeDecision $nodeDecision * * @return NextNode */ public function setNodeDecisionMap(NodeDecision $nodeDecision): NextNode { $this-&gt;nodeDecisionMap[$nodeDecision-&gt;getId()] = $nodeDecision; return $this; } } 节点策略模型 &lt;?php declare(strict_types=1); namespace DecisionTree\\Model\\Tree; /** * 决策模型. */ class NodeDecision { /** * 决策id. * @var int */ private int $id; /** * 决策名称. */ private string $name; /** * 决策key. */ private string $key; /** * 决策类型. */ private string $type; /** * 决策值 */ private $value; public function __construct(int $id, string $name, string $key, string $type, $value) { $this-&gt;setId($id); $this-&gt;setName($name); $this-&gt;setKey($key); $this-&gt;setType($type); $this-&gt;setValue($value); } public function getId(): int { return $this-&gt;id; } public function getName(): string { return $this-&gt;name; } public function setName(string $name) { $this-&gt;name = $name; } public function setId(int $id) { $this-&gt;id = $id; } public function getType(): string { return $this-&gt;type; } public function setType(string $type) { $this-&gt;type = $type; } public function getValue() { return $this-&gt;value; } public function setValue($value) { $this-&gt;value = $value; } public function getKey(): string { return $this-&gt;key; } public function setKey(string $key) { $this-&gt;key = $key; } } 决策结果模型 &lt;?php declare(strict_types=1); namespace DecisionTree\\Model\\Tree; class Result { /** * 用户id. */ private int $userId; /** * 决策树id. */ private int $treeId; /** * 结果节点值 */ private array $result; public function __construct(int $userId, int $treeId, array $result) { $this-&gt;userId = $userId; $this-&gt;treeId = $treeId; $this-&gt;result = array_values($result); } public function getUserId(): int { return $this-&gt;userId; } public function getTreeId(): int { return $this-&gt;treeId; } public function getResult(): array { return $this-&gt;result; } public function setUserId($userId) { $this-&gt;userId = $userId; } public function setTreeId($treeId) { $this-&gt;treeId = $treeId; } public function setResult(array $result) { $this-&gt;result = $result; } } ","link":"https://www.vincent.ac.cn/post/_eJBJ5mzo/"},{"title":"决策引擎系统 (二) 决策流","content":"实际风控需求通常不会只有一组规则，会对不同的规则、规则集进行编排，还会出现分支流程，子流程，形成一个更复杂风控流程，我们叫决策流，决策流的解析就是实现一个流程引擎。 流程引擎也叫工作流引擎，有很多开源实现，比较出名的是java的Activiti，jBPM5。这里我们从业务需求分析，抽象建模并自己实现流程解析过程。 简单决策流 这是一个比较简单的决策流，它由两个规则集顺序编排，并有起始和结束，是符合BPMN规范的 BPMN是什么？Business Process Diagram（BPM）是指一个业务流程图，“N”是Notation符号，BPMN业务流程建模符号，是由OMG组织维护的一套业务流程建模标准。这里我们关注和使用其中流对象（Flow）相关定义及元素 流对象中，选取事件Event中开始Start Event作为决策流的开始节点，结束End Event作为决策流的结束节点，一个规则集作为一个活动Activity，后面决策树、决策矩阵等决策节点也是活动Activity的一种类型，流向Flow作为决策流的编排执行顺序，由此一个简单的决策流就用BPMN规范做了抽象。 数据结构上，决策流节点使用单向线性链表，每个节点持有下一节点指针. 代码实现上，使用pipline架构作为流程解析，前一个节点解析结果(out/sink)作为下一个节点的输入（in/source），每个节点封装解析算法（parse），节点的执行结果统一存储在上下文中，直到全部节点执行完成或中断退出。 决策流分支 分支流程需要增加网关Gateway节点，网关又分为并行网关、排它网关、包容网关 排它网关 更符合风控场景业务语义，即一个决策流只能走一个分支。 （也称为XOR网关或更专业的基于数据的排他网关）用于对流程中的决策建模。当执行到达此网关时，将按照定义它们的顺序评估所有传出序列流。选择条件评估为真（或没有条件集，在概念上具有在序列流上定义的*'真'*）的第一序列流以继续该过程。 决策流 input等于1时走第一条分支经过任务一， input等于2时走任务二的分支，input等于3时走任务三的分支 并行网关 它允许将流程 分成多条分支，也可以把多条分支 汇聚到一起 可用于对流程中的并发进行建模。在流程模型中引入并发性的最直接的网关是并行网关，它允许您分叉到多个执行路径或连接多个传入的执行路径。 * 分支（fork）：并行执行所有传出序列流，为每个序列流创建一个并发执行。 * 聚合（join）：到达并行网关的所有并发执行在网关中等待，直到每个传入的序列流都到达执行。然后，该过程继续经过加入网关。 包容网关 也就是把排他和并行网关的组合与排他网关一样，可以在包容网关的出口顺序流上定义条件，包容网关会计算条件。然而主要的区别是，包容网关与并行网关一样，可以同时选择多于一条出口顺序流。 * 分支（fork）：所有出口顺序流都会被计算，对于计算为true的分支都会被执行。 * 聚合（join）：所有到达包容网关的并行执行，都会在网关处等待，直到每一条具有流程标志的入口顺序流，都有一个执行到达。这是与并行网关的重要区别。换句话说，包容网关只会等待将会被执行的入口顺序流。在合并后，流程穿过合并并行网关继续 ","link":"https://www.vincent.ac.cn/post/jzJBFNAM1/"},{"title":"nacos 部署和使用","content":" 因为公司新项目用的分布式， 需要用到rpc服务 所以 最后选择了使用 nacos 来做服务注册服务发现，以及配置中心 nacos是spring cloud alibaba推出的注册中心和配置中心，可用于替代netfix的eureka。 Nacos 是什么？ 先了解下 Spring Cloud Eureka 是基于 Netflix Eureka （Netflix 是 Java 实现的开源软件）。服务治理（Eureka）包括服务注册、服务发现和服务检测监控等。 那 Nacos 致力于发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 简而言之，Nacos 包含了微服务的配置管理 + 服务的注册、发现等监控。微服务也包括了 Spring Cloud 的微服务实现。 Nacos 其特性重点包含了以下： 服务发现和服务健康监测 动态配置服务 动态 DNS 服务 服务及其元数据管理 等等 官方图如下： 安装 ● 下载nacos的压缩包，并解压 https://github.com/alibaba/nacos/releases // wget https://github.com/alibaba/nacos/releases/download/2.0.3/nacos-server-2.0.3.tar.gz ● 进入解压目录的bin目录下，打开终端，输入命令启动，输出nacos is starting with standalone即为成功 tar -zxvf nacos-server-2.0.3.tar.gz cd nacos/bin sh startup.sh -m standalone ● 进入可视化页面，账号密码都是nacos，进行登录即可，nacos的端口为8848 http://xxx.x.x.x:8848/nacos/#/login ● 关闭nacos sh shutdown.sh ● 但发现关闭后，仍然能在可视化页面连接nacos，所以需要杀死8848端口的进程 //查询8848端口的进程，获取到进程id，例如是45025 lsof -i:8848 //杀死45025进程 kill -9 45025 启动Nacos报错 报错信息如下 which: no javac in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin) readlink: missing operand Try 'readlink --help' for more information. dirname: missing operand Try 'dirname --help' for more information. ERROR: Please set the JAVA_HOME variable in your environment, We need java(x64)! jdk8 or later is better! !! 查找原因：没有安装java环境导致的 解决办法：安装java并配置环境变量即可 ","link":"https://www.vincent.ac.cn/post/epFYXk4ee/"},{"title":"决策引擎系统 (一) 简单了解","content":" 新项目要做营销中心需要对会员动态精准的打上相应标签（例如需要根据性别、年龄、查看偏好等条件来决定给不同范围的用户推送不同的消息，目前就以该场景来实现组合场景），收集了一些资料思考了很久发现它似乎就是一个智能风控决策引擎系统当然了真正的决策引擎涉及（机器学习/深度学习/AI领域建立的模型运算等领域），当然了我的能力只能参考他的运行模式制作一个很简单的出来 决策引擎系统介绍 风控决策引擎系统是在大数据支撑下，根据行业专家经验制定规则策略、以及机器学习/深度学习/AI领域建立的模型运算，对当前的业务风险进行全面的评估，并给出决策结果的一套系统。 决策引擎，常用于金融反欺诈、金融信审等互金领域，由于黑产、羊毛党行业的盛行，风控决策引擎在电商、支付、游戏、社交等领域也有了长足的发展，刷单、套现、作弊，凡是和钱相关的业务都离不开风控决策引擎系统的支持保障。决策引擎和规则引擎比较接近（严格说决策引擎包含规则引擎，之前也有叫专家系统，推理引擎），它实现了业务决策与程序代码的分离。市场上有些开源规则引擎项目可参考，比较出名的开源规则引擎有drools、urule，都是基于Rete算法，都是基于java代码实现，一些企业会进行二次开发落地生产。而这类引擎功能强大但也比较“笨重”，易用性以及定制性并不够好，对其他语言栈二次开发困难。今天我们对决策引擎进行抽象建模，一步步打造一套简单实用的实现，这里会基于php语言进行简单的实现。 规则和决策抽象建模 举例说明 “如果年龄小于18岁，那么就拒绝处理” 对这条规则进行抽象建模成条件表达式：特征 （年龄） 运算符（小于） 阈值（18） ---&gt; 触发结果（拒绝） 这里产生几个概念：特征feature、运算符operator、阈值value，这三要素构成条件表达式condition，加上触发结果decision，组成了规则rule的基础元素。 “如果年龄小于18岁或年龄大于50岁，那么就拒绝处理” 条件表达式1：特征 （年龄） 运算符（小于） 阈值（18） 条件表达式2：特征 （年龄） 运算符（大于） 阈值（50） 逻辑关系：（或） 触发结果：（拒绝） 任何一个为false即为拒绝 这里多了逻辑关系，规则可由多个条件表达式组成，对表达式结果再进行逻辑运算。 “如果职业是学生，那么就拒绝处理” 条件表达式：特征（职业） 运算符（等于） 阈值（学生）触发结果（拒绝） 其他可选阈值：老师、工人、农民、程序员 对于一些名单类特征，比如规则是“命中黑名单则触发拒绝”，将命中结果抽象为枚举型特征，对应条件表达式就是：命中黑名单 等于 true/false。 做个总结：一条规则的执行，先通过数据（身份证号）计算出特征（年龄），然后带入条件表达式（年龄&lt;18）计算，并对多个表达式结果做逻辑运算，最终根据逻辑运算决定是否触发结果。 ","link":"https://www.vincent.ac.cn/post/BHt_pJVse/"},{"title":"php ftp 上传遇到报错","content":"今天 ftp 上传遇到的报错 ftp_nb_put(): php_connect_nonb() failed: Operation now in progress 了解了一下ftp的连接模式 主动模式：就是在客户端FTP登录成功后，FTP服务器主动连客户端的传输端口传输数据，至于端口是多少，是客户端随机取的一个（只要大于1024的端口就可以），所以呢FTP服务器端只需维护20,21两个端口，但是客户端却要放开1024以上的所有端口，不然无法建立数据传输通道。 被动模式：就是客户端去连服务端的传输端口了，就是服务器端是被动的，服务器端随机开发好大于1024的端口号就可以了，而这个是可以在服务器端配置的，只需要给一段端口就行了，这样客户端就不用去开发那么多端口了，这种对有防火墙的客户端就很方便了。 我选择了被动模式 加上了 这行代码 ftp_pasv($conn, true); //ftp设置被动模式 但是问题就来了，居然出现两个警告 ftp_nb_put(): php_connect_nonb() failed: Operation now in progress (36) in ftp_nb_put(): TYPE is now 8-bit binary in 一看以为警告，没什么影响，但是居然上传失败了 然后就是一通网上找，找了N就都是各种无关的复制粘贴的文章（心哇凉哇凉滴），太坑了，然后试着去stackoverflow 搜了一下（英语渣，全靠google翻译硬着头皮找），居然不少人遇到这个问题了，具体找了看到一篇有解决方案的： https://stackoverflow.com/questions/38982901/php-ftp-passive-ftp-server-behind-nat 里面那仅有的一个回答，说出了真相： ftp_set_option($conn, FTP_USEPASVADDRESS, false); //加上一个option操作就行了 ftp_pasv($conn, true); 立马加上，并在FTP服务器设置并开放了被动模式需要的端口，一测试，完美解决！ ","link":"https://www.vincent.ac.cn/post/uSukP0SN4/"},{"title":"Redis中bitmap的妙用 ","content":" 在Redis中我们经常用到set,get等命令，细心的你有没有发现，还有几个相似的命令叫setbit,getbit，它们是用来干嘛的？ BitMap是什么 就是通过一个bit位来表示某个元素对应的值或者状态,其中的key就是对应元素本身。我们知道8个bit可以组成一个Byte，所以bitmap本身会极大的节省储存空间。 Redis中的BitMap Redis从2.2.0版本开始新增了setbit,getbit,bitcount等几个bitmap相关命令。虽然是新命令，但是并没有新增新的数据类型，因为setbit等命令只不过是在set上的扩展。 setbit命令介绍 指令 SETBIT key offset value复杂度 O(1)设置或者清空key的value(字符串)在offset处的bit值(只能只0或者1)。 空间占用、以及第一次分配空间需要的时间 在一台2010MacBook Pro上，offset为2^32-1（分配512MB）需要～300ms，offset为2^30-1(分配128MB)需要～80ms，offset为2^28-1（分配32MB）需要～30ms，offset为2^26-1（分配8MB）需要8ms。&lt;来自官方文档&gt;大概的空间占用计算公式是：($offset/8/1024/1024)MB 使用场景一：用户签到 很多网站都提供了签到功能(这里不考虑数据落地事宜)，并且需要展示最近一个月的签到情况，如果使用bitmap我们怎么做？一言不合亮代码！ &lt;?php $redis = new Redis(); $redis-&gt;connect('127.0.0.1'); //用户uid $uid = 1; //记录有uid的key $cacheKey = sprintf(&quot;sign_%d&quot;, $uid); //开始有签到功能的日期 $startDate = '2017-01-01'; //今天的日期 $todayDate = '2017-01-21'; //计算offset $startTime = strtotime($startDate); $todayTime = strtotime($todayDate); $offset = floor(($todayTime - $startTime) / 86400); echo &quot;今天是第{$offset}天&quot; . PHP_EOL; //签到 //一年一个用户会占用多少空间呢？大约365/8=45.625个字节，好小，有木有被惊呆？ $redis-&gt;setBit($cacheKey, $offset, 1); //查询签到情况 $bitStatus = $redis-&gt;getBit($cacheKey, $offset); echo 1 == $bitStatus ? '今天已经签到啦' : '还没有签到呢'; echo PHP_EOL; //计算总签到次数 echo $redis-&gt;bitCount($cacheKey) . PHP_EOL; /** * 计算某段时间内的签到次数 * 很不幸啊,bitCount虽然提供了start和end参数，但是这个说的是字符串的位置，而不是对应&quot;位&quot;的位置 * 幸运的是我们可以通过get命令将value取出来，自己解析。并且这个value不会太大，上面计算过一年一个用户只需要45个字节 * 给我们的网站定一个小目标，运行30年，那么一共需要1.31KB(就问你屌不屌？) */ //这是个错误的计算方式 echo $redis-&gt;bitCount($cacheKey, 0, 20) . PHP_EOL; 使用场景二：统计活跃用户 使用时间作为cacheKey，然后用户ID为offset，如果当日活跃过就设置为1那么我该如果计算某几天/月/年的活跃用户呢(暂且约定，统计时间内只有有一天在线就称为活跃)，有请下一个redis的命令命令 BITOP operation destkey key [key ...]说明：对一个或多个保存二进制位的字符串 key 进行位元操作，并将结果保存到 destkey 上。说明：BITOP 命令支持 AND 、 OR 、 NOT 、 XOR 这四种操作中的任意一种参数 //日期对应的活跃用户 $data = array( '2017-01-10' =&gt; array(1,2,3,4,5,6,7,8,9,10), '2017-01-11' =&gt; array(1,2,3,4,5,6,7,8), '2017-01-12' =&gt; array(1,2,3,4,5,6), '2017-01-13' =&gt; array(1,2,3,4), '2017-01-14' =&gt; array(1,2) ); //批量设置活跃状态 foreach($data as $date=&gt;$uids) { $cacheKey = sprintf(&quot;stat_%s&quot;, $date); foreach($uids as $uid) { $redis-&gt;setBit($cacheKey, $uid, 1); } } $redis-&gt;bitOp('AND', 'stat', 'stat_2017-01-10', 'stat_2017-01-11', 'stat_2017-01-12') . PHP_EOL; //总活跃用户：6 echo &quot;总活跃用户：&quot; . $redis-&gt;bitCount('stat') . PHP_EOL; $redis-&gt;bitOp('AND', 'stat1', 'stat_2017-01-10', 'stat_2017-01-11', 'stat_2017-01-14') . PHP_EOL; //总活跃用户：2 echo &quot;总活跃用户：&quot; . $redis-&gt;bitCount('stat1') . PHP_EOL; $redis-&gt;bitOp('AND', 'stat2', 'stat_2017-01-10', 'stat_2017-01-11') . PHP_EOL; //总活跃用户：8 echo &quot;总活跃用户：&quot; . $redis-&gt;bitCount('stat2') . PHP_EOL; 假设当前站点有5000W用户，那么一天的数据大约为50000000/8/1024/1024=6MB 使用场景三：用户在线状态 前段时间开发一个项目，对方给我提供了一个查询当前用户是否在线的接口。不了解对方是怎么做的，自己考虑了一下，使用bitmap是一个节约空间效率又高的一种方法，只需要一个key，然后用户ID为offset，如果在线就设置为1，不在线就设置为0，和上面的场景一样，5000W用户只需要6MB的空间。 //批量设置在线状态 $uids = range(1, 500000); foreach($uids as $uid) { $redis-&gt;setBit('online', $uid, $uid % 2); } //一个一个获取状态 $uids = range(1, 500000); $startTime = microtime(true); foreach($uids as $uid) { echo $redis-&gt;getBit('online', $uid) . PHP_EOL; } $endTime = microtime(true); //在我的电脑上，获取50W个用户的状态需要25秒 echo &quot;total:&quot; . ($endTime - $startTime) . &quot;s&quot;; /** * 对于批量的获取，上面是一种效率低的办法，实际可以通过get获取到value，然后自己计算 * 具体计算方法改天再写吧，之前写的代码找不见了。。。 */ ","link":"https://www.vincent.ac.cn/post/-ADPQWJUC/"},{"title":"IO 多路复用","content":"IO = INPUT/OUTPUT, 以一个 10086 客服妹子（一个进程）接待电话来比喻，最开始的电话机，她只能同时接待一个人，而且每次问答都得拨一次号（每次 HTTP 请求都需要三次握手），后来电话机升级可以保持通话了（ keep-alive）这就是所谓的 “IO 复用”。 后来客户接待多了，因为她接待一个人的时候，其他人没有办法打进来（10086 号码占线），咋办呢？于是 10086 可以分配多个电话分机，其他人也可以拨打 10086 进来了（非阻塞模式），于是客服妹子忙坏了，她将面临三个问题： 一个人同时监听多个电话机，怎么知道有新的连接进来？ 一般客服不会主动挂断电话，怎么知道哪些对方已挂断？ 怎么知道哪个电话机的客户在问问题，不会发生没听到的情况？ 针对上面的问题，请了一个后台帮手帮助客服，当有新的电话打来、哪些电话对方说话了、哪些电话对方挂断了，把这个电话机交给客服，这个帮手需要快速轮询靠近每个电话机的听筒，帮手（计算机）虽然很快，缺点也存在，电话机经常在用户空间（客服）和内核空间（帮手）不断传递，而且不能有大量的电话机（性能和内存）。这就是最初的 select 模型，最多支持 2048 个链接，实现了所谓的 “IO 多路复用”。 于是升级后的系统，采用事件监听机制，每个电话机的状态都通过事件 (I/O 流事件)（铃音或者其他）主动报告，这样极大的利用了客服资源（进程）。这就是 epoll 模型。 ","link":"https://www.vincent.ac.cn/post/afmQoP66O/"},{"title":"PHP 安装 grpc 扩展报错","content":"In file included from ./src/core/ext/filters/client_channel/lb_policy.h:31:0, from ./src/core/ext/filters/client_channel/backend_metric.h:24, from /root/grpc-1.41.0/src/core/ext/filters/client_channel/backend_metric.cc:19: ./src/core/ext/filters/client_channel/server_address.h: 在成员函数‘virtual std::string grpc_core::ServerAddressWeightAttribute::ToString() const’中: ./src/core/ext/filters/client_channel/server_address.h:135:41: 错误：对‘StrFormat(const char [3], const uint32_t&amp;)’的调用没有匹配的函数 return absl::StrFormat(&quot;%d&quot;, weight_); ^ ./src/core/ext/filters/client_channel/server_address.h:135:41: 附注：备选是： In file included from ./src/core/ext/filters/client_channel/server_address.h:28:0, from ./src/core/ext/filters/client_channel/lb_policy.h:31, from ./src/core/ext/filters/client_channel/backend_metric.h:24, from /root/grpc-1.41.0/src/core/ext/filters/client_channel/backend_metric.cc:19: /root/grpc-1.41.0/third_party/abseil-cpp/absl/strings/str_format.h:338:34: 附注：template&lt;class ... Args&gt; std::string absl::lts_20210324::StrFormat(absl::lts_20210324::FormatSpec&lt;Args ...&gt;&amp;, const Args&amp; ...) ABSL_MUST_USE_RESULT std::string StrFormat(const FormatSpec&lt;Args...&gt;&amp; format, ^ /root/grpc-1.41.0/third_party/abseil-cpp/absl/strings/str_format.h:338:34: 附注： template argument deduction/substitution failed: In file included from ./src/core/ext/filters/client_channel/lb_policy.h:31:0, from ./src/core/ext/filters/client_channel/backend_metric.h:24, from /root/grpc-1.41.0/src/core/ext/filters/client_channel/backend_metric.cc:19: ./src/core/ext/filters/client_channel/server_address.h:135:41: 附注： mismatched types ‘absl::lts_20210324::FormatSpec&lt;Args ...&gt;’ and ‘const char [3]’ return absl::StrFormat(&quot;%d&quot;, weight_); ^ make: *** [src/core/ext/filters/client_channel/backend_metric.lo] 错误 1 原因分析： 需要安装 you need gcc version 4.9+ 升级gcc 1、安装centos-release-scl sudo yum install centos-release-scl 2、安装devtoolset，注意，如果想安装7.*版本的，就改成devtoolset-7-gcc*，以此类推 sudo yum install devtoolset-8-gcc* 3、激活对应的devtoolset，所以你可以一次安装多个版本的devtoolset，需要的时候用下面这条命令切换到对应的版本 scl enable devtoolset-8 bash 大功告成，查看一下gcc版本 gcc -v 每个版本的目录下面都有个 enable 文件，如果需要启用某个版本，只需要执行 source /opt/rh/devtoolset-8/enable ","link":"https://www.vincent.ac.cn/post/G3An0gaU4/"},{"title":"Mac下docker访问主机服务","content":"目前mac下的docker可以通过指定特殊的域名来访问部署在mac主机上的服务。 比如访问mac主机上的mysql服务， 17.12版本之后只需要将host设置为 docker.for.mac.host.internal 即可。 参考： https://docs.docker.com/docker-for-mac/networking/ ","link":"https://www.vincent.ac.cn/post/2vh0CdvfU/"},{"title":"解决 【git checkout -b dev origin/dev】报错的问题","content":"把远程库的 dev 分支拉倒本地的 dev 分支时使用指令： git checkout -b dev origin/dev 说明： ● -b 表示本地创建 dev 分支并切换到 dev 分支上； ● origin/dev 表示远程库的 dev 分支。 报错信息 解决方法 git fetch origin dev // 命令来把远程分支拉到本地 git checkout -b dev origin/dev // 在本地创建分支dev并切换到该分支 git pull origin dev // 就可以把某个分支上的内容都拉取到本地了 键入命令后如下所示： ","link":"https://www.vincent.ac.cn/post/Q7yzCjxGh/"},{"title":"多路复用一样会阻塞用户线程那它和同步阻塞有什么区别","content":"普通人： ● 在和女神的单聊界面苦等（阻塞等待，对应阻塞的recv()等） ● 工作的时候也要动不动关注女神有没有回复，陷入备胎陷阱，心思没办法维持在工作上，效率低下 （CPU时间被大量浪费在阻塞系统调用上，频繁陷入内核态，上下文切换开销很大） ● 出现了新的恋爱机会，但是没办法同时处理，因此只能拱手让人（一个同步阻塞进程同时只能处理一个连接，当Master进程调度时或当其他进程也在监听同一端口时(REUSE_PORT)，新的连接会被分配给其它进程） ● 虽然看起来很捞，但是很专一 ，并且这也是大多数普通人的求偶方式。（虽然性能不如多路复用，但是网络编程生态很大一部分都建立在同步阻塞的编程模型之上，并且它易于理解，对于开发者心智负担较低） 海王： ● 从不在工作的时候主动等消息，游刃有余（充分利用CPU时间，尽量跑在用户态上） ● 有空摸鱼的时候才顺便打理鱼塘，看下手机有没有消息（CPU运算任务告一段落，检查是否有IO事件，对应 epoll_wait() 之类的调用） ● 检查有多少个妹子给自己发消息了，点亮手机发现收到100个联系人的未读消息通知 （epoll_wait()返回了100，说明有100个文件描述符就绪） ● 遍历处理，但绝不在和某个妹子的会话上单独等待，除非除了把妹之外没事可干了，否则处理完后马上就该干嘛干嘛，进入下一轮循环。（遍历处理可读可写事件，执行非阻塞IO操作，即不会长时间阻塞在某个socket上，而是进入下一轮事件循环再统一等待） 那么，哪怕是一个只会把妹，别的人事啥也不干的海王，它搞定100个妹子的时间也不过是MAX(搞定妹子0的时间, 搞定妹子1的时间, 搞定妹子2的时间, ...搞定妹子99的时间)，而普通人可能就需要 搞定妹子0的时间 + 搞定妹子1的时间 + 搞定妹子2的时间 + 搞定妹子99的时间 ，当妹子的数量越多，搞定妹子的时间越长，海王的优势就越明显。（如本地网络IO速度极快，多路复用的性能优势就不明显，而外部网络尤其是慢速网络环境下，多路复用技术就能体现出其巨大的性能优势） 设计合理的高性能海王能快速祸害成百上千的妹子，而同步阻塞的普通人或许终其一生都无法达到十之一二就因为阳寿耗尽（ETIMEDOUT）被KILL了。 原有的车马很慢书信很远一生只够爱一个人已不能满足当代人日渐空虚的内心和永远填不满的情感需求，海王之风因而大行其道（当原有的多进程多线程+同步阻塞模式不能满足日益增长的高并发需求，多路复用技术因此而兴起）。 脑洞又开了开，每当出现一个新来的妹子时，伺机而动的单身狗们全都被惊动，变成舔狗，但它们之中只有一个人能得逞，这就是惊群，频繁的惊群极大地损害了得不到妹子的舔狗们的身心，造成了感情的浪费。（惊群问题是计算机科学中，当许多进程等待一个事件，事件发生后这些进程被唤醒，但只有一个进程能获得执行权，其他进程又得被阻塞，这造成了大量的系统上下文切换开销） 而如果你是屌丝，你大概率会倒在这几步 ● 找不到妹子 （DNS resolution failed） ● 找到心仪的妹子加微信被拒绝（Connection refused） ● 加上妹子了妹子发现你是屌丝然后装死 （Connection timed out） ● 加上妹子了妹子发现你是屌丝然后把你删了（Connection reset by peer） ● 在你发消息的时候你发现妹子把你删了（Broken pipe） ● 妹子把你拉黑了（加入防火墙黑名单） 但是我们不用气馁，海王撩妹也是有上限的，因为微信有5000个好友的上限，那么即便是最顶级的海王，也只能同时搞定5000个妹子，这就是经典的C5K问题(笑，这里对应了单机能力是有上限的，不能无限扩展。 但是坏了，写到这里我才想来，海王可以有多个手机，多个微信，这就升级到集群了……集群还可以解决单个微信每天加的妹子太多，被微信限制的问题，多个微信均衡负载，每天可以加的妹子数量又上升了... 高级别的海王意识到用一个微信很容易出岔子，发个朋友圈还得小心翼翼地设置有谁可见，那么它就会对自己的服务作拆分，工作、家庭、亲戚、朋友、鱼塘全都解耦，于是分布式海王诞生了... 注重安全的海王会和妹子用多种社交APP建立联系，防止某个约妹APP突然挂了或是被下架导致鱼塘损失，这是多活容灾。 找到规律的海王会形成一套把妹话术，妹子多了很难一一应付，就在把妹之前预加载好话术，根据妹子的类型找到话术缓存，降低压力。 知进退的高级海王知道有些妹子不好对付，引入了熔断降级机制，而普通人只知道在一棵树上吊死，感情失败黑化了，想学习海王，结果被妹子拒得心态血(雪)崩。 虽然跑题跑远了... 但是这还可以告诉大家，网络编程到多路复用这里只是刚刚开始，C10K后面还有C10M，现在还喜欢动不动就百万千万亿万并发的 ","link":"https://www.vincent.ac.cn/post/2A1QfTR-0/"},{"title":"用户签到的数据库设计方案","content":"初步设计了一下用户签到的设计方案，记录下这种思路，以后可能需要完善。每月最多有31天，int32有32位，签到与没签到只有两种状态，签到用1来表示，未签到用0来表示，因此可以用int32来表示用户每月的签到情况。 数据库表（sign_record）的设计： 列 类型 描述 id int64 自增键 user_id int64 索引，用户表的id date_month date 索引，月份，形如2019-02 mask int32 用户签到的数据 continue_sign_month int32 用户本月连续签到的天数 需要解决的一些问题：假设当前服务器月份是month 获取用户当月的签到状态： 根据服务器时间判断当前的月份month，根据传入的user_id和month去数据库中查找用户签到的数据mask。 签到： 假设当日是本月第i天（这个可以计算得出），更新数据库中mask: mask = mask | (1 &lt;&lt; i)，更新连续签到天数+1 判断当日是否签到： 如果mask &amp; (1 &lt;&lt; i)大于0，说明签到了，如果为0，说明未签到。 本月补签： 补签某个日期，假设是第j天，更新数据库中mask: mask = mask | (1 &lt;&lt; j)，重新统计本月连续签到天数，从第i位开始逆序遍历统计天数。 本月连续签到天数： 直接返回数据库中continue_sign_month字段。 待续…… 由于存在可能补签的情况，需要记录所有的签到记录，由于有了所有的签到记录，其实任何功能都可以实现，只是实现的复杂度可能不同。 ","link":"https://www.vincent.ac.cn/post/FPQG4z3uM/"},{"title":"随机数","content":" /dev/random 是有系统的熵池来源很多 比如cpu 中断 或者网卡的中断 产生的随机数的质量是能量化的可能我cpu受温度影响了 然后就产生了一点变化 整个随机序列就完全变了 而这个变化是你预测不了的对安全要求高一些的可以使用这类随机数发生器 伪随机数并不是假随机数，这里的“伪”是有规律的意思，就是计算机产生的伪随机数既是随机的又是有规律的。怎样理解呢？产生的伪随机数有时遵守一定的规律，有时不遵守任何规律；伪随机数有一部分遵守一定的规律；另一部分不遵守任何规律。比如“世上没有两片形状完全相同的树叶”。 /dev/random和/dev/urandom是Linux系统中提供的随机伪设备，这两个设备的任务，是提供永不为空的随机字节数据流。很多解密程序与安全应用程序（如SSH Keys,SSL Keys等）需要它们提供的随机数据流。 这两个设备的差异在于：/dev/random的random pool依赖于系统中断，因此在系统的中断数不足时，/dev/random设备会一直封锁，尝试读取的进程就会进入等待状态，直到系统的中断数充分够用, /dev/random设备可以保证数据的随机性。/dev/urandom不依赖系统的中断，也就不会造成进程忙等待，但是数据的随机性也不高。 php7以下的版本使用 php7请用 random_int() 函数 /* * 通过此方法获取随机数，但需要mycrpt支持 * */ private function GetURandom2($min = 0, $max = 0x7FFFFFFF) { $diff = $max - $min; if ($diff &lt; 0 || $diff &gt; 0x7FFFFFFF) { throw new RuntimeException(&quot;Bad range&quot;); } $bytes = mcrypt_create_iv(4, MCRYPT_DEV_URANDOM); if ($bytes === false || strlen($bytes) != 4) { throw new RuntimeException(&quot;Unable to get 4 bytes&quot;); } $ary = unpack(&quot;Nint&quot;, $bytes); $val = $ary['int'] &amp; 0x7FFFFFFF; // 32-bit safe $fp = (float) $val / 2147483647.0; // convert to [0,1] return round($fp * $diff) + $min; } /* * * php 版本 &gt;= 5.3， 通过读取&quot;/dev/urandom&quot;实现产生较好随机数 * * */ private function GetURandom($min = 0, $max = 0x7FFFFFFF) { $diff = $max - $min; if ($diff &gt; PHP_INT_MAX) { throw new RuntimeException('Bad Range'); } $fh = fopen('/dev/urandom', 'r'); stream_set_read_buffer($fh, PHP_INT_SIZE); $bytes = fread($fh, PHP_INT_SIZE ); if ($bytes === false || strlen($bytes) != PHP_INT_SIZE ) { //throw new RuntimeException(&quot;nable to get&quot;. PHP_INT_SIZE . &quot;bytes&quot;); return 0; } fclose($fh); if (PHP_INT_SIZE == 8) { // 64-bit versions list($higher, $lower) = array_values(unpack('N2', $bytes)); $value = $higher &lt;&lt; 32 | $lower; } else { // 32-bit versions list($value) = array_values(unpack('Nint', $bytes)); } $val = $value &amp; PHP_INT_MAX; $fp = (float)$val / PHP_INT_MAX; // convert to [0,1] return (int)(round($fp * $diff) + $min); } ","link":"https://www.vincent.ac.cn/post/jCQSdFjqv/"},{"title":"1000万个数字怎么快速取出最小5个数或者最大5个数","content":"TopN问题 最优解：小顶堆 不需要排序，排序效率太差了 如果大家对堆排序的原理不清除，可以查阅相关资料，我推荐大家参考《算法导论》第六章堆排序，讲解很详细。如果大家需要堆排序的源码，可以参考笔者这篇堆排序文章，本文对堆排序不在赘述。 首先，我们需要构建一个大小为N的小顶堆，小顶堆的性质如下：每一个父节点的值都小于左右孩子节点，然后依次从文件中读取10亿个整数，如果元素比堆顶小，则跳过不进行任何操作，如果比堆顶大，则把堆顶元素替换掉，并重新构建小顶堆。当10亿个整数遍历完成后，堆内元素就是TopN的结果。 public class TopN { public static int N = 10; //Top10 public static int LEN = 100000000; //1亿个整数 public static int arrs[] = new int[LEN]; public static int arr[] = new int[N]; //数组长度 public static int len = arr.length; //堆中元素的有效元素 heapSize&lt;=len public static int heapSize = len; public static void main(String[] args) { //生成随机数组 for(int i = 0;i&lt;LEN;i++){ arrs[i] = new Random().nextInt(999999999); } //构建初始堆 for(int i = 0;i&lt;N;i++){ arr[i] = arrs[i]; } //构建小顶堆 long start =System.currentTimeMillis(); buildMinHeap(); for(int i = N;i&lt;LEN;i++){ if(arrs[i] &gt; arr[0]){ arr[0] = arrs[i]; minHeap(0); } } System.out.println(LEN+&quot;个数，求Top&quot;+N+&quot;，耗时&quot;+(System.currentTimeMillis()-start)+&quot;毫秒&quot;); print(); } /** * 自底向上构建小堆 */ public static void buildMinHeap(){ int size = len / 2; for(int i = size;i&gt;=0;i--){ minHeap(i); } } /** * i节点为根及子树是一个小堆 * @param i */ public static void minHeap(int i){ int l = left(i); int r = right(i); int index = i; if(l&lt;heapSize &amp;&amp; arr[l]&lt;arr[index]){ index = l; } if(r&lt;heapSize &amp;&amp; arr[r]&lt;arr[index]){ index = r; } if(index != i){ int t = arr[index]; arr[index] = arr[i]; arr[i] = t; //递归向下构建堆 minHeap(index); } } /** * 返回i节点的左孩子 * @param i * @return */ public static int left(int i){ return 2*i; } /** * 返回i节点的右孩子 * @param i * @return */ public static int right(int i){ return 2*i+1; } /** * 打印 */ public static void print(){ for(int a:arr){ System.out.print(a+&quot;,&quot;); } System.out.println(); } 与TopN类似的题目并且应用堆原理的问题有很多，再给大家举个例子哈： 记得上周，小编和同事聚餐，期间有个同事提出了一个问题： 给一个无序数组，元素个数亿级，要求写一个算法，要求最后数组左边的任何一个数都比数组右边任何一个数小，但左右数组中元素是否有序不要求。于是，热闹的饭局一下子安静下来，其他同事们都陷入了深深的思考。 了解完堆和TopN的原理后，这样的题也很容易，解法如下： 数组长度为len，构建一个大小为n=len/2的大顶堆，从n处遍历数组 如果元素小于堆顶元素，将该元素与堆顶元素交换，并重新构建大顶堆 若该元素大于堆顶元素，则不操作，继续遍历 直到遍历完成，此时堆中的数据就是左半部分小的数组，与原数组合并后就是需要的结果 public class TopN { public static int LEN = 20; //数组大小 public static int N = LEN/2; //堆大小 public static int arrs[] = new int[LEN]; public static int arr[] = new int[N]; //堆 //数组长度 public static int len = arr.length; //堆中元素的有效元素 heapSize&lt;=len public static int heapSize = len; public static void main(String[] args) { //初始化数组 for(int i = 0;i&lt;LEN;i++){ arrs[i] = new Random().nextInt(1000); } for(int i = 0;i&lt;N;i++){ arr[i] = arrs[i]; } //构建大顶堆 buildMaxHeap(); for(int i = N;i &lt; LEN;i++){ //如果比堆顶元素小，交换两个数的位置，并重新调整堆结构 if(arrs[i] &lt; arr[0]){ int t = arrs[i]; arrs[i] = arr[0]; arr[0] = t; maxHeap(0); } } //修改原数组 for(int i = 0;i&lt;N;i++){ arrs[i] = arr[i]; } print(); } /** * 自底向上构建大堆 */ public static void buildMaxHeap(){ int size = len / 2; for(int i = size;i&gt;=0;i--){ maxHeap(i); } } /** * i节点为根及子树是一个大堆 * @param i */ public static void maxHeap(int i){ int l = left(i); int r = right(i); int index = i; if(l&lt;heapSize &amp;&amp; arr[l]&gt;arr[index]){ index = l; } if(r&lt;heapSize &amp;&amp; arr[r]&gt;arr[index]){ index = r; } if(index != i){ int t = arr[index]; arr[index] = arr[i]; arr[i] = t; //递归向下构建堆 maxHeap(index); } } /** * 返回i节点的左孩子 * @param i * @return */ public static int left(int i){ return 2*i; } /** * 返回i节点的右孩子 * @param i * @return */ public static int right(int i){ return 2*i+1; } /** * 打印 */ public static void print(){ for(int a:arrs){ System.out.print(a+&quot;,&quot;); } System.out.println(); } ","link":"https://www.vincent.ac.cn/post/bw_q2WfZA/"},{"title":"hyperf使用nginx转发服务出现静态资源访问404问题的原因与解决方法","content":"项目用hyperf框架开发的在部署的时候选择用nginx 反向代理 来转发服务请求 location /hyperf-api/ { # 将客户端的 Host 和 IP 信息一并转发到对应节点 proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 转发Cookie，设置 SameSite proxy_cookie_path / &quot;/; secure; HttpOnly; SameSite=strict&quot;; # 执行代理访问真实服务器 proxy_pass http://hyperf_api/; } 但是通过以上配置之后，虽然能够访问到转发后的地址，但是所有静态资源文件的请求都报404错误，导致反向代理并没有完全成功。 经过多次排查与反复尝试，最终问题还是定位在nginx的路由配置上。具体是，出于nginx的路由路径【/hyperf-api/】在路由匹配成功之后还会继续往下寻找匹配规则（在上面的配置中找不到）以及在路径中末尾【/】的原因，静态资源的请求地址无法被nginx有效识别，直接导致反向代理失败了，所有的二级地址都没有被代理成功。 解决方法则是修改路由路径的匹配规则（加上往下匹配的通配符【^~】）即可： location ^~ /hyperf-api/ { # 将客户端的 Host 和 IP 信息一并转发到对应节点 proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 转发Cookie，设置 SameSite proxy_cookie_path / &quot;/; secure; HttpOnly; SameSite=strict&quot;; # 执行代理访问真实服务器 proxy_pass http://hyperf_api/; } ","link":"https://www.vincent.ac.cn/post/yxXTxkQ86/"},{"title":"hyperf 框架 单台服务器部署进行滚动更新","content":" docker集群的发布过程。 发布新的容器 添加对应的dns解析 卸载将要停止容器的dns解析 停止对应的容器 所以发布项目的时候，写一个脚本来模拟这个发布过程。 切换服务端口启动项目 刷新nginx到新的端口 去掉老的nginx映射 关掉老的服务 以下为 deploy.sh脚本实现代码 #!/bin/bash #TODO 随机可用端口 ports=(9603 9604) check_port() { # shellcheck disable=SC1083 code=$(curl -I -m 10 -o /dev/null -s -w %{http_code} 127.0.0.1:&quot;$1&quot;/check_port) echo &quot;$code&quot; } online_port=0 reload_port=0 for i in &quot;${!ports[@]}&quot;; do code=$(check_port &quot;${ports[$i]}&quot;) # shellcheck disable=SC2053 if [[ '200' == $code ]]; then online_port=${ports[$i]} else reload_port=${ports[$i]} fi done if [[ $online_port == 0 ]]; then echo '服务未启动' reload_port=${ports[0]} echo &quot;自动分配端口 $reload_port&quot; else echo &quot;当前端口 $online_port&quot; echo &quot;重启端口 $reload_port&quot; fi if [[ $reload_port == 0 ]]; then echo '部署失败, 未获取到可用端口' exit 1; fi # nginx配置文件路径 nginx_upstream=&quot;/www/server/panel/vhost/upstream/upstream_hyperf.conf&quot; # shellcheck disable=SC2016 upstream=' upstream hyperf { server 127.0.0.1:'&quot;$reload_port&quot;'; } ' git pull docker build -t hyperf_server:hyperf_cli . echo &quot;docker run -p $reload_port:9602 --name hyperf_server_$reload_port -dit hyperf_server:hyperf_cli&quot; docker run -p &quot;$reload_port&quot;:9602 --name hyperf_server_&quot;$reload_port&quot; -dit hyperf_server:hyperf_cli while : do reload=$(check_port &quot;$reload_port&quot;) echo &quot;check $reload_port 服务 reload $reload&quot; # shellcheck disable=SC2053 if [[ '200' == $reload ]]; then echo &quot;新服务重启成功 hyperf_server_$reload_port&quot; echo &quot;$upstream&quot; &gt; $nginx_upstream nginx -s reload if [[ $online_port != 0 ]]; then # 无法探知老服务持有链接响应完成时间 sleep 5 echo &quot;停止旧服务 lm_ipad_server_&quot;&quot;$online_port&quot;&quot;_&quot;&quot;$socket_io_online_port&quot; # shellcheck disable=SC2027 docker stop &quot;lm_ipad_server_&quot;&quot;$online_port&quot;_&quot;$socket_io_online_port&quot; docker rm -f &quot;lm_ipad_server_&quot;&quot;$online_port&quot;_&quot;$socket_io_online_port&quot; fi echo &quot;清理无效的docker镜像&quot; docker rmi -f $(docker images | grep &quot;&lt;none&gt;&quot; | awk &quot;{print \\$3}&quot;) break fi sleep 2 done Nginx代理socket.io时60s自动断开 利用nginx代理socket.io的时候，发现客户端和服务器握手成功后，如果在60s时间内没有数据交互，连接就会自动断开 nginx.conf 文件里location 中的proxy_read_timeout 默认60s断开，可以把他设置大一点，你可以设置成自己需要的时间，我这里设置的是十分钟（600s）． location ^~/socket.io/ { # 执行代理访问真实服务器 proxy_pass http://lmpad_socket_io; proxy_http_version 1.1; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_read_timeout 600s; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } 按照上述方法设置好后，我们可以发现，如果在10分钟之内没有数据交互的话，websocket连接就会自动断开 上面nginx配置的时候还出了一个小插曲，微改了nginx配置之后，没有重启nginx服务，导致设置的过期时间一直没有生效，所以需要用 sudo nginx -s reload 重启nginx服务 ","link":"https://www.vincent.ac.cn/post/eIg09332U/"},{"title":"docker 容器 无法访问宿主机服务","content":"公司的新项目使用hyperf进行开发，所以选择了docker的方式进行部署，但是遇到无法直接通过127.0.0.1 方法 主机上的mysql 和redis 的问题 docker 容器 无法访问宿主机服务 路 redis、mysql 问题根因 docker网卡地址冲突 docker网络模式默认使用的bridge模式，当我们创建容器时，每个容器会有它自己的虚拟网络接口连接到桥接网络docker0，并获取一个ip。可以通过ifconfig 查看docker0的信息，使用route -n命令可以看到。 docker网段,占用了172.17.0.0网段 在实际使用环境中，有可能咱们局域网内已经将这些网段分配到了其他的工作区域中，如果在这些工作区域中去访问此环境下的docker服务，是无法正常访问的。 那么这时候就只有两种解决办法，将已分配的工作区域的网段换成其他网段，或者将docker占用的网段指定成其他网段，显然前者相对来说成本要稍高些。 解决过程 事先安装 yum install -y bridge-utils 停掉docker服务 service docker stop 关闭docker虚拟网卡及另开启对应的网卡 ip link set dev docker0 down brctl delbr docker0 iptables -t nat -F POSTROUTING brctl addbr docker0 ip addr add 172.16.10.1/24 dev docker0 ip link set dev docker0 up 修改docker配置文件 vim /etc/docker/daemon.json { &quot;registry-mirrors&quot;: [&quot;https://q7aeuv4l.mirror.aliyuncs.com&quot;], &quot;bip&quot;:&quot;172.16.10.1/24&quot; } 重启docker systemctl restart docker mysql redis 服务器默认的设置为允许127.0.0.1段的ip地址访问 如果用 172.16.0.1 仍然无法访问到宿主机的话，需要设置一下mysql和redis的访问权限 ","link":"https://www.vincent.ac.cn/post/eMo2wCY1r/"},{"title":"清除docker无用镜像和容器","content":"在docker镜像列表中我们经常会看到一堆tag为 &lt;none&gt; 的镜像，已经没有在使用，但随着提交次数增加，这些僵尸的占用了大量的磁盘空间，有必要做一次清理。 可以使用以下命令清理none镜像 docker rmi -f $(docker images | grep &quot;&lt;none&gt;&quot; | awk &quot;{print \\$3}&quot;) 使用以下命令清理已经停止运行的docker容器 docker rm $(docker ps --all -q -f status=exited) ","link":"https://www.vincent.ac.cn/post/nBfESCKq-/"},{"title":"设置Docker容器日志文件大小限制","content":"vim /etc/docker/daemon.json { &quot;log-driver&quot;:&quot;json-file&quot;, &quot;log-opts&quot;: {&quot;max-size&quot;:&quot;500m&quot;, &quot;max-file&quot;:&quot;3&quot;} } max-size=500m，意味着一个容器日志大小上限是500M， max-file=3，意味着一个容器有三个日志，分别是id+.json、id+1.json、id+2.json。 2.然后重启docker的守护线程 命令如下： systemctl daemon-reload systemctl restart docker 【需要注意的是：设置的日志大小规则，只对新建的容器有效】 ","link":"https://www.vincent.ac.cn/post/isu6EwADe/"},{"title":"linux查看nginx、apache、php、php-fpm、mysql及配置项所在目录","content":"很多时候会登录一台陌生的服务器； 当需要调整环境的时候； 那真是起步啥都没有；装备全靠打； 两眼一抹黑到处找配置项； 还好我这记的有一份笔记； 可以先总结下； 大都是先用 which 获取目录； 然后再获取配置项位置； mysql ~  which mysql /usr/local/bin/mysql ~  /usr/local/bin/mysql --help | grep -A1 'Default options' php ~  which php /usr/local/bin/php ~  /usr/local/bin/php -i | grep &quot;Loaded Configuration File&quot; apache ps -ef | grep 'http' /usr/local/apache2/bin/httpd -V | grep 'SERVER_CONFIG_FILE' 拼起来就是： /usr/local/apache2/conf/httpd.conf nginx ps -ef | grep 'nginx' 如果没有 那就根据上图中的nginx位置执行 ~  /usr/local/opt/nginx/bin/nginx -t nginx: the configuration file /usr/local/etc/nginx/nginx.conf syntax is ok nginx: configuration file /usr/local/etc/nginx/nginx.conf test is successful nginx和配置项的目录全有了； php-fpm ps -ef | grep 'php-fpm' openssl ~  openssl version -a LibreSSL 2.8.3 built on: date not available platform: information not available options: bn(64,64) rc4(16x,int) des(idx,cisc,16,int) blowfish(idx) compiler: information not available OPENSSLDIR: &quot;/private/etc/ssl&quot; ~  which openssl /usr/bin/openssl 配置项文件路径一眼就看到了； ","link":"https://www.vincent.ac.cn/post/zSdzi_lTD/"},{"title":"Go 学习笔记 第二弹 初识编写第一个Go程序与package","content":"第一个Go程序 up 搭建完 go 的运行环境 可以开始写程序代码了我们先来写个 hello world up 在 GoProject 目录 src 下创建一个 study 项目目录，之后up又创建了 day01 目录来存放今天学习的代码 首先右键创建一个 go 文件 文件名填写 main 回车 创建成功后你会发现创建的文件里自动书写了 package day01 代码，我们需要把 day01 改成 main ，应为一个独立可执行的 Go 语言程序必须有 package main 声明。 并书写以下代码并执行 package main import &quot;fmt&quot; func main() { fmt.Print(&quot;hello world!&quot;) } 如果不出意外 hello world! 变打印出来了 第一个 Go 程序就完成了， 这里面有些需要注意的。 程序中必须包含main包 func表示后面跟的是一个函数 main函数是整个程序的入口，所有的包围main包 每行代码结尾都没有分号 Print() 函数首字母大写 下面我们来了解一下 package package 基本使用 package是 Go管理代码的重要工具 每一个 Go 语言程序都必须是一些包的一部分，一个独立可执行的 Go 语言程序必须有 package main 声明。如果一个程序是 main 包的一部分，那么在 go install 则会生成一个二进制文件，在执行时则会调用 main 函数。如果一个程序除了 main 包外还是其他包的一部分，那么在使用 go install 命令时会创建包存档文件。 项目中的每个文件夹都是一个package。package下可以嵌套package。但每个.go文件的package以其所在的当前文件夹为准。 在GoLand中新建文件夹时，在该层目录下新建的.go文件，其package默认为当前文件夹名（大小写一致）。当.go文件创建后，再去修改文件夹名时，需要注意其下的.go文件中的package是否自动修改。 同一层目录下的.go文件，package必须一致，否则编译出错。 package main Go 的所有文件都需要指定其所在的包（package），包有两种类型，一种是 main 包，使用 package main 在代码的最前面声明。另外一种就是 非main 包，使用 package + 包名 。main包的可以有唯一的一个 main 函数，这个函数也是程序的入口。也只有 main 包可以编译成可执行的文件。 上面写的代码就是个简单的例子 在 study 下创建了一个 day01目录，day01 里有个main.go文件。main.go 的第一行声明了这是一个 main 包，因此可以定义一个 main 函数。使用 go run 可以编译并运行 main.go。虽然 main 包的文件名也是 main.go，其实包名和文件名没有直接关系。 自定义 package Go 使用 package 来管理源文件。package 必须在一个文件夹内，且一个文件夹内也只能有一个package，但是一个文件夹可以有多个文件。下面自定义一个 package。 up先在day01目录下创建个A目录，A目录下创建一个test.go 文件 package Atest import &quot;fmt&quot; func TestPrint() { fmt.Println(&quot;这是一个测试 Print&quot;) } 然后在 main.go 文件中，通过 import &quot;study/day01/A&quot; 引入了Atest 包所在的文件夹。最后通过 包名.包函数 调用 package main import ( &quot;fmt&quot; &quot;study/day01/A&quot; ) func main() { fmt.Println(&quot;hello world!&quot;) Atest.TestPrint() } 包名为 Atest，文件夹为 A，文件为 test.go。它们三者的命名都是不一样的。这与很多其他语言相悖。正如前文所言，一个包可以分散在不同的同级文件里，只要都声明为一个包名即可。例如下面再增加一个文件 demo.go package Atest import &quot;fmt&quot; func demoPrintln() { fmt.Println(&quot;这是一个demo&quot;) } 在 main 函数里同样使用 包名.包函数 ---- Atest.demoPrintln() 调用 其实很好理解，即同样的一个包，文件内容太多，拆分成多个文件而已。文件名跟包名没有直接关系。如果只有一个文件，通常可以写成包名。但是导入的时候，必须导入包所在的文件夹的路径。其实可以这样理解，import 的是 path（路径），那么go就去那个路径下搜索，搜索当然是查找包名。只不过通常习惯是 文件名 和 包名一致。 这包名和文件夹名不一致，是反模式。主要是为了直观的表示包名和文件夹名没有直接关系。 内嵌 package 在 A 内再创建一个文件夹 Atest，此时再命名一个 Atest.go 文件。即 文件夹名 和 包名 一致。其内容如下 package Atest import &quot;fmt&quot; func AtestPrint() { fmt.Print(&quot;AtestPrint&quot;) } up 在用 import 导入包所在的文件夹，因此up来修改 main.go 把 &quot;study/day01/A/Atest&quot; 引入进来， 但是还按照刚刚的这种方法引入编译会报错 显然，在 A 文件内的 test.go 和 demo.go 声明了 package Atest。在 A/Atest 文件夹里的 Atest.go 也声明为 Atest。这是同名的两个包，但是在 main 函数里，都是使用包名引用函数。由于名字冲突，无法确定到底使用那个 Atest 包，进而报错。解决方法也很简单，给包名增加一个别名即可。 package main import ( &quot;fmt&quot; Atest &quot;study/day01/A&quot; testNew &quot;study/day01/A/Atest&quot; ) func main() { fmt.Println(&quot;hello world!&quot;) Atest.TestPrint() Atest.DemoPrintln() testNew.AtestPrint() } 这样Atest与testNew两者空间就相互隔离了，在次运行代码 AtestPrint 便被打印出来了 ","link":"https://www.vincent.ac.cn/post/wfH7LDssy/"},{"title":"Go 学习笔记 第一弹 mac 开发环境搭建","content":"安装 Go 安装 brew install go 验证 go version 配置GOPATH 查看变量环境 执行 go env 修改变量环境 cd ~ 进入根目录 vim ~/.zshrc 编辑该文件如果没有安装 zsh 请运行vim ~/.bash_profile 输入下列内容 export GOROOT=/usr/local/Cellar/go/1.13.1/libexecGOROOT=/usr/local/Cellar/go/1.13.1/libexec export GOPATH=/Users/vincent/GoProject export GOBIN=$GOPATH/bin export PATH=$PATH:$GOBIN:$GOROOT/bin 使立即生效 source ~/.zshrc 如果没有安装 zsh 请运行 source ~/.bash_profile 再输入 go env 可以看到刚才配置的自定义项目路径 配置说明 GOROOT：安装目录（go语言安装目录）。 GOPATH：工程目录（自己工程项目目录）。 GOBIN：可执行文件目录。 PATH：将go可执行文件加入PATH中，使GO命令与我们编写的GO应用可以全局调用。 GOPATH包含三个目录：bin、pkg、src。 src目录：源文件。 pkg目录：编译好的库文件，主要是*.a文件。 bin目录：可执行文件。 注意：千万不要把GOPATH设置成go的安装路径。 GO语言项目结构 在进行Go语言开发的时候，我们的代码总是会保存在$GOPATH/src目录下。在工程经过go build、go install或go get等指令后，会将下载的第三方包源代码文件放在$GOPATH/src目录下， 产生的二进制可执行文件放在 $GOPATH/bin目录下，生成的中间缓存文件会被保存在 $GOPATH/pkg 下。 如果我们使用版本管理工具（Version Control System，VCS。常用如Git）来管理我们的项目代码时，我们只需要添加$GOPATH/src目录的源代码即可。bin 和 pkg 目录的内容无需版本控制。 适合个人开发者 我们知道源代码都是存放在GOPATH的src目录下，那我们可以按照下图来组织我们的代码。 目前流行的项目结构 Go语言中也是通过包来组织代码文件，我们可以引用别人的包也可以发布自己的包，但是为了防止不同包的项目名冲突，我们通常使用顶级域名来作为包名的前缀，这样就不担心项目名冲突的问题了。 因为不是每个个人开发者都拥有自己的顶级域名，所以目前流行的方式是使用个人的github用户名来区分不同的包。 举个例子：A和B都有一个名叫test的项目，那么这两个包的路径就会是： import &quot;github.com/A/test&quot; 和 import &quot;github.com/B/test&quot; 以后我们从github上下载别人包的时候，如： go get github.com/A/test 那么，这个包会下载到我们本地GOPATH目录下的src/github.com/A/test 使用GoLand 来编写 Go 其实也不用配置啥，新建项目时你需要填写 Location 和 GOPATH 就OK了 Location：就是你的代码存放目录，这里的 /Users/vincent/GoProject 就是上面所说的 GOPATH 路径，可以使用 go env 来查看当前的GOPATH路径，/src 是源代码目录，你的项目必须放在这个目录下，/study 就是你的项目目录了，这个名称可以自己修改 GOROOT：go安装路径，点击右边的箭头选择，会默认带出系统的go安装路径，选择就好 至此，go的安装与配置就好了。。。 ","link":"https://www.vincent.ac.cn/post/8iwfLXyXo/"},{"title":"Mac小技巧 增强快速预览功能","content":"开个新篇记录下Mac的使用小技巧 默认在 mac 上是在文件上按空格键预览，但是这个预览的功能特别的简陋，预览个 php 这类文件没有高亮，json 之类的文件更惨直接就没法预览 这时候就需要 Quick Look plugins 了 它主要有以下功能： 高亮预览代码文件 预览没有后缀的文本文件 预览 markdown 文件 预览 json 文件 预览压缩文件 预览时显示图片的像素尺寸和文件大小 预览 webp 文件 预览 pkg 文件 预览 ase 文件 预览视频文件 安装 brew cask install qlcolorcode qlstephen qlmarkdown quicklook-json webpquicklook suspicious-package quicklookase qlvideo MacOS 10.14 Mojave 以上版本不能通过 brew 安装预览图片像素尺寸和文件大小的 qlImageSize ； 这里需要手动编译安装 先下载xcode 安装完成后运行如下命令 sudo xcode-select -switch /Applications/Xcode.app 使用 git clone 代码 cd ~ &amp;&amp; git clone git@github.com:Nyx0uf/qlImageSize.git xcodebuild cd ~/qlImageSize &amp;&amp; xcodebuild 将 qlImageSize.qlgenerator 移动到 QuickLook 目录 mv ~/qlImageSize/build/Release/qlImageSize.qlgenerator ~/Library/QuickLook/ ","link":"https://www.vincent.ac.cn/post/MRSx8I4Yg/"},{"title":"laravel 模型Eloquent ORM 添加编辑删除","content":"既然玩了查询接着来玩玩添加编辑删除 CURD要完整嘛 添加 一般是前端传过来数据存到数据库，模型有一个 create 方法就是用来新增数据的，up 建个 store 方法 function store(Test $TestMdl) { $postData = [ 'testId' =&gt; '6', 'title' =&gt; '这是个title6', 'email' =&gt; '6666@qq.com', 'describe' =&gt; '这是个describe6', ]; $TestMdl-&gt;create($postData); } 如果我们直接访问这个方法是会报错的 因为在模型默认不允许进行批量赋值需要先定义允许 create 方法插入到数据库的字段,就是给 $fillable 属性定义允许赋值的字段 up 先在模型中定义 $fillable 属性 /** * 可以被批量赋值的属性。 * * @var array */ protected $fillable = ['testId', 'title', 'email', 'describe']; 再次访问 store 就可以把数据插入到数据库中了,如果字段很多一个个定义贼慢，这时便需要 $guarded 属性 登场了，这个属性是用来定义不允许复制的字段的，但是up现在不需要保护表里的字段。那么直接给 $guarded 赋值为空数组就等于没有任何限制了 /** * 不可批量赋值的属性。 * * @var array */ protected $guarded = []; 需要注意的是 $fillable 和 $guarded 只能定义其中的一个,不能同时存在 create 方法的返回值就是当前插入到数据库中的内容up可以通过返回值判断成功或者失败而实际开发中up经常需要返回新增数据的id那直接访问返回值的 id 属性即可。 function store(Test $TestMdl) { $postData = [ 'testId' =&gt; '8', 'title' =&gt; '这是个title8', 'email' =&gt; '6666777888@qq.com', 'describe' =&gt; '这是个describe888', ]; $res = $TestMdl-&gt;create($postData); dump($res); dump($res-&gt;id); } 编辑 刚刚添加了数据这边在编辑下数据咯，这里就要用到 update 方法了，这个就简单了 function update(Test $TestMdl) { $postId = 8; $postData = [ 'testId' =&gt; '8', 'title' =&gt; '这是个title8888866666', 'email' =&gt; '6666777888@qq.com', 'describe' =&gt; '这是个describe88866666', ]; $res = $TestMdl-&gt;where('id',$postId)-&gt;update($postData); dump($res); } update 方法的返回值是被改动的数据的条数 我们查看下数据 数据中一眼就发现了后三条数据的不同，我们之前用 DB 插入到数据库中的数据 created_at 和 updated_at 字段都是空,而我们用模型插入和修改后 created_at 和 updated_at 自动都变成了插入或者修改的时间了,这就是使用模型的好处一大好处 删除 但是最后的这个 deleted_at 是空的，这个字段应该怎么用呢？接下来 up 来学下模型的删除。 删除数据是一件很危险的行为，up 刚刚入行的时候不小心给生产环境的用户表删除了，当时全靠谷歌用的好给恢复了不然我就跑路了😄，现实版删库跑路😂。当时我希望能有一个恢复删除的功能比如说回收站，laravel 的模型为我们提供了很方便的软删除功能 要启用软删除首先数据表需要有 deleted_at 字段 之前玩迁移的时候简单的说了下创建迁移的时候调用 softDeletes 即可,模型默认是没有开启软删除功能的开启也很简单就是使用SoftDeletes &lt;?php namespace App\\Models; use Illuminate\\Database\\Eloquent\\Model; use Illuminate\\Database\\Eloquent\\SoftDeletes; class Test extends Model { use SoftDeletes; } Tip： SoftDeletes trait 会自动将 deleted_at 属性转换成 DateTime / Carbon 实例 当然，你需要把 deleted_at 字段添加到数据表中。 Laravel 的 数据库迁移 有创建这个字段的方法 现在，当你在模型实例上使用 delete 方法， 当前日期时间会写入 deleted_at 字段。同时，查询出来的结果也会自动排除已被软删除的记录。 /** * 删除数据 */ public function delete(Test $TestMdl) { $id = 8; $result = $TestMdl-&gt;where('id', $id)-&gt;delete(); dump($result); } 让我来查询一下数据 数据并没有真正被删除只是 deleted_at 不是 null 而是删除的时间了 让我们用代码去查询一下访问一下之前的 index 方法 up发现 id等于8的数据已经查询不到了，如果想查询到这条数据改怎么做呢，可以调用 withTrashed 方法 function getWith(Test $testMdl) { $data = $testMdl-&gt;withTrashed()-&gt;get(); dump($data-&gt;toArray()); } 我们来访问一下 现在刚刚软删除的数据又回来了，如果up只想查询乱删除的数据呢？可以用 onlyTrashed 方法 function getOnly(Test $testMdl) { $data = $testMdl-&gt;onlyTrashed()-&gt;get(); dump($data-&gt;toArray()); } 到这一步离实现回收站功能 就差个能恢复删除的方法，很简单调用 restore 方法即可 function restoreData(Test $testMdl) { $id = 8; $data = $testMdl-&gt;where('id', $id)-&gt;restore(); dump($data); } 执行完这个在查询下数据库 up 发现 deleted_at 已经被置空这个时候在请求 index 方法 之前乱删除的数据变恢复回来了 但是如果要彻底删除改怎么做呢？同样很简单调用 forceDelete 方法即可 function completelyDelete(Test $testMdl){ $id = 8; $data = $testMdl-&gt;where('id', $id)-&gt;forceDelete(); dump($data); } 执行完毕后up来查询下数据库 id等于8的数据被彻底删除啦 到现在增删改查 up 就都了解了 我的博客即将同步至腾讯云+社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=15aa76to9flt0 ","link":"https://www.vincent.ac.cn/post/26UdNhbpe/"},{"title":"laravel 模型Eloquent ORM 查询","content":"up前面玩了 DB 查询，但是laravel开发基本不怎么使用db方式查询，应该有更强大的 模型 Model 介绍 Laravel 的 Eloquent ORM 提供了一个漂亮、简洁的 ActiveRecord 实现来和数据库交互。每个数据库表都有一个对应的「模型」用来与该表交互。你可以通过模型查询数据表中的数据，以及在数据表中插入新记录。 在开始之前，请确保在 config/database.php 中配置数据库连接。更多关于数据库配置的信息，请查看 文档。 模型 就是把数据库的表映射到模型类，用面向对象的方式来操作数据库，既然是面向对象自然就可以继承了可以方便的复用。 laravel 的 Model 使用先进的 Eloquent ORM 但也有优缺点 优点是数据库的操作变的简单安全 缺点也明显数据库的操作变的缓慢笨重 Eloquent ORM 作为 laravel 中亮点，Taylor 可是耗费了相当大的精力，用起来当真是没的说 操作-创建个 Model up这里先创建个 Model，其他就是个类文件。使用的是单数形式帕斯卡命名法 ，也就是首字母大写的驼峰命名法 比如 up之前创建的 test表 Model 命名就是 Test.php 但是呢， laravel 都能 用命令创建控制器生成表跟数据填充了，自然也能生成 模型咯！ 直接运行 artisan 命令就行 php artisan make:model Test 运行命令后看到 Model created successfully. 提示就表示model 创建成功了 但是up发现这个文件是建在跟目录下的 app 目录下的 这就坑爹了，表很多的话都生成在这个目录强迫症处女座的up怎么能忍，分分掀桌子的节奏。最后度娘告诉我命令行也是支持目录的,命令改一改就好了。未来方便找up统一就放app目录下的Models目录里 php artisan make:model Models/Test 执行完命令会自动创建 Models 目录 现在有了Model 接下来就是 调用他咯 调用 Model up 先创建一个新的控制器 TestMdlController 在里面写个index方法 &lt;?php namespace App\\Http\\Controllers; use App\\Models\\Test; use Illuminate\\Http\\Request; class TestMdlController extends Controller { // function index(Test $testMdl) { dump($testMdl-&gt;get()); } } 建好路由访问下 index 但是却报错了我们看到model生成的sql 莫名其妙拼接了一个 s 这里我百度了一下 artisan 生成的model 若没有特别指定，laravel系统会默认自动对应名称为「Eloquent类名称的小写复数形态」的数据库表 两种方式解决 第一种Eloquent中自定义$table，缺点：如果是重构的项目，表名每个Eloquent都要重新定义可就有的哭了 ``` protected $table = 'test'; ``` 第二种添加自定义的Eloquent基类 BaseModel 黑科技可以永绝后患 &lt;?php namespace App\\Models; use Illuminate\\Database\\Eloquent\\Model; class BaseModel extends Model { //根据model class获取表名 表名中包含_，用驼峰自动转换 public function getTable() { return $this-&gt;table ? $this-&gt;table : class_basename($this); } } &lt;?php namespace App\\Models; use Illuminate\\Database\\Eloquent\\Model; class Test extends BaseModel { // } 以后的模型不要直接由 Eloquent 派生，改为由 BaseModel 派生，就不用特殊指定表名，表名与模型名称直接一致，也不再驼峰呀什么的了。毕竟是黑科技 改造完成后我们在来访问 index 可以看到能正常访问了，这时候我们就通过模型把数据全取出来了 和使用了 DB 取出来的数据一样的是都是一个 Collection 集合，不一样的是 DB 取出来的是数组，Model 取出来的是一个类，需要一层一层的剥开点到 attributes 我们才能看到数据 如果想更直观点查看的话就使用 toArray 方法转成数据 dump($data-&gt;toArray()); 但是有点写法可能不太明白这种类名跟一个变量直接当参数传给方法的 function index(Test $testMdl) laravel 中大量使用了这种方法，百度了下才知道这个东西叫做 依赖注入 。 当然除了依赖注入的方式我们还可以用传统的方式来玩比如 new 的方式来玩 function index(Test $testMdl) { // 依赖注入 $data = $testMdl-&gt;get(); dump($data-&gt;toArray()); // new 的方式 $TestMdlNew = new Test(); dump($TestMdlNew-&gt;get()-&gt;toArray()); } 当然也可以直接像调用静态方法 function index(Test $testMdl) { // 依赖注入 $data = $testMdl-&gt;get(); dump($data-&gt;toArray()); // new 的方式 $TestMdlNew = new Test(); dump($TestMdlNew-&gt;get()-&gt;toArray()); //直接调用静态方法 dump(Test::get()-&gt;toArray()); } 而且模型可以像 DB 那样链式调用，DB 有的那些方法模型也都有都是可以的 （拖篇幅别介意） function get(Test $TestMdl) { $data = $TestMdl-&gt;select('id', 'title', 'describe') -&gt;where('title', '&lt;&gt;', '文章1') -&gt;whereIn('id', [1, 2, 3]) -&gt;groupBy('id') -&gt;orderBy('id', 'desc') -&gt;get() -&gt;toArray(); dump($data); } 像 get 里面这一长串方法一样,我们在查询数据的时候经常会有略微复杂的查询把它们写成一个模型方法 比如说在 app/Models/Test.php 文件中写一个 getList 方法 &lt;?php namespace App\\Models; use Illuminate\\Database\\Eloquent\\Model; class Test extends BaseModel { /* * 获取 test 表指定数据 */ function getList(){ $data = $this-&gt;select('id', 'title', 'describe') -&gt;where('title', '&lt;&gt;', '文章1') -&gt;whereIn('id', [1, 2, 3]) -&gt;groupBy('id') -&gt;orderBy('id', 'desc') -&gt;get() -&gt;toArray(); return $data; } } 然后我们就可以在各个地方方便的复用了 function get(Test $TestMdl) { $data = $TestMdl-&gt;select('id', 'title', 'describe') -&gt;where('title', '&lt;&gt;', '文章1') -&gt;whereIn('id', [1, 2, 3]) -&gt;groupBy('id') -&gt;orderBy('id', 'desc') -&gt;get() -&gt;toArray(); dump($data); $data1 = $TestMdl-&gt;getList(); dump($data1); } ","link":"https://www.vincent.ac.cn/post/-JIl7kxRA/"},{"title":"在浏览器输入 URL 回车之后发生了什么（超详细版）","content":"这个问题已经是老生常谈了，更是经常被作为面试的压轴题出现，网上也有很多文章，但最近闲的无聊，然后就自己做了一篇笔记，感觉比之前理解更透彻了。 这篇笔记是我这两天看了数十篇文章总结出来的，所以相对全面一点，但由于我是做前端的，所以会比较重点分析浏览器渲染页面那一部分，至于其他部分我会罗列出关键词，感兴趣的可以自行查阅， 注意：本文的步骤是建立在，请求的是一个简单的 HTTP 请求，没有 HTTPS、HTTP2、最简单的 DNS、没有代理、并且服务器没有任何问题的基础上，尽管这是不切实际的。 大致流程 URL 解析 DNS 查询 TCP 连接 处理请求 接受响应 渲染页面 URL 解析 地址解析： 首先判断你输入的是一个合法的 URL 还是一个待搜索的关键词，并且根据你输入的内容进行自动完成、字符编码等操作。 HSTS 由于安全隐患，会使用 HSTS 强制客户端使用 HTTPS 访问页面。详见：你所不知道的 HSTS。 其他操作 浏览器还会进行一些额外的操作，比如安全检查、访问限制（之前国产浏览器限制 996.icu）。 检查缓存 DNS 查询 基本步骤 浏览器缓存 浏览器会先检查是否在缓存中，没有则调用系统库函数进行查询。 操作系统缓存 操作系统也有自己的 DNS缓存，但在这之前，会向检查域名是否存在本地的 Hosts 文件里，没有则向 DNS 服务器发送查询请求。 路由器缓存 路由器也有自己的缓存。 ISP DNS 缓存 ISP DNS 就是在客户端电脑上设置的首选 DNS 服务器，它们在大多数情况下都会有缓存。 根域名服务器查询 在前面所有步骤没有缓存的情况下，本地 DNS 服务器会将请求转发到互联网上的根域，下面这个图很好的诠释了整个流程： 根域名服务器：维基百科 需要注意的点 递归方式：一路查下去中间不返回，得到最终结果才返回信息（浏览器到本地DNS服务器的过程） 迭代方式，就是本地DNS服务器到根域名服务器查询的方式。 什么是 DNS 劫持 前端 dns-prefetch 优化 TCP 连接 TCP/IP 分为四层，在发送数据时，每层都要对数据进行封装： 应用层：发送 HTTP 请求 在前面的步骤我们已经得到服务器的 IP 地址，浏览器会开始构造一个 HTTP 报文，其中包括： 请求报头（Request Header）：请求方法、目标地址、遵循的协议等等 请求主体（其他参数） 其中需要注意的点： 浏览器只能发送 GET、POST 方法，而打开网页使用的是 GET 方法 传输层：TCP 传输报文 传输层会发起一条到达服务器的 TCP 连接，为了方便传输，会对数据进行分割（以报文段为单位），并标记编号，方便服务器接受时能够准确地还原报文信息。 在建立连接前，会先进行 TCP 三次握手。 关于 TCP/IP 三次握手，网上已经有很多段子和图片生动地描述了。 相关知识点： SYN 泛洪攻击 网络层：IP协议查询Mac地址 将数据段打包，并加入源及目标的IP地址，并且负责寻找传输路线。 判断目标地址是否与当前地址处于同一网络中，是的话直接根据 Mac 地址发送，否则使用路由表查找下一跳地址，以及使用 ARP 协议查询它的 Mac 地址。 注意：在 OSI 参考模型中 ARP 协议位于链路层，但在 TCP/IP 中，它位于网络层。 链路层：以太网协议 以太网协议 根据以太网协议将数据分为以“帧”为单位的数据包，每一帧分为两个部分： 标头：数据包的发送者、接受者、数据类型 数据：数据包具体内容 Mac 地址 以太网规定了连入网络的所有设备都必须具备“网卡”接口，数据包都是从一块网卡传递到另一块网卡，网卡的地址就是 Mac 地址。每一个 Mac 地址都是独一无二的，具备了一对一的能力。 广播 发送数据的方法很原始，直接把数据通过 ARP 协议，向本网络的所有机器发送，接收方根据标头信息与自身 Mac 地址比较，一致就接受，否则丢弃。 注意：接收方回应是单播。 相关知识点： ARP 攻击 服务器接受请求 接受过程就是把以上步骤逆转过来，参见上图。 服务器处理请求 大致流程 HTTPD 最常见的 HTTPD 有 Linux 上常用的 Apache 和 Nginx，以及 Windows 上的 IIS。 它会监听得到的请求，然后开启一个子进程去处理这个请求。 处理请求 接受 TCP 报文后，会对连接进行处理，对HTTP协议进行解析（请求方法、域名、路径等），并且进行一些验证： 验证是否配置虚拟主机 验证虚拟主机是否接受此方法 验证该用户可以使用该方法（根据 IP 地址、身份信息等） 重定向 假如服务器配置了 HTTP 重定向，就会返回一个 301永久重定向响应，浏览器就会根据响应，重新发送 HTTP 请求（重新执行上面的过程）。 关于更多：详见这篇文章 URL 重写 然后会查看 URL 重写规则，如果请求的文件是真实存在的，比如图片、html、css、js文件等，则会直接把这个文件返回。 否则服务器会按照规则把请求重写到 一个 REST 风格的 URL 上。 然后根据动态语言的脚本，来决定调用什么类型的动态文件解释器来处理这个请求。 以 PHP 语言的 MVC 框架举例，它首先会初始化一些环境的参数，根据 URL 由上到下地去匹配路由，然后让路由所定义的方法去处理请求。 浏览器接受响应 浏览器接收到来自服务器的响应资源后，会对资源进行分析。 首先查看 Response header，根据不同状态码做不同的事（比如上面提到的重定向）。 如果响应资源进行了压缩（比如 gzip），还需要进行解压。 然后，对响应资源做缓存。 接下来，根据响应资源里的 MIME 类型去解析响应内容（比如 HTML、Image各有不同的解析方式）。 渲染页面 浏览器内核 不同的浏览器内核，渲染过程也不完全相同，但大致流程都差不多。 基本流程 HTML 解析 首先要知道浏览器解析是从上往下一行一行地解析的。 解析的过程可以分为四个步骤： 解码（encoding） 传输回来的其实都是一些二进制字节数据，浏览器需要根据文件指定编码（例如UTF-8）转换成字符串，也就是HTML 代码。 预解析（pre-parsing） 预解析做的事情是提前加载资源，减少处理时间，它会识别一些会请求资源的属性，比如img标签的src属性，并将这个请求加到请求队列中。 符号化（Tokenization） 符号化是词法分析的过程，将输入解析成符号，HTML 符号包括，开始标签、结束标签、属性名和属性值。 它通过一个状态机去识别符号的状态，比如遇到&lt;，&gt;状态都会产生变化。 构建树（tree construction） 注意：符号化和构建树是并行操作的，也就是说只要解析到一个开始标签，就会创建一个 DOM 节点。 在上一步符号化中，解析器获得这些标记，然后以合适的方法创建DOM对象并把这些符号插入到DOM对象中。 ```HTML &lt;html&gt; Web page parsing Web page parsing This is an example Web page. ``` ![](https://www.vincent.ac.cn//post-images/1573718234151.jpg) 浏览器容错进制 你从来没有在浏览器看过类似”语法无效”的错误，这是因为浏览器去纠正错误的语法，然后继续工作。 事件 当整个解析的过程完成以后，浏览器会通过DOMContentLoaded事件来通知DOM解析完成。 CSS 解析 一旦浏览器下载了 CSS，CSS 解析器就会处理它遇到的任何 CSS，根据语法规范解析出所有的 CSS 并进行标记化，然后我们得到一个规则表。 CSS 匹配规则 在匹配一个节点对应的 CSS 规则时，是按照从右到左的顺序的，例如：div p { font-size :14px }会先寻找所有的p标签然后判断它的父元素是否为div。 所以我们写 CSS 时，尽量用 id 和 class，千万不要过度层叠。 渲染树 其实这就是一个 DOM 树和 CSS 规则树合并的过程。 注意：渲染树会忽略那些不需要渲染的节点，比如设置了display:none 的节点。 计算 通过计算让任何尺寸值都减少到三个可能之一：auto、百分比、px，比如把rem转化为px。 级联 浏览器需要一种方法来确定哪些样式才真正需要应用到对应元素，所以它使用一个叫做specificity的公式，这个公式会通过： 标签名、class、id 是否内联样式 !important 然后得出一个权重值，取最高的那个。 渲染阻塞 当遇到一个script标签时，DOM 构建会被暂停，直至脚本完成执行，然后继续构建 DOM 树。 但如果 JS 依赖 CSS 样式，而它还没有被下载和构建时，浏览器就会延迟脚本执行，直至 CSS Rules 被构建。 所有我们知道： CSS 会阻塞 JS 执行 JS 会阻塞后面的 DOM 解析 为了避免这种情况，应该以下原则： CSS 资源排在 JavaScript 资源前面 JS 放在 HTML 最底部，也就是 前 另外，如果要改变阻塞模式，可以使用 defer 与 async，详见：这篇文章 布局与绘制 确定渲染树种所有节点的几何属性，比如：位置、大小等等，最后输入一个盒子模型，它能精准地捕获到每个元素在屏幕内的准确位置与大小。 然后遍历渲染树，调用渲染器的 paint() 方法在屏幕上显示其内容。 合并渲染层 把以上绘制的所有图片合并，最终输出一张图片。 回流与重绘 回流(reflow) 当浏览器发现某个部分发现变化影响了布局时，需要倒回去重新渲染，会从html标签开始递归往下，重新计算位置和大小。 reflow基本是无法避免的，因为当你滑动一下鼠标、resize 窗口，页面就会产生变化。 重绘(repaint) 改变了某个元素的背景色、文字颜色等等不会影响周围元素的位置变化时，就会发生重绘。 每次重绘后，浏览器还需要合并渲染层并输出到屏幕上。 回流的成本要比重绘高很多，所以我们应该尽量避免产生回流。 比如： display:none 会触发回流，而 visibility:hidden 只会触发重绘。 JavaScript 编译执行 大致流程 可以分为三个阶段： 词法分析 JS 脚本加载完毕后，会首先进入语法分析阶段，它首先会分析代码块的语法是否正确，不正确则抛出“语法错误”，停止执行。 几个步骤： 分词，例如将var a = 2，，分成var、a、=、2这样的词法单元。 解析，将词法单元转换成抽象语法树（AST）。 代码生成，将抽象语法树转换成机器指令。 预编译 JS 有三种运行环境： 全局环境 函数环境 eval 每进入一个不同的运行环境都会创建一个对应的执行上下文，根据不同的上下文环境，形成一个函数调用栈，栈底永远是全局执行上下文，栈顶则永远是当前执行上下文。 创建执行上下文 创建执行上下文的过程中，主要做了以下三件事： 创建变量对象 参数、函数、变量 建立作用域链 确认当前执行环境是否能访问变量 确定 This 指向 执行 JS 线程 虽然 JS 是单线程的，但实际上参与工作的线程一共有四个： 其中三个只是协助，只有 JS 引擎线程是真正执行的 JS 引擎线程：也叫 JS 内核，负责解析执行 JS 脚本程序的主线程，例如 V8 引擎 &amp;事件触发线程：属于浏览器内核线程，主要用于控制事件，例如鼠标、键盘等，当事件被触发时，就会把事件的处理函数推进事件队列，等待 JS 引擎线程执行 定时器触发线程：主要控制setInterval和setTimeout，用来计时，计时完毕后，则把定时器的处理函数推进事件队列中，等待 JS 引擎线程。 HTTP 异步请求线程：通过XMLHttpRequest连接后，通过浏览器新开的一个线程，监控readyState状态变更时，如果设置了该状态的回调函数，则将该状态的处理函数推进事件队列中，等待JS引擎线程执行。 注：浏览器对同一域名的并发连接数是有限的，通常为 6 个。 宏任务 分为： 同步任务：按照顺序执行，只有前一个任务完成后，才能执行后一个任务 异步任务：不直接执行，只有满足触发条件时，相关的线程将该异步任务推进任务队列中，等待JS引擎主线程上的任务执行完毕时才开始执行，例如异步Ajax、DOM事件，setTimeout等。 微任务 微任务是ES6和Node环境下的，主要 API 有：Promise，process.nextTick。 微任务的执行在宏任务的同步任务之后，在异步任务之前。 代码例子 ``` console.log('1'); // 宏任务 同步 setTimeout(function() { console.log('2'); // 宏任务 异步 }) new Promise(function(resolve) { console.log('3'); // 宏任务 同步 resolve(); }).then(function() { console.log('4') // 微任务 }) console.log('5') // 宏任务 同步 ``` 以上代码输出顺序为：1,3,5,4,2 参考文档 what-happens-when-zh_CN Tags to DOM 彻底理解浏览器的缓存机制 浏览器的工作原理：新式网络浏览器幕后揭秘 深入浅出浏览器渲染原理 js引擎的执行过程（一） 还有一些找不到了。。。。。 本文作者：4Ark 本文链接： https://4ark.me/post/b6c7c0a2.html ","link":"https://www.vincent.ac.cn/post/jtBl6SuXF/"},{"title":"网络上收集的有关 Redis 方面的面试题 ","content":"假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来 使用keys指令可以扫出指定模式的key列表 ### 对应的问题 因为redis 是单线程 所以一次性操作大量的数据 可能会导致业务出现卡顿 ### 解决办法 这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长. Redis有哪些数据结构？ 字符串String、字典Hash、列表List、集合Set、有序集合SortedSet。 如果你是Redis中高级用户，还需要加上下面几种数据结构HyperLogLog、Geo、Pub/Sub。 如果你说还玩过Redis Module，像BloomFilter，RedisSearch，Redis-ML，面试官得眼睛就开始发亮了。 使用过Redis分布式锁么，它是什么回事？ 先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。 这时候对方会告诉你说你回答得不错，然后接着问如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？ 这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。 紧接着你需要抓一抓自己得脑袋，故作思考片刻，好像接下来的结果是你主动思考出来的 然后回答：我记得set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的！ 对方这时会显露笑容，心里开始默念：摁，这小子还不错。 使用过Redis做异步队列么，你是怎么用的？ 一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。 如果对方追问可不可以不用sleep呢？list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。 如果对方追问能不能生产一次消费多次呢？使用pub/sub主题订阅者模式，可以实现1:N的消息队列。 如果对方追问pub/sub有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。 如果对方追问redis如何实现延时队列？我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。 但是你很克制，然后神态自若的回答道：使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。 到这里，面试官暗地里已经对你竖起了大拇指。但是他不知道的是此刻你却竖起了中指，在椅子背后。 如果有大量的key需要设置同一时间过期，一般需要注意什么？ 如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。 Redis如何做持久化的？ bgsave做镜像全量持久化，aof做增量持久化。 因为bgsave会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要aof来配合使用。 在redis实例重启时，会使用bgsave持久化文件重新构建内存，再使用aof重放近期的操作指令来实现完整恢复重启之前的状态。 对方追问那如果突然机器掉电会怎样？取决于aof日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。 但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。 对方追问bgsave的原理是什么？你给出两个词汇就可以了，fork和cow。 fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。 Pipeline有什么好处，为什么要用pipeline？ 可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。 使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。 Redis的同步机制了解么？ Redis可以使用主从同步，从从同步。 第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存。 加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。、 是否使用过Redis集群，集群的原理是什么？ Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。 Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。 如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？ 这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。&lt;br&gt;这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。 redis如何实现延时队列？ 我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。但是你很克制，然后神态自若的回答道：&lt;br&gt;使用有序集合，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。 使用redis有哪些好处？ * (1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) * (2) 支持丰富数据类型，支持string，list，set，sorted set，hash * (3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 * (4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除 redis相比memcached有哪些优势？ * (1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 * (2) redis的速度比memcached快很多 * (3) redis可以持久化其数据 Memcache与Redis的区别都有哪些？ * 1)、存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，这样能保证数据的持久性。 * 2)、数据支持类型 Memcache对数据类型支持相对简单。 Redis有复杂的数据类型。 * 3)、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 redis常见性能问题和解决方案： * 1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。 * 2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。&lt;br&gt;Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 * 3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 * 4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内 为什么redis需要把所有数据放到内存中? Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。 Redis是单进程单线程的 redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销。 redis的并发竞争问题如何解决? Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是由于客户端连接混乱造成。对此有2种解决方法： * 1).客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。 * 2).服务器角度，利用setnx实现锁。 注：对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用synchronized也可以使用lock；第二种需要用到Redis的setnx命令，但是需要注意一些问题。 redis 最适合的场景 Redis最适合所有数据in-momory的场景，虽然Redis也提供持久化功能，但实际更多的是一个disk-backed的功能，跟传统意义上的持久化有比较大的差别，那么可能大家就会有疑问，&lt;br&gt;似乎Redis更像一个加强版的Memcached，那么何时使用Memcached，何时使用Redis呢?如果简单地比较Redis与Memcached的区别，大多数都会得到以下观点： 1. Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 2. Redis支持数据的备份，即master-slave模式的数据备份。 3. Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 * (1).会话缓存（Session Cache） 最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。 * (2).全页缓存（FPC） 除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。 再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。 此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 * (3).队列 Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。如果你快速的&lt;br&gt;在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。 * (4).排行榜/计数器 Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名&lt;br&gt;最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行： ZRANGE user_scores 0 10 WITHSCORES Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。 * (5).发布/订阅 最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！ ","link":"https://www.vincent.ac.cn/post/eQcNjr_UO/"},{"title":"什么是一致性哈希算法？","content":"一致性哈希算法 什么是一致性哈希算法 一致性hash就是 计算每个分布式服务器落点的算法 假设，服务器都在一个线上或则环上，缓存请求落点顺时针寻找最近的服务器，这样的好处就是，如果一台服务器down了，只会影响一段缓存，其他的不受影响，加减服务器成本降到最低，如果是余数散列算法，只要down掉一台缓存失败率上升至少80%，所以memcache分布式，都是用一致性hash算法来计算服务器散列位置的，你用php的memcached扩展，add服务器，可以选择散列算法，默认是一致性hash，也可以选择余数。 一致性hash的使用在PHP中有三种选择分别是原生的memcache扩展，memcached扩展，还有一个是网上比较流行的 Flexihash类。前两者都适用于memcache 但不适合Redis Flexihash 是一个小型PHP库，实现了一致的哈希，这在分布式缓存中最有用。 一致性哈希算法简介 一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用 目前主要应用于分布式缓存当中，一致性哈希可以有效地解决分布式存储结构下动态增加和删除节点 一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义 平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。 单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。 在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。 传统哈希方式 在分布式缓存系统中吗，需要将数据均匀的分布到缓存服务器集群的不同机器上。 需要对缓存的key做hash值计算，将hash值除以服务器节点的数量取模计算出数据需要落在哪台服务器节点上。 缓存策略的潜在问题是如果增加或删除机器时（N变化）代价会很高，所有的数据都不得不根据id重新计算一遍哈希值，并将哈希值对新的机器数进行取模操作，然后进行大规模的数据迁移为了解决这些问题，引入一致性哈希算法。假设数据的id通过哈希函数转换成的哈希值范围是232，也就是（0~232-1）的数字空间中。 我们将这些数字头尾相连，想象成一个闭合的环形，那么一个数字id在计算出哈希值之后认为对应到环中的一个位置上接下来，想象有三台机器也处于这样一个环中，这三台机器在环中的位置根据机器id计算出的哈希值来决定。那么一条数据如何确定归属哪台机器呢？首先把该数据的id用哈希值算出哈希值，并映射到环中的相应位置，然后顺时针找寻离这个位置最近的机器，那台机器就是该数据的归属。例如，下图有一个数据m，计算其hash值后映射到环上，那么他的归属就是2号机器 这种算法很简单，也可以实现数据的均匀分布。但是增加或者减少数据节点的时候会导致所有缓存数据失效。 举个栗子： 例如10条数据，3个节点，如果按照传统hash结构对3进行取模： node a：0，3，6，9 node b：1，4，7 node c：2，5，8 当增加一个节点的时候，数据分布变更为对4进行取模： node a：0，4，8 node b：1，5，9 node c：2，6 node d：3，7 然后，我们就可以看到，我们需要迁移的节点：3，4，5，6，7，8，9成本是不是很高 一致性哈希方式 一致性Hash算法最关键的区别就是：对节点和数据，都做一次哈希运算，然后比较节点和数据的哈希值，数据存放在下一个的节点中，这样就会保证节点增加或者减少的时候，影响的数据最少。 例子 还是刚才的例子（使用简单的字符串 ascii码 做哈希key） 求出数据的hash值 0：192 1：196 2：200 3：204 4：208 5：212 6：216 7 ：220 8：224 9：228 求出节点的hash值 node a：203 node g：209 node z：228 这时候，我们就可以将整个Hash值看做一个环，比较数据和节点的hash值，如果大于228，那么就归到前面的203上 求出节点的hash值 node a：0，1，2 node g：3，4 node z：5，6，7，8，9 加入了node：n节点之后 node n：216 这个时候对应的数据就会做迁移 node a： 0，1，2 node g：3，4， node n：5，6 node z：7，8，9 于是我们可以看到：只有5，6节点需要迁移。 这个算法是厉害，但是若是服务节点过少的情况下，是不是会导致节点分配不均匀可能会导致数据倾斜的问题呢？ 为了解决数据倾斜的问题，一致性哈希算法引入了虚拟节点机制：即对每一个服务节点计算多个哈希，每个计算得到的Hash位置都放置一个此服务节点，称虚拟节点。具体可以在服务器ip或主机名的后面增加编号来实现。 结点（机器）删除 以上面的分布为例，如果Node2（机器2）出现故障被删除了，那么按照顺时针迁移的方法，Hash值属于图中红色片段的所有数据将会被迁移到Node3（机器）中，这样仅仅是红色的一段映射位置发生了变化，其它的对象没有任何的改动。如下图： 结点（机器）添加 如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中，如下图： 按照顺时针迁移的规则，数据Hash值处于红色段的数据被迁移到了Node4中，其它对象还保持这原有的存储位置。通过对节点的添加和删除的分析，一致性哈希算法在保持了单调性的同时，数据的迁移时间达到了最小，这样的算法对分布式集群来说是非常合适的，避免了大量数据迁移，减小了服务器的的压力 一致性哈希算法优化 其实上面的一致性哈希函数还存在一个很大的问题，我们说Hash函数是输入的样本量很大的时候，其输出结果在输出域上是均匀分布的，但是这里假如只有三个输入，就很难保证分布是均匀的，有可能产生下图所示的分布，就导致负载极其不均衡 更加优化的一致性哈希算法引入了虚拟节点机制，即对每一台机器产生多个结点，称为虚拟节点。具体做法可以在机器ip或主机名的后面增加编号或端口号来实现。假设一台机器有1000个虚拟节点，3台机器就有3000个结点，3000个结点映射到哈希域上就相对比较均匀了 由于水平原因，本文参考了多篇文章 https://www.cnblogs.com/clarencezzh/p/11703747.html https://www.jianshu.com/p/8469954d3b45 ","link":"https://www.vincent.ac.cn/post/QUyR68yNI/"},{"title":"swoole入门 server 跟 client","content":" 刚刚 up 了解了下 swoole 并安装了环境接下来 up 迫不及待的了解下 server 与 client 一、server ###那么什么是server呢 ？ 顾名思义就是服务端。up 平时接触比较多的无非就是 nginx 和 apache。作为 webServer，二者都是通过监听某端口对外提供服务,swoole 的 server 也不例外同样需要绑定端口,同时能够提供给客户端相关的服务。 创建一个server对象 创建 server 的步骤 实例化 Server 对象 设置运行时参数 注册事件回调函数 启动服务器 示例 server 的创建，只需要绑定要监听的 ip 和端口，如果ip指定为 127.0.0.1，则表示客户端只能位于本机才能连接，其他计算机无法连接，如果需要所有的客户端都能连接则可以设置 0.0.0.0 端口这里指定为 9501，可以通过 netstat 查看下该端口是否被占用。如果该端口被占用，可更改为其他端口，如 9502，9503 等。 配置 在享受 swoole 的 server 之前,同样 up 需要配置一下 server，比如调几个人来提供服务（几个进程），以及是否是后台执行（守护进程）等等一些其它的配置。 这个就需要我们做一些配置了，但是并非像 fpm 直接在文件内配置，我们可以在 server 创建后，通过 set 方法指定配置项。 同时，这个配置项也有很多，比如说我们可以指定日志文件记录具体的错误信息等等，你都可以在官网的手册上寻找有哪些配置项。 这里 up 首要说明一下 worker 进程数的配置，因为 swoole 是多进程的异步服务器所以需要设置工作进程数，提升服务器性能。 我们可以指定配置项 worker_num 等于某个正整数。这个正整数设置多少合适，即我要开多少个worker 进程处理们的业务逻辑才好呢我？官方建议我们设置为 CPU 核数的 1-4倍 。因为我们开的进程越多，内存的占用也就更多，进程间切换也就需要耗费更多的资源。up 这里设置开启两个 worker进程。默认该参数的值等于你机器的CPU核数。 事件驱动 swoole 另外一个比较吸引人的地方，就是swoole_server 是事件驱动的。我们在使用的过程中不需要关注底层是怎么实现的，底层是 C 写的php 只是做了个传递的作用，所以只需要对底层相应的动作注册相应的回调，在回调函数中处理业务逻辑即可。 什么意思呢？up 举个例子： 你启动了一个server，当客户端连接的时候（触发事件），你不需要关心它是怎么连接的，你就单纯的注册一个connect函数，做一些连接后的业务处理即可(执行业务)。类似于js的事件监听，比如触发了click 事件，就会执行相应的闭包。 ####Swoole监听的事件 up来看看几种常见的事件回调。 参数 $serv 是我们一开始创建的 swoole_server 对象，参数 $fd 是唯一标识，用于区分不同的客户端，同时该参数是 1-1600万之间 可以复用的整数。简单解释下复用：假设现在客户端1、2、3处于连接中，客户端4要连接的话 $fd 就是4，但是不巧的是客户端3连接不稳定，断掉了，客户端4连接到 server 的话，$fd 就是3，这样看的话。1600W 个连接够用吗？单机业务百万连接，已经是很厉害了，不用担心 监听客户端数据发送，触发回调 worker 进程内触发的。第三个参数 $fromId 指的是哪一个 reactor 线程，具体 up 会在学习多进程模型当中详细分析这里先忽略。。直接看第四个参数，这个参数就是服务端接受到的数据，注意是字符串或者二进制内容,注意我们在 Receive 回调内，调用了$serv的send方法，我们可以使用send方法，向client发起通知。 监听客户端关闭，触发回调 这个很简单，当客户端关闭，或者服务端主动关闭连接的时候会触发。到此呢，up基本上已经搭建到了一个高性能的 server。当然，非常简单，下面 up 只需要调用 start 方法启动 server 即可。 由于swoole_server只能运行在CLI模式下，所以不要试图通过浏览器进行访问，有听说过apache是基于nginx运行的吗，大家地位相同，只能配合，没有上下关系，up在命令行下面执行，自行去连接，这里不补充基础知识，tese.php 就是刚刚服务器的方法 up 平时执行完一个指令，执行完就结束了，但是现在的情况正好相反，当前程序一直处于执行中的状态，并没有退出终端。同时因为swoole的server是常驻内存运行的，所以如果修改了代码，需要ctrl+c中断，重新运行才行。在up在第一步初始化server时填写了ip和端口，就是说 server现在正在监听9501端口提供服务。当前终端暂时不动，up新开一个终端，查看端口发现确实如此。 server启动好了能干什么呢？常见的网络编程模式都是client-server的，也就是说up还需要模拟一个客户端与之交互。 二、同步client跟异步client 默认的swoole的server是可以提供tcp/udp socket请求协议，然后根据请求数据，执行相应的逻辑 在PHP中，我们常用socket函数来创建TCP连接，用CURL库来创建Http连接。同样的，为了简化操作，Swoole也提供了同样的Client类用于实现客户端的功能，并且增加了异步非阻塞的模式，让用户在客户端也能使用事件循环。 swoole_client 的构造函数 从上图可以看出一共三个参数 第一个参数： SWOOLE_SOCK_TCP 创建 tcp socket SWOOLE_SOCK_TCP6 创建 tcp ipv6 socket SWOOLE_SOCK_UDP 创建 udp socket SWOOLE_SOCK_UDP6 创建 udp ipv6 socket 第二个参数表示是同步还是异步 SWOOLE_SOCK_SYNC 同步客户端 SWOOLE_SOCK_ASYNC 异步客户端 第三个参数(暂不了解) 用于长连接的Key，默认使用IP:PORT作为key。相同key的连接会被复用 新建一个同步客户端 同步client是同步阻塞的。一整套connect-&gt;send()-&gt;rev()-&gt;close()是同步进行的。如果需要大量的数据处理，后台不能在规定的时间内返回数据会导致接收超时，并且因为是同步执行所以需要等待后台数据的返回。 同步异步概念 swoole是既支持全异步，也支持同步，同步跟异步的概念，我们需要了解 同步与异步的重点在消息通知的方式上，也就是调用结果通知的方式。 同步: 当一个同步调用发出去后，调用者要一直等待调用结果的通知后，才能进行后续的执行。 异步：当一个异步调用发出去后，调用者不能立即得到调用结果的返回。 生活中的例子： 同步买奶茶：小明点单交钱，然后等着拿奶茶； 异步买奶茶：小明点单交钱，店员给小明一个小票，等小明奶茶做好了，再来取。 异步客户端 当设定 swoole_client为异步模式后，swoole_client就不能使用recv方法了，而需要通过on方法提供指定的回调函数，然后在回调函数当中处理，也就是小明等待奶茶做好了异步通知,消息发送跟接收并不是同步运行的。 心跳检测 4.3被移除但是可能有其它的设备或者是语言是长连接,并且用来演示心跳检测 心跳是什么？ 顾名思义，心跳是判断一个事物生还是死的一个标准，在swoole里，心跳是指用来判断一个连接是正常还是断开的 为什么要心跳？ 心跳的目的其实是通过判断客户端是否存活，从而回收fd,系统为什么要回收fd，因为fd资源是有限的，所以必需重复利用 心跳作用主要有两个： 客户端定时给服务端发送点数据，防止连接由于长时间没有通讯而被某些节点的防火墙关闭导致连接断开的情况。 服务端可以通过心跳来判断客户端是否在线，如果客户端在规定时间内没有发来任何数据，就认为客户端下线。这样可以检测到客户端由于极端情况(断电、断网等)下线的事件。 心跳在swoole里的实现? swoole会在主进程独立起一个心跳线程，通过定时轮询所有的连接，来判断连接的生死，所以swoole的心跳不会堵塞任何业务逻辑。 设置完成了之后，你会发现设置了定时检测之后，如果客户端没在规定的时间之内发送数据就会关闭。 heartbeat_check_interval： 服务器定时检测在线列表的时间 heartbeat_idle_time： 连接最大的空闲时间 （如果最后一个心跳包的时间与当前时间之差超过这个值，则认为该连接失效） 配置建议 建议 heartbeat_idle_time 为heartbeat_check_interval 的两倍多一点。 这个两倍是为了进行容错，允许丢一个包而多一点是考虑到网络的延时。 为什么需要心跳包？客户端如何维持心跳？ 在从客户端到服务器的一条巨大的链路中会经过无数的路由器，其中每一个路由器都有可能会有检测到多少秒时间内无数据包则自动关闭连接的这种节能机制，为了让这个可能会出现的节能机制失效，客户端可以设置一个定时器，每隔固定的时间都发一个随机字符的一字节的数据包，通常我们把这种数据包就叫做心跳包。 实战案例 客户端设备发送一个请求，服务端接收，根据业务逻辑的需求服务端A需要发送一个请求到服务端B获取数据，再返回给服务端A，服务端A返回给客户端A。 服务端A既是客户端也是服务器,服务端A要发送请求到服务端B,然后服务端B返回消息给服务端A client $client = new swoole_client(SWOOLE_SOCK_TCP); $client-&gt;connect('127.0.0.1',9800) || exit('连接失败'); $client-&gt;send(&quot;我是客户端1&quot;); $client-&gt;send(&quot;我是客户端2&quot;); sleep(2); $client-&gt;send(&quot;我是客户端3&quot;); $res = $client-&gt;recv(); $data = json_decode($res,1); var_dump($data);//接收消息 //关闭 $client-&gt;close(); server1 echo &quot;运行脚本1&quot;.PHP_EOL; $server = new Swoole\\Server('0.0.0.0',9800); $server-&gt;set([ 'worker_num' =&gt; 1,//设置进程数 // 'heartbeat_idle_time' =&gt;10,//连接最大的空闲时间 // 'heartbeat_check_interval' =&gt; 3, //服务器定时检查 'open_eof_check' =&gt; true, //开启EOF结束协议 'package_eof' =&gt; &quot;\\r\\n&quot;, //设置结尾字符 'open_eof_split' =&gt; true //自动拆分 ]); //监听事件 $server-&gt;on('connect',function ($sev,$fd){ echo &quot;新的连接进入:&quot;.$fd.PHP_EOL; }); //消息发送过来 $server-&gt;on('receive',function (swoole_server $server, int $fd,$reactor_id,$data){ echo &quot;消息发送过来:&quot;.$fd.PHP_EOL; echo &quot;消息内容:&quot;.$data.PHP_EOL; echo &quot;请求服务端2:&quot;.PHP_EOL; $client = new swoole_client(SWOOLE_SOCK_TCP); if (!$client-&gt;connect('127.0.0.1', 9900)) { exit(&quot;connect failed. Error: {$client-&gt;errCode}\\n&quot;); } $client-&gt;send(&quot;我是服务端1&quot;); $data = array( 'server1' =&gt; '我是服务端1', 'server2' =&gt; $client-&gt;recv(), ); $client-&gt;close(); $server-&gt;send($fd,json_encode($data)); }); //消息关闭 $server-&gt;on('close',function (){ echo &quot;消息关闭&quot;.PHP_EOL; }); //服务开启 echo &quot;开启服务&quot;.PHP_EOL; $server-&gt;start(); server2 echo &quot;运行脚本2&quot;.PHP_EOL; $server = new Swoole\\Server('0.0.0.0',9900); $server-&gt;set([ 'worker_num' =&gt; 1,//设置进程数 // 'heartbeat_idle_time' =&gt;10,//连接最大的空闲时间 // 'heartbeat_check_interval' =&gt; 3, //服务器定时检查 'open_eof_check' =&gt; true, //开启EOF结束协议 'package_eof' =&gt; &quot;\\r\\n&quot;, //设置结尾字符 'open_eof_split' =&gt; true //自动拆分 ]); //监听事件 $server-&gt;on('connect',function ($sev,$fd){ echo &quot;新的连接进入:&quot;.$fd.PHP_EOL; }); //消息发送过来 $server-&gt;on('receive',function (swoole_server $server, int $fd,$reactor_id,$data){ echo &quot;消息发送过来:&quot;.$fd.PHP_EOL; echo &quot;消息内容:&quot;.$data.PHP_EOL; $server-&gt;send($fd,'我是服务端2'); }); //消息关闭 $server-&gt;on('close',function (){ echo &quot;消息关闭&quot;.PHP_EOL; }); //服务开启 echo &quot;开启服务&quot;.PHP_EOL; $server-&gt;start(); ","link":"https://www.vincent.ac.cn/post/qhuBcqwbw/"},{"title":"swoole入门 初识","content":" up 第一次初识 swoole 是在2017年11月份，还是从朋友那头得知的当时他在做一个直播的项目为此脑壳疼了好久，我也是从哪天起打开了新世界的大门发现PHP 不只如此。说起来惭愧直到2019年4月份才真正的开始接触学习 swoole，所以今后会将自己的成长之路记录下来加油 swoole介绍 让我们先来了解下swoole swoole 简介 swoole是PHP的异步、并行、高性能网络通信引擎，使用纯C语言编写，提供了PHP语言的异步多线程服务器，异步TCP/UDP网络客户端，异步MySQL，异步Redis，数据库连接池，AsyncTask，消息队列，毫秒定时器，异步文件读写，异步DNS查询。 Swoole内置了Http/WebSocket服务器端/客户端、Http2.0服务器端。 swoole提供的功能库 swoole提供了哪些功能给我们用，以为我们用到哪些服务时，可以用swoole来帮我们实现。 http服务 ，编写一个简单的web server。 TCP/UDP服务 ，编写一个消息接受处理系统。 异步，可以异步的处理请求。 并发 ，可以并发的处理同一个业务逻辑。 socket，socket通讯处理技术。 毫秒级别定时器，可以在php中使用定时器了。 协程，相比线程更稳定和好用。 如果你的业务中，有用到以上等特性，你又在用使用php，那么完全可以用swoole来完成了,再具体点的场景如下： 互联网 移动通信 企业软件 云计算 网络游戏 物联网（IOT） 车联网 智能家居等领域 swoole的框架 Hyperf 是基于 Swoole 4.4+ 实现的高性能、高灵活性的 PHP 协程框架，内置协程服务器及大量常用的组件，性能较传统基于 PHP-FPM 的框架有质的提升，提供超高性能的同时，也保持着极其灵活的可扩展性，标准组件均基于 PSR 标准 实现，基于强大的依赖注入设计，保证了绝大部分组件或类都是 可替换 与 可复用 的。框架组件库除了常见的协程版的 MySQL 客户端、Redis 客户端，还为您准备了协程版的 Eloquent ORM、WebSocket 服务端及客户端、JSON RPC 服务端及客户端、GRPC 服务端及客户端、Zipkin/Jaeger (OpenTracing) 客户端、Guzzle HTTP 客户端、Elasticsearch 客户端、Consul 客户端、ETCD 客户端、AMQP 组件、Apollo 配置中心、阿里云 ACM 应用配置管理、ETCD 配置中心、基于令牌桶算法的限流器、通用连接池、熔断器、Swagger 文档生成、Swoole Tracker、Blade 和 Smarty 视图引擎、Snowflake 全局ID生成器 等组件，省去了自己实现对应协程版本的麻烦。Hyperf 还提供了 基于 PSR-11 的依赖注入容器、注解、AOP 面向切面编程、基于 PSR-15 的中间件、自定义进程、基于 PSR-14 的事件管理器、Redis/RabbitMQ 消息队列、自动模型缓存、基于 PSR-16 的缓存、Crontab 秒级定时任务、Translation 国际化、Validation 验证器 等非常便捷的功能，满足丰富的技术场景和业务场景，开箱即用。 Swoft 首个基于 Swoole 原生协程的新时代 PHP 高性能协程全栈框架，内置协程网络服务器及常用的协程客户端，常驻内存，不依赖传统的 PHP-FPM，全异步非阻塞 IO 实现，以类似于同步客户端的写法实现异步客户端的使用，没有复杂的异步回调，没有繁琐的 yield, 有类似 Go 语言的协程、灵活的注解、强大的全局依赖注入容器、完善的服务治理、灵活强大的 AOP、标准的 PSR 规范实现等等，可以用于构建高性能的Web系统、API、中间件、基础服务等等。 EasySwoole EasySwoole 是一款基于Swoole Server 开发的常驻内存型PHP框架，专为API而生，摆脱传统PHP运行模式在进程唤起和文件加载上带来的性能损失。EasySwoole 高度封装了Swoole Server 而依旧维持Swoole Server 原有特性，支持同时混合监听HTTP、自定义TCP、UDP协议，让开发者以最低的学习成本和精力编写出多进程，可异步，高可用的应用服务。 SwooleDistributed SwooleDistributed 老牌Swoole框架拥有最完善的开发工具以及最强大的功能，首创SDHelper开发者工具包和开发者调试命令集，可以进行单元测试，捕获客户端流量分析，可视化的进行远程断点联调，还具备代码覆盖率检测的功能（swoole与xdebug扩展不兼容，SDHelper无需xdebug扩展），并且内置组件极其丰富（类MQTT强悍的订阅发布/Actor模型/内存高速缓存/事件派发/进程管理/定时任务/AMQP任务调度/后台监控/集群/微服务/RPC/异步连接池/自定义命令等等），开发者可以直接使用加快开发进度。几乎所有的功能都支持集群化，单机切换到集群无需对代码做任何的修改。如果业务开发比较复杂比如（游戏开发）那么SD框架将是你的不二之选。 环境部署-php7安装 一键安装包方式 简单粗暴适合快速安装，前期自己容易编译错误的时候，直接按照教程快速安装，可以用这种，up只知道两个一键安装 lnmp oneinstack 这里up 推荐用 oneinstack wget -c http://mirrors.linuxeye.com/oneinstack-full.tar.gz &amp;&amp; tar xzf oneinstack-full.tar.gz &amp;&amp; ./oneinstack/install.sh --nginx_option 1 --php_option 7 --phpcache_option 1 --php_extensions zendguardloader,ioncube,sourceguardian,gmagick,fileinfo,imap,ldap,phalcon,yaf,redis,memcached,memcache,mongodb,swoole,xdebug --phpmyadmin --db_option 2 --dbinstallmethod 1 --dbrootpwd oneinstack --pureftpd --redis --memcached --iptables --reboot 编译安装 大体步骤： 解压 configure make make install 生产环境下，自己掌握如何编译，并且安装扩展 首先通过wget命令下载到指定文件 Wget http://cn2.php.net/distributions/php-7.2.15.tar.gz 通过tar命令解压 tar -zxf php-7.2.15.tar.gz 进入目录利用 configure 生成安装文件 在安装包下面一般有个 configure， 是用来生成 Makefile，为下一步的编译做准备，你可以通过在 configure 后加上参数来对安装进行控制，具体可以通过 configure --help 查看相应的命令，这里只指定了php目录跟配置文件目录，开放了其中一部分扩展 ./configure --prefix=/usr/local/php \\--prefix=/usr/local/php \\--with-config-file-path=/usr/local/php/etc \\-with-libxml-dir=/usr \\--with-mhash \\--with-openssl \\--with-mysqli=shared,mysqlnd \\--with-pdo-mysql=shared,mysqlnd \\--with-zlib \\--enable-zip \\--enable-inline-optimization \\--disable-debug \\--disable-rpath \\--enable-shared \\--enable-xml \\--enable-bcmath \\--enable-shmop \\--enable-sysvsem \\--enable-mbregex \\--enable-mbstring \\--enable-pcntl \\--enable-sockets \\--without-pear \\--with-gettext \\--enable-session 编译前检查 想要编译必须要安装相应的依赖扩展库可以提前的下载这里使用yum来进行扩展安装，一般需要以下几个扩展支持，否则会出现错误 yum -y install gcc gcc-c++ libxml2-devel m4 autoconf pcre-devel make cmake bison openssl openssl-devel 正式安装 make &amp;&amp; make install CentOS下将php和mysql命令加入到环境变量中 开发过程中、需要使用到php命令执行程序、但是php命令没有在全局命令中；每次执行都需要加上全路径特别麻烦，把php命令添加到全局变量中，以后每次只用输入php可以了在centos7.2当中就可以使用下面的方式进行添加 vim /etc/profile 文件然后执行 source /etc/profile 让当前的配置生效 最后配置文件拷贝到指定的目录 php -i | grep Configuration 查询配置文件目录 将源码当中的配置文件指定到相应的目录 cp php.ini-development /usr/local/php/etc/php.ini 扩展安装示例、通过yum安装依赖，然后在ext目录安装,同样的编译方式，比如curl的安装 yum install libcurl-devel 环境部署-swoole源码编译安装 Swoole安装方式跟php安装方式是一样的，下载解压、编译 # 下载 git clone https://github.com/swoole/swoole-src.git #解压 cd swoole-src # 编译安装 phpize ./configure make &amp;&amp; make install ide提示工具 安装好之后呢。如果你还需要对你想对你的编辑器，比如：phpstrom 对swoole的代码提示功能，就可以下载帮助文件：https://github.com/swoole/ide-helper 点击setting选择languages 点击+号添加我们下载的文件 我的博客即将同步至腾讯云+社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=15aa76to9flt0 ","link":"https://www.vincent.ac.cn/post/ZSx6EOX69/"},{"title":"laravel 学习之路  Collections","content":"上文中我们从数据库查出的数据并不是我们常见的数组形式， 这就要了解下 Collections 对象，在 laravel 中 collection 是比数组更高等般的存在，我们可以像对待数组一样的来操作 collection，而且它还能以链式操作的方式便捷易读的处理数据，为了更直观的了解 up 定义个数组来看一下 function studyCollection() { # 随便创建个数组 $array = ['', 'u', '啦', 'p', '主', '真', '帅', false, null]; # 打印创建的数组 dump($array); # 把创建的数组转为 collection $collect = collect($array); # 打印 $collect dump($collect); # 然后就能像数组一样取值循环了 foreach ($collect as $K =&gt; $v) { dump($v); } } 但是仅仅是这的话似乎并不怎么样，下面我接着玩点花的。比如把 $array 中的啦字去掉，接着过滤掉其中为 false 为空字符串 为 null 的值 最后用 - 连接起来拼成 'up主真帅' 我们先用数组先玩一玩 function testArray() { $array = ['', 'u', '啦', 'p', '主', '真', '帅', false, null]; $collect = collect($array); // unset() 删除 '啦' 字 unset($array[2]); // array_filter() 过滤为假的值 // implode() 用 - 连接 dump(implode('-', array_filter($array))); } 接下来用 collect 玩玩 function testCollect() { $array = ['', 'u', '啦', 'p', '主', '真', '帅', false, null]; $collect = collect($array); // forget() 删除 '啦' 字 filter() 过滤为假的值 implode() 用 - 连接 dump($collect-&gt;forget(2)-&gt;filter()-&gt;implode('-')); } 两种方式打印出来的结果是一样的 操作再复杂点都用函数一层一层的的套的话就很崩溃了还是链式操作即直观又美观，为什么说 laravel 便是如此咯。 collection 其实有一大堆的功能可以供我们使用 回到刚刚的话题由于从数据库取出的数据本身就是一个 collection 所以可以直接使用这些方法 function getCollectData(){ $titles = DB::table('test')-&gt;pluck('describe', 'title')-&gt;implode('-'); dump($titles); } up 17年刚刚接触 laravel 的时候不知道 collection 是个啥，只知道数组数据库查出来的时候都懵逼了百度半天才知道 -&gt;toArray() 可以把 collection 转成数组，每次都是转成数组玩。直到后来同事吐槽我，我才知道 collection 的强大。 ","link":"https://www.vincent.ac.cn/post/JIjj0QEOH/"},{"title":"Linux 安装 minDoc 接口文档在线管理 ","content":"昨天被分配给公司安装 minDoc 水文记录一下安装的过程 MinDoc 是一款针对IT团队开发的简单好用的文档管理系统。 MinDoc 的前身是 SmartWiki 文档系统。SmartWiki 是基于 PHP 框架 laravel 开发的一款文档管理系统。因 PHP 的部署对普通用户来说太复杂，所以改用 Golang 开发。可以方便用户部署和实用。 开发缘起是公司IT部门需要一款简单实用的项目接口文档管理和分享的系统。其功能和界面源于 kancloud 。 可以用来储存日常接口文档，数据库字典，手册说明等文档。内置项目管理，用户管理，权限管理等功能，能够满足大部分中小团队的文档管理需求。 下载 我是从 https://github.com/lifei6671/mindoc/releases 下载最新版的可执行文件，一般文件名为 mindoc_linux_amd.tar.gz 或mindoc_linux_amd64.zip 。 #进入存放项目的根目录 cd /data/httpd/ #创建存放 `minDoc` 目录 并进入 mkdir minDoc &amp;&amp; cd minDoc #下载可执行文件压缩包 wget https://github.com/lifei6671/mindoc/releases/download/v2.0/mindoc_linux_amd64.zip # 解压该压缩包 unzip mindoc_linux_amd64.zip 配置数据库 MinDoc 支持 MySQL 或 Sqlite3 数据库，因为up这个是给公司搭建的是团队使用所以选择了 MySQL，如果是个人用需求量不大的话选择 Sqlite3 就好。 我用的是 MySQL 数据库，需要创建一个编码为utf8mb4 格式的数据库，也可以用 CREATE DATABASE mindoc_db DEFAULT CHARSET utf8mb4 COLLATE utf8mb4_general_ci; 命令来创建，如果用 sqlite 数据库 直接在 conf/app.conf 中的数据库配置成如下,系统会自动创建 sqlite 数据库文件 好了接下来修改一下数据库配置，先找到配置文件 conf/app.conf # 进入conf 目录 cd conf/ # 保险起见我习惯在改配置文件前备个份 cp app.conf app.conf.example # 打开app.conf vi app.conf 找到数据库配置进行配置，并且注释掉 Sqlite3 安装 配置完成后变可以安装了 # 需要回到 minDoc 根目录 cd ../ # 执行如下命令，用于初始化数据库 ./mindoc_linux_amd64 install 等待了大约一分钟，程序会自动初始化数据库，当看到“Install Successfully!”说明安装成功，这时会自动创建一个超级管理员账号：admin 密码：123456 运行并安装服务 安装完成后需要先授予权限并安装服务 chmod +x mindoc_linux_amd64 &amp;&amp; ./mindoc_linux_amd64 service install 这样就能注册到系统服务中了,也就是说是以后台运行的方式运行服务 之后就可以 service 控制minDoc 的启用停用和重启拉 service mindocd start/stop/restart 当然还可以查看 minDoc 的状态 service mindocd status 这样就安装完毕了.直接使用了 ","link":"https://www.vincent.ac.cn/post/UNZ7vbISR/"},{"title":"laravel 学习之路 数据库操作 查询数据","content":"到这一步 test 表已经有数据了，我们可以来玩数据查询了 运行原生 SQL 查询 一旦配置好数据库连接后，便可以使用 DB facade 运行查询。 DB facade 为每种类型的查询提供了方法： select，update，insert，delete 和 statement。 运行 Select 查询 你可以使用 DB Facade 的 select 方法来运行基础的查询语句我们在上面创建的路由里增加个 index 的路由 dump 是 laravel 的打印函数可以把它理解为 php 的 var_dump 函数的升级版 Route::prefix('db')-&gt;group(function () { Route::get('insert', 'DbController@insert'); Route::get('index', 'DbController@index'); }); 并在控制器增加一个 index 方法 &lt;?php namespace App\\Http\\Controllers; use Illuminate\\Http\\Request; use Illuminate\\Support\\Facades\\DB; class DbController extends Controller { // function insert() { // DB::insert('INSERT INTO test (testID,title,email,`describe`) VALUES (1,&quot;这是个title&quot;,&quot;123456@qq.com&quot;,&quot;这是个describe&quot;)'); $insertData = [ [ &quot;testID&quot; =&gt; '2', &quot;title&quot; =&gt; '这是个title2', &quot;email&quot; =&gt; '22222@qq.com', &quot;describe&quot; =&gt; '这是个describe2', ], [ &quot;testID&quot; =&gt; '3', &quot;title&quot; =&gt; '这是个title3', &quot;email&quot; =&gt; '33333@qq.com', &quot;describe&quot; =&gt; '这是个describe3', ], ]; DB::table('test')-&gt;insert($insertData); } function index() { $data = DB::select('select * from test where testId = ?', [1]); dump($data); } } 来访问一下 http://study.laraveltest.com/db/index 传递给 select 方法的第一个参数就是一个原生的 SQL 查询，而第二个参数则是需要绑定到查询中的参数值。通常，这些值用于约束 where 语句。参数绑定用于防止 SQL 注入。 select 方法将始终返回一个数组，数组中的每个结果都是一个 StdClass 对象，可以像下面这样访问结果值 function index() { $data = DB::select('select * from test where testId = ?', [1]); foreach ($data as $datum) { echo $datum-&gt;id; } dump($data); } 使用命名绑定 除了使用 ? 表示参数绑定外，你也可以使用命名绑定来执行一个查询 function index() { //使用命名绑定 $binding = DB::select('select * from test where testId = :id', ['id' =&gt; 1]); dump($binding); } 查询构造器 Laravel 的数据库查询构造器为创建和运行数据库查询提供了一个方便的接口。它可用于执行应用程序中大部分数据库操作，且可在所有支持的数据库系统上运行。 Laravel 的查询构造器使用 PDO 参数绑定来保护您的应用程序免受 SQL 注入攻击。因此没有必要清理作为绑定传递的字符串 注意：PDO 不支持绑定列名。因此，不能让用户通过输入来指定查询语句所引用的列名，包括 order by 字段等等。 如果必须要允许用户通过选择某些列来进行查询，请始终根据允许列的白名单来校验列名。 从一个数据表中获取所有行 先注册一个 getList 路由 Route::prefix('db')-&gt;group(function () { Route::get('insert', 'DbController@insert'); Route::get('index', 'DbController@index'); Route::get('getList', 'DbController@getList'); }); 并且相应的控制器创建 getList 方法 function getList() { $data = DB::table('test')-&gt;get(); dump($data); } DB table 选中表 调用 get 方法就可以获取全部的数，来访问一下 http://study.laraveltest.com/db/getList 三角箭头是可以点击收起展开的，按住 command 键点击三角箭头是可以全部展开。 不过实际业务中大多时候都不会取全部数据并且，一般会有限制语句 where() 方法 function getList() { $data = DB::table('test')-&gt;where('testId', 1)-&gt;get(); dump($data); } 第一参数就是字段名，第二个参数就是值 where('testId', 1) 表示查询 testId 等于 1 的数据，那如果想取 testId 不为 1 的数据 就需要传三个参数，第一个参数还是字段名，第二个参数是符号，第三个参数是值 -&gt;where('testId', '&lt;&gt;', 1)。 function getList() { $data = DB::table('test')-&gt;where('testId', '&lt;&gt;',1)-&gt;get(); dump($data); } sql 中还有个 IN 的用法 laravel 中就是 whereIn() 第一个参数还是字段名第二个参数是数组 function getList() { $data = DB::table('test')-&gt;whereIn('testId', [1, 2, 3])-&gt;get(); dump($data); } 那么 NOT IN 就是 whereNotIn()，Between 同理，关联表就是 join 了，可以传3个参数关联表就是 join 了可以传3个参数，第一个参数就是要关联的表名可以使用 as 给表定义别名，当表比较长的时候会比较方便，第二个和第三个分别是关联的字段，谁在前谁在后无所谓哈 function getList() { $data = DB::table('test')-&gt;join('users as u', 'u.id', 'test.user_id')-&gt;get(); dump($data); } 如果使用了 join 那 where 就同样要指明表了 function getList() { $data = DB::table('test') -&gt;join('users as u', 'u.id', 'test.testId') -&gt;whereIn('u.id', [1, 2, 3]) -&gt;get(); dump($data); } 联系到 sql 还会有 left join 和 right join 使用驼峰命名法即可 function getList() { $data = DB::table('test') -&gt;join('users as u', 'u.id', 'test.testId') -&gt;leftJoin('password_resets as pr', 'pr.email', 'test.email') -&gt;whereIn('u.id', [1, 2, 3]) -&gt;get(); dump($data); } 分组和排序的则需要在关键字后面加个 by function getList() { $data = DB::table('test') -&gt;join('users as u', 'u.id', 'test.testId') -&gt;leftJoin('password_resets as pr', 'pr.email', 'test.email') -&gt;whereIn('u.id', [1, 2, 3]) -&gt;groupBy('u.id') -&gt;get(); dump($data); } orderBy 还可以指定第二个参数用于指定正序还是倒序 function getList() { $data = DB::table('test') -&gt;join('users as u', 'u.id', 'test.testId') -&gt;leftJoin('password_resets as pr', 'pr.email', 'test.email') -&gt;whereIn('u.id', [1, 2, 3]) -&gt;groupBy('u.id') -&gt;orderBy('test.created_at', 'desc') -&gt;get(); dump($data); } 如果只想取指定字段的可以使用 select function getList() { $data = DB::table('test') -&gt;select('u.id', 'u.title', 'u.email') -&gt;join('users as u', 'u.id', 'test.testId') -&gt;leftJoin('password_resets as pr', 'pr.email', 'test.email') -&gt;whereIn('u.id', [1, 2, 3]) -&gt;groupBy('u.id') -&gt;orderBy('test.created_at', 'desc') -&gt;get(); dump($data); } 从数据表中获取单行或单列 如果你只需要从数据表中获取一行数据，你可以使用 first 方法。该方法返回一个 StdClass 对象，创建个 getRow 方法 路由就不多叙述了 function getRow() { $data = DB::table('test')-&gt;where('id', 1)-&gt;first(); echo $data-&gt;title; dump($data); } 请求 http://study.laraveltest.com/db/getRow 会得到 StdClass 对象 如果你甚至不需要整行数据，可以使用 value 方法从记录中获取单个值 function getRow() { $data = DB::table('test')-&gt;where('id', 1)-&gt;value('title'); dump($data); } 获取一列的值 当然业务中有时候需要获取 某个字段 哪一列的值的集合，这个时候就用到了 pluck 方法，pluck 接受 2 个参数 第一个参数是我们要取的字段； 第二个字段是可以选的用来做 key function getPluck(){ $titles = DB::table('test')-&gt;pluck('title'); foreach ($titles as $title) { echo $title;echo &quot;&lt;br&gt;&quot;; } } 当然 还可以将 test 表里 title 字段作为键名，describe 字段作为键值 返回 function getPluck(){ $titles = DB::table('test')-&gt;pluck('describe','title'); foreach ($titles as $title =&gt; $describe) { echo $title;echo &quot;&lt;br&gt;&quot;; echo $describe;echo &quot;&lt;br&gt;&quot;;echo &quot;===================&quot;;echo &quot;&lt;br&gt;&quot;; } dump($titles); } 聚合 查询构造器还提供了各种聚合方法，比如 count, max，min， avg，还有 sum 这些就很简单了 $users = DB::table('test')-&gt;count(); $price = DB::table('test')-&gt;max('id'); 当然也可以将这些聚合方法与其他的查询语句相结合 $price = DB::table('test')-&gt;where('id', 1)-&gt;avg('price'); 判断记录是否存在 这个操作除了用 count 方法外 还可以使用 exists 和 doesntExist 方法 return DB::table('test')-&gt;where('id', 1)-&gt;exists(); return DB::table('test')-&gt;where('id', 1)-&gt;doesntExist(); ","link":"https://www.vincent.ac.cn/post/Bh2gcn6S4/"},{"title":"laravel 学习之路 数据库操作 数据插入与数据填充","content":" 前面学了 Migrations 迁移建了数据表，现在可以学习数据库操作了。 数据插入 先搞个控制器 php artisan make:controller DbController 当然路由也不能忘记 Route::prefix('db')-&gt;group(function () { Route::get('insert', 'DbController@insert'); }); 接下来给控制器写个 insert 方法 &lt;?php namespace App\\Http\\Controllers; use Illuminate\\Http\\Request; use Illuminate\\Support\\Facades\\DB; class DbController extends Controller { // function insert(){ DB::insert('INSERT INTO test (testID,title,email,`describe`) VALUES (1,&quot;这是个title&quot;,&quot;123456@qq.com&quot;,&quot;这是个describe&quot;)'); } } 这里需要引入个 DB 类，DB 类就是我们操作数据库的关键，Db 类有个 insert 方法，它可以直接传插入内容的 sql 语句，现在我访问一 下 study.laraveltest.com/db/insert 如果没有报错数据就插入成功了。 确实是很简单吧！但是并不提倡这种拼接字符串的方式来添加数据，维护起来麻烦不说还不安全，所以我换种方式，DB 还有个 table 方法可以传表名再调用 insert 方法可以传要插入的数组，于是我改造那么一丢丢下面就是改造后的样子。 &lt;?php namespace App\\Http\\Controllers; use Illuminate\\Http\\Request; use Illuminate\\Support\\Facades\\DB; class DbController extends Controller { // function insert() { // DB::insert('INSERT INTO test (testID,title,email,`describe`) VALUES (1,&quot;这是个title&quot;,&quot;123456@qq.com&quot;,&quot;这是个describe&quot;)'); $insertData = [ [ &quot;testID&quot; =&gt; '2', &quot;title&quot; =&gt; '这是个title2', &quot;email&quot; =&gt; '22222@qq.com', &quot;describe&quot; =&gt; '这是个describe2', ], [ &quot;testID&quot; =&gt; '3', &quot;title&quot; =&gt; '这是个title3', &quot;email&quot; =&gt; '33333@qq.com', &quot;describe&quot; =&gt; '这是个describe3', ], ]; DB::table('test')-&gt;insert($insertData); } } 我在访问一 下 study.laraveltest.com/db/insert 然后查看数据库 数据填充 使用 DB 插入数据的方式学会后我们就可以讲点填充了，以前下载开源项目如果没有给出安装步骤，哪一般都先找 sql 文件，但是 sql 文件中一般不只是表结构一般还有一些初始化的数据昨天学习了表结构今天来玩玩数据，刚刚学习了插入数据的方式，但那是在控制器里的这种创建路由创建控制器写填充的方式不太优雅，laravel 是优雅的框架这么做跟 laravel 的优雅不符，所有 laravel 必定准备了其他方法，下面学下的填充就是向数据库批量添加数据的，简单概述下就是 数据库迁移+数据填充 = SQL 我们先来看看官网的介绍 Laravel 包含一个填充类可以为你的数据库填充测试数据，所有的填充类都放在 database/seeds 目录下。你可以随意为填充类命名，但是更建议您遵守类似 UsersTableSeeder 的命名规范。通常， Laravel 默认定义了一个 DatabaseSeeder 类。通过这个类，你可以用 call 方法来运行其它的 seed 类从而控制数据填充的顺序。 编写 Seeders 那么就先搞个 Seeders 类玩玩 ，运行 Artisan 命令 make:seeder 生成 Seeder. php artisan make:seeder TestTableSeeder 执行上面这个命令如果洗过脸会生成一个 database/seeds/TestTableSeeder.php 文件 可以看到里面有个 run 方法这个方法会在执行 db:seed 这个 Artisan 命令 时被调用，利用 DB 的方法写上要填充的内容，你也可以用 查询构造器 或 Eloquent 模型工厂 来手动插入数据。 Tip：使用数据填充时会自动禁用 批量赋值保护 &lt;?php use Illuminate\\Database\\Seeder; use Illuminate\\Support\\Facades\\DB; class TestTableSeeder extends Seeder { /** * Run the database seeds. * * @return void */ public function run() { $insertData = [ [ &quot;testID&quot; =&gt; '4', &quot;title&quot; =&gt; '这是个title4', &quot;email&quot; =&gt; '4444444@qq.com', &quot;describe&quot; =&gt; '这是个describe4', ], [ &quot;testID&quot; =&gt; '5', &quot;title&quot; =&gt; '这是个title5', &quot;email&quot; =&gt; '55555@qq.com', &quot;describe&quot; =&gt; '这是个describe5', ], ]; DB::table('test')-&gt;insert($insertData); } } 运行 Seeders 填充文件就算创建完成了，和迁移一样创建好文件写好内容就可以运行了，有一点要注意的是在完成 seeder 类的编写之后，你可能需要使用 dump-autoload 命令重新生成 Composer 的自动加载器 composer dump-autoload 现在我来用 Artisan 命令 db:seed 来填充数据库玩一玩 php artisan db:seed 执行完 php artisan db:seed 我发现数据库里毛的没有后来发现 这是因为填充比迁移多一个步骤，我发现 database/seeds 目录下还有个 DatabaseSeeder.php 文件，他默认就存在不是我创建的打开它里面也有个 run 方法并且里面有一行代码注释掉了 // $this-&gt;call(UsersTableSeeder::class); 翻看了 官方文档 才知道 db:seed 命令会去运行 DatabaseSeeder 类，在这个类可以用来调用其它 Seed 类 也就是我们需要仿照注释的示例在 DatabaseSeeder 类中去调用我刚刚创建的Seed 类 TestTableSeeder 。那么我去修改一下 DatabaseSeeder 类 &lt;?php use Illuminate\\Database\\Seeder; class DatabaseSeeder extends Seeder { /** * Seed the application's database. * * @return void */ public function run() { // $this-&gt;call(UsersTableSeeder::class); $this-&gt;call(TestTableSeeder::class); } } 不过这里需要主要一下填充文件的执行顺序，我们会创建很多填充文件如果有外键的话执行顺序不对是会报错的所以需要严格的自己指定顺序，OK我们在执行一下 php artisan db:seed 命令 数据终于写入数据库中了，当然 官方文档 也给出了其他的方式运行比如可以使用 --class 选项来指定一个特定的 seeder 类。 php artisan db:seed --class=TestTableSeeder 也可以用 migrate:refresh 这个命令来填充数据库，该命令会回滚并重新运行所有迁移。这个命令可以用来重建数据库 php artisan migrate:refresh --seed 另外在生产环境中强制使用一些填充操作可能会导致原有数据的更新或丢失。为了保护生产环境数据库的数据，在运行填充命令前会进行确认。可以添加 --force 选项来强制运行填充命令: php artisan db:seed --force 相比于迁移，填充的价值就没有那么革命性了，而且填充更强大的功能需要模型的支持这个后面会学到的。 ","link":"https://www.vincent.ac.cn/post/Wb4f8UHdq/"},{"title":"laravel 学习之路 数据库操作 Migrations","content":" 前面我们设置好了数据库，可以开始对数据库操作了但是前提是我们得有表啊，说到数据库做开发的肯定能知道其中的辛酸苦与泪。 团队合作的时候为了避免代码冲突，以及方便记录修改历史和回退我们有版本控制比如说 git svn 但是数据库怎么搞呢? 在远古时代在中小公司中在没有一套比较好用的管理表变动的方案的时候相信童鞋们多少都经历过改数据库的痛苦,每次自己在本地增加了表或者字段都要记录下来告知其他同事，其他同事也得在自己本地修改，还要胆战心惊的改生产跟测试环境的数据库这种经历贼痛苦，但是自从接触了 laravel，一口气搞定所有的环境的表结构。 那laravel怎样来帮助我们的呢？ 这就要说 laravel 内置了表迁移的功能，迁移就像是数据库的版本控制器，让你的团队更容易修改和共享程序的数据库结构。迁移通常配合 Laravel 的结构生成器，能更容易的生成应用程序的数据库结构。如果你曾经让一个团队成员在他本地的数据库结构中手动的添加了字段，那么你将面对解决数据库迁移的问题。 Laravel 的 Schema 门面 提供数据库无关的支持，用于在所有 Laravel 支持的数据库系统中创建和操作表 创建迁移 使用 make:migration Artisan 命令来创建迁移 php artisan make:migration create_test_table 新创建的迁移会放在你的 database/migrations 目录。 你运行的时候肯定不会跟我这个文件名一样,因为我们很容易就发现这个文件加了时间前缀,也就是说我是在 2019-11-06 16:08:05 创建的这个文件。 --table 和 --create 选项也可用于确定表的名称以及是否在迁移中创建新的数据表。这些选项用指定的迁移模板预先填充指定的数据表，这里就不做过多演示了 php artisan make:migration create_test_table --create=test php artisan make:migration add_votes_to_test_table --table=test 迁移结构 除了我们创建的 test 表迁移文件，我们还发现了 laravel 框架自带的 2014 年的 users 表和 password_resets 表，直接打开2014_10_12_000000_create_users_table.php 我们来参考下它的内容 一共有两个方法 up 和 down ，up 方法是用于新增数据库的数据表、字段或者索引的，而 down 方法与 up 方法执行操作相反是用来删除表的。 在这两种方法中，你可以使用 Laravel 的结构生成器以表达式方式创建和修改表。 Schema 生成器上可用的所有方法 请查阅 官方文档 我们直接来读上图的代码，大致意思是 要创建一个 user 表 指定这个表的主键为 id 指定 name 字段为字符串类型 指定 email 字段为为字符串类型且限制唯一性 指定 email_verified_at 字段为TIMESTAMP类型并且此字段允许写入 NULL 值 指定 password 字段为字符串 rememberToken 这个字段不通用就不多讲具体看手册 重点要说下 timestamps ，$table-&gt;timestamps() 的作用是给表增加 created_at 和 updated_at 它们的类型是 timestamps laravel 插入和编辑数据的时候会自动通过这两个字段记录操作的日期时间 这我们就发现了 laravel 的又一特点，整个项目对于各种命名的斟酌，很多时候我们即便不看文档甚至不看源代码注释只看方法名就能猜到作用了，她不只是一个框架还是我们编程的一个范本。 参考了 users 表我们回到 2019_11_06_160805_create_test_table.php 通过命令行生成文件的同时自动已经生成了下面这样的代码 很明显 laravel 默认表的主键字段名为 id 然后默认表有 created_at 和 updated_at 字段，增删改查不分家，增和改都默认有了个字段记录操作日期了，那删怎么能没有呢？没错 laravel 又为我们设计好了。 $table-&gt;softDeletes(); 这个方法就是为表增加一个 deleted_at ，laravel 会在删除数据的时候记录操作日期，具体到功能比如 回收站 的功能了，我们可能会删除某些数据，但是我们还希望能恢复删除的数据，当某条数据的 deleted_at 为 null 的时候表示正常，当有日期的时候就表示这条数据是在这个日期被删掉了。 运行迁移 现在回到 2019_11_06_160805_create_test_table.php 我们简单编辑下这个文件 我们在之前学习 artisan 的时候说过 artisan 主要2个作用 一个是创建迁移文件、一个是执行迁移任务，我们已经用 artisan 创建控制器和迁移了现在终于到了执行任务的时候了，我们上面的迁移文件定义了表的结构，执行迁移才会真正生成表 php artisan migrate 执行上面的命令的时候up遇到了这样的报错 SQLSTATE[HY000] [2054] The server requested authentication method unknown to the client 这是因为 up 本地 使用的是 MySQL 8 是由于 MySQL 8 默认使用了新的密码验证插件：caching_sha2_password，而之前的PHP版本中所带的 mysqlnd 无法支持这种验证。解决这个问题可以在MySQL 8中创建（或修改）使用caching_sha2_password 插件的账户，让其使用mysql_native_password 插件 ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'R9s33P8,,8&amp;BH;2'; 修改后我们重新执行 php artisan migrate 我们可以看到这样的提示 这意思就是我们的迁移已经完成了,那我们再执行一遍命令呢？我们会看到这样的的提示 Nothing to migrate. 嗯哼？也就是说已经成功的迁移并不会重复执行，这是在哪控制的呢？让我们 连接上 mysql show tables 一下 除了 laravel 自带的 users 表和 password_resets 表，除了我们创建的 test 表，我们还发现了个 migrations 表，我们看下这个表的内容 我们的3个迁移文件名都在里面记录着了,说明这个表里面存的是已经执行过的迁移的文件名,再查看下 test 表的结构. 完美跟我们迁移文件中写的是一样的表就这么轻松的创建了，但是再认真看会发现并没有 string 类型，肯定的喽，因为 mysql 压根就没 string，string 就是 varchar 了，再但是再认真看还会发现除了 timestamp ，其他的字段都多了个 NOT NULL ，这个我们并没有在迁移中指定，这里就需要解释下了，这个 NOT NULL 是 laravel 为我们默认添加的，那如果确实有字段想让它允许为 NULL 怎么办呢？别担心 laravel 还有个 -&gt;nullable() 我们这里学习了最常用的 int 、 varchar 、 text 那更多的类型呢？这时候就是 laravel 官方手册真正的作用了，laravel 官方手册更适合作为一本工具书，我们去像查字典一样去查工具书就可以了。 修改字段 创建表的方式我们已经学会了，除了创建表，我们还经常需要改变表结构，默认的 users 并没有 deleted_at 字段，我们如果想为 用户 也增加一个类似回收站的字段怎么办呢？ 我们再来创建一个表迁移文件 php artisan make:migration add_deleted_at_to_users_table 在 add_deleted_at_to_users_table 文件中添加如下代码 Schema::table('users', function (Blueprint $table) { $table-&gt;softDeletes(); }); up 中就是我们迁移的内容，创建表的时候我们使用的是 Schema::create ，编辑表的时候我们使用的是 Schema::table，然后回调函数中的内容跟创建表的时候的格式是一样的，现在我们执行 php artisan migrate 迁移命令。 我们在来看看 users 表的结构 deleted_at 就这么加上了 回退 回滚迁移 down 方法中就是回退的内容了，创建表的时候 down 中是 drop 表，添加字段的时候 down 中的自然就是 drop 字段了 Schema::table('users', function (Blueprint $table) { $table-&gt;dropColumn('deleted_at'); }); 我们一直在说回退说 laravel 的迁移功能可以让我们回退到某个状态，那到底是怎么回退呢？其实也很简单同样是运行命令，为了更深刻的理解 migrations 表的作用，在运行回退命令前我们先看下 migrations 表的内容 一共有5条记录 4条创建表的，1条添加字段的好我们来运行回退命令 php artisan migrate:rollback 然后再来看 migrations 表和 users 表 migrations 表的第4条添加字段的记录没有了，users 表的 deleted_at 字段也没了，再回退一次就把第一次运行迁移的时候的3张表就全删了，如果再运行迁移命令一切就又有了。 重命名一个存在的数据库表，请使用 rename 方法： Schema::rename($from, $to); 删除一个存在的数据表，你可以使用 drop 或者 dropIfExists 方法： Schema::drop('users'); Schema::dropIfExists('users'); 修改字段类型 到这里创建表、删除表、添加字段、删除字段我们都学习了，最后再来学习下修改字段的，修改字段需要借助 dbal扩展包 ，先来执行下列命令安装扩展包 composer require doctrine/dbal 剩下的工作也很简单我这里举个栗子，比如 test表没有几条数据，用 int 类型太奢侈了，我们改成 tinyint 就足够了。 那么我们先创建一个迁移文件 php artisan make:migration change_category_id_in_test_table 然后在 up 中写上修改的内容即可 Schema::table('test', function (Blueprint $table) { $table-&gt;tinyInteger('testId')-&gt;unsigned()-&gt;default(0)-&gt;comment('测试id')-&gt;change(); }); 但是这里要讲一个坑，如果直接运行上面这个迁移文件是会报错的因为 dbal 并不支持修改成 tinyInteger ，为了兼容更多类型的数据库需要使用替代方案使用 boolean 类型 那 down 里面就是相反的内容了 总结下就是 up 中写需要迁移的内容 down 中写回退的内容。 ","link":"https://www.vincent.ac.cn/post/xwp3_04xN/"},{"title":"laravel 学习之路 配置config","content":" 前面文章路由与控制器我们都了解了，现在了解一下laravel的config配置 配置项 laravel 的配置项是在根目录下的 /config 目录中,还有一个是根目录下的 .env 文件 这里就有个疑问了为啥要有2个地方用于写配置项呢？让我们打开 .env 来看看 第一行就是一个 APP_NAME ,我们再打开 config/app.php 我们也找到了这个 APP_NAME , 不过是作为一个参数传给了 env() 函数，我们来了解下这个函数 它是用来获取 .env 文件中的配置的 它有2个参数 第一个参数就是配置项名 第二个参数就是默认值 'name' =&gt; env('APP_NAME', 'Laravel') 到这里这句代码的意思就很明显了，从 .env 获取 APP_NAME 的值，如果 .env 中不存在 APP_NAME 那就取默认值 Laravel 在 config/database.php 文件中我们可看到数据库的配置 依然是一片熟悉的 env 函数,比如说数据库的 host 、port 、database 、username、password 但是还有一些并没有用 env 函数,比如说 charset 、 prefix 那我们不禁迷惑了, 到底什么时候用 env 函数什么时候不用 env 函数呢？ 在理解这个问题前咱还需再穿插一点 git 的小知识在项目根目录下我们可以看到有个 .gitignore 文件. 其中有一行写了 .env ,它的作用就是告诉 git 忽略 .env 文件,所以如果你去 github 上看别的 laravel 项目的时候你会发现并没有 .env 文件. 很显然需要保密的配置或者每个项目特有的或者每个环境不同的东西我们可以把它卸载 .env 文件里然后在 /config 目录下的配置文件中用 env() 函数获取数据库的配置就很明显属于这类。 并且在团队开发的时候每个人都有自己的本地开发环境还有测试环境生产环境，如果直接写死就需要每个团队成员在这些环境中设置成统一的账号密码，这样做很不安全并且非常麻烦，而那些不需要报名却需要一定统一的性的配置可以直接卸载 /config 目录下的配置文件里。 好了哪我们现在来简单改一下配置 配置 .env 文件 首先 APP_NAME 需要该成我们的项目名称，我就随便起名字叫 study 了。 APP_URL 是需要该的，他就是项目的域名，我是在本地开发的 http://study.laraveltest.com/ DB_开头的这一堆配置也都要改成本地数据库。 /config 目录下的数据库的配置 laravel 5.4 以后默认使用 utf8mb4 字符集，utf8mb4 主要是用来支持 emoji 表情的，如果你的本地环境的 mysql 低于5.7.7，为了防止在以后使用的过程中报如下错误 [Illuminate\\Database\\QueryException] SQLSTATE[42000]: Syntax error or access violation: 1071 Specified key was too long; max key length is 767 bytes (SQL: alter table users add unique users_email_unique(email)) [PDOException] SQLSTATE[42000]: Syntax error or access violation: 1071 Specified key was too long; max key length is 767 bytes 需要找到 config/database.php 文件中的 mysql 修改 charset、collation为utf8 'charset' =&gt; 'utf8', 'collation' =&gt; 'utf8_unicode_ci', 不过这样做的后果就是不能在数据库直接存 emoji 表情了，如果说你就是想在数据库中存 emoji 表情,那还有一种方案，找到appProvidersAppServiceProvider.php 文件， 先 use Schema use Illuminate\\Support\\Facades\\Schema; 在 boot 中添加如下代码 public function boot() { Schema::defaultStringLength(191); } 如果使用 5.7 以上的 mysql 数据库,还可以把 strict 改为 false 关闭严格模式,以防止报类似如下 only_full_group_by 的错误。 除了数据库还有两个需要改的打开 config/app.php 文件把 timezone 改为 PRC ,laravel 默认的时区是 UTC 中国的时区是 PRC 如果没有改的话, 那数据库存自动生成的时间会和我们的实际相差8个小时然后把 locale 改为 zh-CN这个就好理解了把语言改为中文。 ","link":"https://www.vincent.ac.cn/post/laravel5/"},{"title":"laravel 学习之路 路由与控制器","content":" 前面学习的路由与控制器，接下来学习如何把路由与控制器关联起来 配置路由关联控制器 Route 的 get 或者 post 方法，第一个参数就是我们要定义的路由，就是我们在地址栏请求的那段url， 第二个参数可以是一个闭包函数里面写请求定义的路由时执行的内容但是如果把代码都放这个闭包函数中是臃肿且难以维护的所以就需要使用控制器了。 很显然控制器就是来替代这第二个参数的闭包函数的写起来也非常简单直接写控制器名即可,然后用 @ 符号分割控制器和控制器的方法Route::get('test/index','TestController@index'); Route::get('test/create','TestController@create'); Route::get('test/store','TestController@store'); 接着在控制器中写点东西 这样我们在浏览器访问就可以看到返回的响应 路由分组 多么完美但是如果你和我一样帅，一样懒，你回发现三条路由都是 test/ 未前缀，在路由中应该减少这样的重复但是怎么做呢？接下来我们来了解了路由分组的概念 路由分组有啥好处？ 有时候啊 一大堆路由它们都有共同的地方，比如都使用一个中间件(过两天写)或是前缀都一样，避免代码重复 我们可以将他们分到一组中。 路由组允许你在大量路由之间共享路由属性，例如中间件或命名空间，而不需要为每个路由单独定义这些属性。共享属性应该以数组的形式传入 Route::group 方法的第一个参数中。 嵌套的组尝试智能地「合并」其属性及其父组。中间件和 where 条件语句在附加名称、命名空间和前缀时被合并。在适当的情况下，命名空间的分隔符和斜线会被自动添加到 URI 前缀中 我们先来定义一个前缀路由组,上面这3条路由就可以改造成这个样子了 Route::prefix('test2')-&gt;group(function () { Route::get('index', 'TestController@index'); Route::get('create', 'TestController@create'); Route::post('store', 'TestController@store'); }); 随着项目的扩大如果控制器都直接放在 app/Http/Controllers 目录下的话,那维护起来也开始也很头疼了于是就可以为控制器分目录存放. 比方说说建个 app/Http/Controllers/Admin/StoreController.php,再建一个 app/Http/Controllers/Home/IndexController.php 命令行也是可以加目录的 1. php artisan make:controller Admin/StoreController --resource 2. php artisan make:controller Home/IndexController --resource 再在新建的控制器中写点内容加以区分 这种多级目录是不需要指明目录的只需要指明相对于app/Http/Controllers 目录的 namespace 即可 Route::prefix('admin/store')-&gt;namespace('Admin')-&gt;group(function () { Route::get('index', 'StoreController@index'); Route::get('create', 'StoreController@create'); Route::post('store', 'StoreController@store'); }); group 是可以嵌套的那么上面这样的路由还可以改造下 Route::prefix('home')-&gt;namespace('Home')-&gt;group(function () { Route::prefix('index')-&gt;group(function () { Route::get('index', 'IndexController@index'); Route::get('create', 'IndexController@create'); Route::post('store', 'IndexController@store'); }); }); 访问http://study.laraveltest.com/home/index/index 与 http://study.laraveltest.com/admin/store/index 会得到这样的响应 因为创建的目录下我们还会创建更多的路由器所以，我们应该使用 group 嵌套的这种方式，比如说我们再有一个 app/Http/Controllers/Home/TagController.php 执行创建控制器命令 php artisan make:controller Home/TagController --resource 那么路由就是这样的 Route::prefix('home')-&gt;namespace('Home')-&gt;group(function () { Route::prefix('index')-&gt;group(function () { Route::get('index', 'IndexController@index'); Route::get('create', 'IndexController@create'); Route::post('store', 'IndexController@store'); }); Route::prefix('tag')-&gt;group(function () { Route::get('index', 'TagController@index'); Route::get('create', 'TagController@create'); Route::post('store', 'TagController@store'); }); }); 路由参数 到这里我们已经学会了如何组织多级目录了，让我们回到 app/Http/Controllers/TestController.php 控制器上 会发现命令行创建的控制器里面有个 edit 方法，edit 方法有个 $id 参数,通过名字我们很容易就明白这是用来修改数据的，id 一般又是数据库的自增字段,但是这个 id 是哪传来的呢？下面就到了了解路由参数的时候了。 定义路由的时候我们是可以定义路由参数，我们接着上面的路由加一个 edit ,我们在定义路由的时候用花括号包一个变量名那这个变量就可以直接传到控制器方法中然后在地址栏传什么控制器中就可以接到什么为了方便测试我们在这个方法中返回 id Route::prefix('test2')-&gt;group(function () { Route::get('index', 'TestController@index'); Route::get('create', 'TestController@create'); Route::post('store', 'TestController@store'); Route::get('edit/{id}', 'TestController@edit'); }); 接下来我们访问http://study.laraveltest.com/test2/edit/2344 这里面有个值得注意的地方，就是控制器中的参数名跟路由参数名不是必须相同的，一个路由参数的时候这倒不会觉得什么，一旦定义多个路由参数的时候，这就有点坑了 重新写一个方法edit1 /** * @param $name * @param $id * * @return string */ public function edit1($name,$id) { return '吾乃 Test 控制器的 edit 方法,地址栏的传参id为: &quot;'. $id .'&quot;,name为: &quot;'.$name.'&quot;'; } 配置路由 Route::prefix('test2')-&gt;group(function () { ... Route::get('edit1/{id}/{name}', 'TestController@edit1'); }); 访问 http://study.laraveltest.com/test2/edit1/2344/风清醉 你会发现 id 和 name 没对上，这边画个重点 路由参数中的第一个参数对应控制器中的第一个路由参数以此类推在控制器中路由参数跟参数名是没关系的只跟顺序有关。 再个 id 一般都是纯数字，这里却传了字母 ，我们应该怎么约束下 id 呢？laravel 方方面面都为我们考虑到了，我们加个 where 就行了。 Route::prefix('test2')-&gt;group(function () { ... Route::get('edit1/{id}/{name}', 'TestController@edit1')-&gt;where('id', '[0-9]+');; }); 这样就只能传数字了其实大多的表都是用 id 做主键的如果每个路由都手动定义一遍约束那也是挺麻烦的laravel 又一次方方面面都为我们考虑到了。 找到 app/Providers/RouteServiceProvider.php 这个文件在 boot 方法中可以定义全局约束 Route::pattern('id', '[0-9]+'); 这样就不需要为每条带 id 参数的路由定义约束了,以后所有带 id 参数的路由就只能传数字了。 请求参数 路由参数容易搞混的是请求参数路由参数？请求参数？傻傻分不清楚 我们请求 http://study.laraveltest.com/test2/edit1/2344/清风醉?code=12345&amp;status=succ id 和 name 就是路由参数 code 和 status就是请求参数，路由参数上文已经介绍了，那么请求参数怎么获取呢？ 现在让我们回到控制器里去找 update 方法 /** * Update the specified resource in storage. * * @param \\Illuminate\\Http\\Request $request * @param int $id * @return \\Illuminate\\Http\\Response */ public function update(Request $request, $id) { // } 这个 Request $request 就是我们用来获取请求参数的关键,它的意思是向控制器的方法传一个 $request 它是一个 Request 类,我们可以把我们的 edit 方法也加个 $request /** * @param Request $request * @param $name * @param $id * * @return string */ public function edit1(Request $request, $id, $name ) { $code = $request-&gt;input('code'); $status = request()-&gt;input('status'); return '吾乃 Test 控制器的 edit 方法,地址栏的传参id为: &quot;' . $id . '&quot;,name为: &quot;' . $name . '&quot;,code为: &quot;'. $code.'&quot;,status为: &quot;'. $status.'&quot;'; } 这个 Request $request 是不会影响路由参数的顺序的 它放前放后都是可以的,我们访问这个方法并携带请求参数 Request 类有一个 input 方法,把要获取的参数名传给它就可以了,我上面示例中还用了个 request() 函数它跟 Request $request 效果是一样的,$request 可以方便复用,所以在控制器中更推荐使用$request,如果传的请求参数比较多的时候这样一个一个取贼麻烦，Request 还有个 all 方法就可以获取全部的请求参数 public function edit(Request $request, $id, $name) { dump($request-&gt;all()); } dump 是 laravel 自带的一个打印函数,就是 php 自带的 var_dump 函数的升级版,打印的效果如下 Request 还有个 only 方法作用是从一大堆请求参数中获取指定的请求参数 public function edit(Request $request, $id, $name) { dump($request-&gt;only('music', 'book')); } Request 还有个 except 方法作用是排除某个参数剩下的全要 public function edit(Request $request, $id, $name) { dump($request-&gt;except('music')); } ","link":"https://www.vincent.ac.cn/post/laravel4/"},{"title":"译 - 为什么要学习Go？","content":" “Go将成为未来的服务器语言。” — TobiasLütke，Shopify 在过去的几年中，出现了新的编程语言：Go或GoLang。没有什么比新的编程语言更使开发人员疯狂了，对吗？因此，我在4到5个月前开始学习Go语言，在这里我将告诉您为什么还要学习这种新语言。 我不会教你如何在本文中写“ Hello World !!”。在线上还有很多其他文章。我将解释计算机硬件软件的当前阶段，以及为什么我们需要像Go这样的新语言？因为如果没有问题，那么我们就不需要解决方案，对吗？ 硬件限制： 摩尔定律失败了。 英特尔早在2004年就推出了第一款时钟频率为3.0GHz的奔腾4处理器。今天，我的Mackbook Pro的时钟速度为2.9GHz。因此，近十年来，原始处理能力并没有获得太多收益。您可以在下表中看到随时间增加处理能力的比较。 从上面的图表中可以看到，单线程性能和处理器频率在近十年中一直保持稳定。如果您认为添加更多晶体管是解决方案，那么您错了。 这是因为在较小的规模上，一些量子特性开始出现（例如隧道效应），并且实际上放置更多晶体管的成本更高（为什么？），每美元可添加的晶体管数量开始下降。 因此，为了解决上述问题， 制造商开始向处理器添加越来越多的内核。如今，我们有四核和八核CPU。 我们还介绍了超线程。 向处理器添加了更多缓存，以提高性能。 但是上述解决方案也有其 自身的局限性。由于缓存具有物理限制，因此无法向处理器添加越来越多的缓存来提高性能：缓存越大，缓存越慢。向处理器添加更多内核也有其成本。同样，这不能无限期地扩展。这些多核处理器可以同时运行多个线程，这带来了并发性。我们稍后再讨论。 因此，如果我们不能依靠硬件改进，唯一的方法就是使用更高效的软件来提高性能。但是可悲的是，现代编程语言效率不高。 “现代处理器就像是硝基燃料的有趣汽车，它们在四分之一英里处表现出色。不幸的是现代编程语言都像蒙特卡洛，他们充满曲折。” - 戴维·安加 去有goroutines！ 如上所述，硬件制造商正在为处理器添加越来越多的内核，以提高性能。所有数据中心都在这些处理器上运行，我们应该期望在未来几年内内核数量会增加。更重要的是，当今的应用程序使用多个微服务来维护数据库连接，消息队列和维护缓存。因此，我们开发的软件和编程语言应轻松支持并发性，并且应随着内核数量的增加而扩展。 **但是，大多数现代编程语言（如Java，Python等）都来自90年代的单线程环境。**这些编程语言大多数都支持多线程。但是真正的问题在于并发执行，线程锁定，竞争条件和死锁。 这些事情使得在这些语言上创建多线程应用程序变得困难。 例如，在Java中创建新线程效率不高。由于每个线程消耗大约1MB的内存堆大小，最终如果您开始旋转数千个线程，它们将对堆施加巨大压力，并由于内存不足而导致关闭。另外，如果您想在两个或多个线程之间进行通信，则非常困难。 另一方面，Go于2009年发布，当时多核处理器已经可用。这就是为什么走的是与保持并发考虑建造。Go具有goroutines而不是线程。它们从堆中消耗了将近2KB的内存。所以，你可以随时旋转百万够程的。 `Goroutines如何工作？Reffrance：http ://golangtutorials.blogspot.in/2011/06/goroutines.html` 其他好处是： Goroutine具有可增长的分段堆栈。这意味着它们仅在需要时才使用更多的内存。 Goroutine具有比线程更快的启动时间。 Goroutine带有内置原语以在它们之间（通道）之间安全地通信。 使用Goroutines可以避免共享数据结构时不得不使用互斥锁。 此外，goroutine和OS线程没有1：1映射。一个goroutine可以在多个线程上运行。Goroutines被多路复用到少量的OS线程中。 您可以看到Rob Pike出色的通话并发性并不是并行机制，因此无法对此有更深入的了解。 以上所有这些，使Go在处理Java，C和C ++之类的并发性方面非常强大，同时保持了并发执行代码的平稳性和Erlang之类的美丽。 `Go兼顾了两个世界。易于编写并发并有效管理并发` Go直接在基础硬件上运行。 与其他现代高级语言（例如Java / Python）相比，使用C，C ++的最大好处是它们的性能。因为C / C ++是经过编译而不进行解释的。 处理器了解二进制文件。通常，当您在编译项目时使用Java或其他基于JVM的语言构建应用程序时，它会将人类可读的代码编译为字节代码，而JVM或在底层OS之上运行的其他虚拟机可以理解这些代码。在执行时，VM解释这些字节码并将其转换为处理器可以理解的二进制文件。 `基于VM的语言的执行步骤` 另一方面，C / C ++无法在VM上执行，这从执行周期中删除了一个步骤，从而提高了性能。它直接将人类可读的代码编译为二进制文件。 但是，释放和分配这些语言中的变量是一个巨大的痛苦。大多数编程语言都使用垃圾收集器或引用计数算法来处理对象分配和删除。 Go带来了两全其美的优势。像C / C ++这样的低级语言一样，Go是编译语言。这意味着性能几乎接近低级语言。它还使用垃圾回收来分配和删除对象。因此，不再需要malloc（）和free（）语句！！！凉！！！ 用Go编写的代码易于维护。 我告诉你一件事。Go没有像其他语言一样疯狂的编程语法。它具有非常简洁的语法。 Google Go语言的设计师在创建语言时就牢记这一点。由于google具有庞大的代码库，并且成千上万的开发人员正在同一个代码库上工作，因此对于其他开发人员而言，代码应易于理解，并且一段代码对另一段代码的影响应最小。这将使代码易于维护和修改。 Go故意遗漏了现代OOP语言的许多功能。 没有课程。每件事都只分为包。Go只有结构而不是类。 不支持继承。 这将使代码易于修改。在Java / Python之类的其他语言中，如果类ABC继承了类XYZ，并且您对类XYZ进行了一些更改，则在继承XYZ的其他类中可能会产生一些副作用。通过删除继承，Go还可轻松理解代码（因为在查看一段代码时没有要查看的超类）。 没有构造函数。 没有注释。 没有泛型。 没有例外。 上述变化使Go与其他语言完全不同，并且使Go编程也与其他语言不同。您可能不喜欢上面的几点。但是，这不像没有上述功能就无法编写应用程序。您所要做的就是再写2–3行。但从积极的方面来说，它将使您的代码更整洁，并为您的代码增加更多清晰度。 `代码可读性与效率` 上图显示Go几乎与C / C ++一样高效，同时使代码语法像Ruby，Python和其他语言一样简单。对于人类和加工者来说，这是双赢的局面！！！ 与Swift等其他新语言不同，Go的语法非常稳定。自2012年首次公开发布1.0版以来，它一直保持不变。这使其向后兼容。 Go得到了Google的支持。 我知道这不是直接的技术优势。但是，Go是由Google设计和支持的。Google拥有世界上最大的云基础架构之一，并且已大规模扩展。Go是Google设计的，旨在解决他们在支持可扩展性和有效性方面的问题。这些都是您在创建自己的服务器时将面临的相同问题。 此外，诸如Adobe，BBC，IBM，Intel甚至Medium的一些大公司也使用Go 。（来源：https : //github.com/golang/go/wiki/GoUsers） 结论： 尽管Go与其他面向对象的语言有很大不同，但它仍然是相同的野兽。Go为您提供了诸如C / C ++的高性能，为Java提供了超高效的并发处理，并为Python / Perl等代码带来了乐趣。 如果您没有学习Go的计划，我仍然会说硬件限制给我们（软件开发人员）编写超高效代码的压力。开发人员需要了解硬件并相应地优化程序。经过优化的软件可以在更便宜，更慢的硬件（例如IOT设备）上运行，并且总体上对最终用户体验的影响更好。 ———————————————— 版权声明：本文为博主「Keval Patel」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。 原文链接：https://medium.com/@kevalpatel2106/why-should-you-learn-go-f607681fad65 ","link":"https://www.vincent.ac.cn/post/go1/"},{"title":"laravel 学习之路 控制器Controller","content":"前面学习了路由可以分发请求还可以引入html页面，这些都可以在 route/web.php 中搞定。 但是如果项目设计的业务很繁杂，都写在路由里会非常臃肿难以维护，于是今天的主角 Controller 控制器的价值就很明显了，把业务逻辑写在控制器中，路由只负责转发请求到控制器。 创建控制器 都9102年了既然用上了现代话框架必须玩点高逼格的方式使用命令行的方式创建控制器 laravel 是一个现代化框架，它对命令行有着非常好的支持，artisan 就是 laravel 的命令行接口 我们可以把它理解为命令行级的单入口文件，跟 index.php 文件的使命一样，所有命令都需要通过他，所有如果需要使用命令行就需要 cd 到项目根目录去或者指定一长串路径这个看个人喜好了up是喜好到根目录去。 使用很简单 php artisan 起手 后面跟上响应的命令，在命令行中以 php 开头意思是用 php 来执行某个文件，php index.php 意思就是使用 php 的命令行模式运行 index.php 。 命令行下是可以不需要文件后缀就能识别的所以根目录下的 artisan 文件并没有带上 .php 好了让我们用 php artisan 来创建控制器在项目根目录执行下列代码 php artisan make:controller TestController 如果最近没做坏事，洗过脸的话会看到成功的提示 并会生成一个 app/Http/Controllers/TestController.php 文件，打开是这个样子 &lt;?php namespace App\\Http\\Controllers; use Illuminate\\Http\\Request; class TestController extends Controller { // } 不但自动创建了文件还定义了命名空间并且继承好了父级控制器，这样我们直接写CURD就好了 接下来我们给上面的命令加个 --resource 选项 php artisan make:controller TestController --resource 如果直接运行的话是会报错提示Controller already exists! 这是因为我们刚已经创建过 TestController了，所以我们需要进入项目根目录执行下面的命令把刚刚创建的文件删除掉 cd app/Http/Controllers/ &amp;&amp; rm -rf TestController.php 删除掉后再回到项目根目录执行刚刚的命令 如果人品正常，那么会再次生成一个 app/Http/Controllers/TestController.php 文件,打开会是这个样子 &lt;?php namespace App\\Http\\Controllers; use Illuminate\\Http\\Request; class TestController extends Controller { /** * Display a listing of the resource. * * @return \\Illuminate\\Http\\Response */ public function index() { // } /** * Show the form for creating a new resource. * * @return \\Illuminate\\Http\\Response */ public function create() { // } /** * Store a newly created resource in storage. * * @param \\Illuminate\\Http\\Request $request * @return \\Illuminate\\Http\\Response */ public function store(Request $request) { // } /** * Display the specified resource. * * @param int $id * @return \\Illuminate\\Http\\Response */ public function show($id) { // } /** * Show the form for editing the specified resource. * * @param int $id * @return \\Illuminate\\Http\\Response */ public function edit($id) { // } /** * Update the specified resource in storage. * * @param \\Illuminate\\Http\\Request $request * @param int $id * @return \\Illuminate\\Http\\Response */ public function update(Request $request, $id) { // } /** * Remove the specified resource from storage. * * @param int $id * @return \\Illuminate\\Http\\Response */ public function destroy($id) { // } } 怎么样逼格高吧，不但增删改查的方法都定义好了，连注释都写好了，这其实是按 RESTful 规范生成的格式。 ","link":"https://www.vincent.ac.cn/post/laravel3/"},{"title":"《数据结构与算法》Day.1 最大子列和","content":"算法1：暴力法 int MaxSubseqSum1(int A[], int N) { int ThisSum, MaxSum = 0; int i, j, k; for( i = 0; i &lt; N; i++) { for( j = i; j &lt; N; j++) { ThisSum = 0; for( k = i; k &lt;= j; k++) { ThisSum += A[k]; if( ThisSum &gt; MaxSum) MaxSum = ThisSum; } } } return MaxSum; } // T(N) = O(N^3) 算法2：还是暴力法 int MaxSubseqSum2(int A[], int N) { int ThisSum, MaxSum = 0; int i, j, k; for( i = 0; i &lt; N; i++) { ThisSum = 0; for( j = i; j &lt; N; j++) { ThisSum += A[j]; if( ThisSum &gt; MaxSum) MaxSum = ThisSum; } } return MaxSum; } // T(N) = O(N^2) 算法3：二分法 //返回3个整数中的最大的一个 int getmaxint3(int a,int b,int c) { return a&gt;b?(a&gt;c?a:c):(b&gt;c?b:c); } //递归调用分治思想的核心代码 int MaxSubseqSum3(int nums[],int left,int right) { //左右最大子列和 int MaxLeftSum, MaxRightSum; //跨边界左右最大子列和 int MaxLeftBorderSum, MaxRightBorderSum; //当前计算的左右边界子列和 int LeftBorderSum, RightBorderSum; int center, i; //递归调用终止条件，子列只有一个元素 if( left == right ) { if( nums[left] &gt; 0 ) return nums[left]; else return 0; } //先分 center = ( left + right ) / 2; //递归调用获取左边最大子列和 left.....center MaxLeftSum = MaxSubseqSum3( nums, left, center ); //递归调用获取右边最大子列和 center+1.....right MaxRightSum = MaxSubseqSum3( nums, center+1, right ); //跨边界最大子列和 MaxLeftBorderSum = 0; LeftBorderSum = 0; for( i=center; i&gt;=left; i-- ) { /* 从中线向左扫描 */ LeftBorderSum += nums[i]; if( LeftBorderSum &gt; MaxLeftBorderSum ) MaxLeftBorderSum = LeftBorderSum; } /* 左边扫描结束 */ MaxRightBorderSum = 0; RightBorderSum = 0; for( i=center+1; i&lt;=right; i++ ) { /* 从中线向右扫描 */ RightBorderSum += nums[i]; if( RightBorderSum &gt; MaxRightBorderSum ) MaxRightBorderSum = RightBorderSum; } /* 右边扫描结束 */ /* 下面返回&quot;治&quot;的结果 */ return getmaxint3( MaxLeftSum, MaxRightSum, MaxLeftBorderSum + MaxRightBorderSum ); } 算法4：在线处理法 int MaxSubseqSum4(int A[], int N) { int ThisSum, MaxSum; int i; ThisSum = MaxSum = 0; for( i = 0; i &lt; N; i++) { ThisSum += A[i]; if( ThisSum &gt; MaxSum) MaxSum = ThisSum; else if(ThisSum &lt; 0) ThisSum = 0; } return MaxSum; } //T(N) = O(N); ———————————————— 版权声明：本文为博主「Sofar」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。 原文链接：https://sofar1994.github.io/post/19111/ ","link":"https://www.vincent.ac.cn/post/zhuan-zai-lesslessshu-ju-jie-gou-yu-suan-fa-greatergreater-day1-zui-da-zi-lie-he/"},{"title":"laravel 学习之路  路由视图初探","content":"我大致了解了 laravel 下，在开始一个 Http 程序需要先定义路由。之前的例子中，我们的业务逻辑都是在路由里实现，这对于简单的网站或 web 应用没什么问题，当我们需要扩大规模，程序变得复杂，分层的业务逻辑更为适合。这时候，我们就应该使用控制器。 了解 MVC 的都对控制器的作用有所了解，控制器是实现主要业务逻辑的。在其他框架，控制器一般就是一个类，laravel 也不例外，laravel 的控制其结构并没有什么特殊。 &lt;?php namespace App\\Http\\Controllers; use App\\User; use App\\Http\\Controllers\\Controller; class UserController extends Controller { /** * @return string */ public function index($id) { return 'hello world!'; } } Route（路由）是什么？ 路由就是网络请求的 url 与 laravel 应用层的逻辑处理地址的对应关系。 通俗的说：路由就是把url的请求优雅的对应到你想要执行的操作方法，路由的作用是简化URL访问地址，并根据定义的路由类型做出正确的解析。 laravel 中的路由 跟路由器很像好比你家里只有一根网线网线上接着 wifi 路由器，多部手机和电脑就可以通过 wifi 上网了，路由器起到了一个分发的作用，大致是这样实现的 我们访问项目的时候最先请求到的是index.php这个入口文件这个 public/index.php 这个时候我们把public/index.php 比作网线，route/web.php 类比成路由器设备，controller控制器比作多部手机设备变很好理解 配置路由 laravel 的每一个路由是需要手动定义的，Laravel 的控制器非常的干净，与其他类的耦合度相当的低。得益于 laravel 的 IoC 容器，我们很容易实现相当丰富的功能，且不会产生紧密耦合。那么如何才能访问到这个控制器里的逻辑呢？ 我们所知道的许多框架，通常有着既定的路由规则，我个人比较熟悉 TP，TP 的默认路由规则是 http://xxxx/Module/Controller/Action，假如我们访问http://xxxx/Content/Home/index，默认会将请求派发至 Content 模块下的HomeController类的 index 方法。 ThinkPHP 这种默认路由规则使得框架开箱即用，十分便捷。但是这样并不灵活，假如我想通过访问 http://xxxx/user/1 就访问到 UserController 控制器下的 show 方法并包含一个值为 1 的参数，ThinkPHP 你需要修改配置（并且那个配置非常不优雅），亦或者我想要通过向 http://xxxx/topic POST 一个数据以添加一篇文章，处理这个过程的实际是 Admin\\TopicController 类的 create 方法，且该方法只接受 POST 请求，这时候似乎大多数框架就要通过写更多的代码实现了。 说到这里，似乎大家是不是想起了 laravel 那种路由定义方式的好处了？虽然 laravel 没有强加给你既定的路由规则，但你拥有了更多定制的权利，并且 laravel 定义路由的方式非常优雅，带给你的体验非常丰富。另一个好消息是，定义控制器路由和普通路由有所差别，这个差别是在便利性上的，你将很快感受到这种便利带给你的好处！ 打开 routes/web.php 我们直接看代码 其中 Route 是一个静态类 ，get是Route类的静态方法，get方法传递了2个参数，第一个是 / 、第二个是一个闭包并且在闭包函数中return返回的东西就是我们请求到的内容，从中可以看出 Route:: 后面可以跟一个请求方法代码中就是 get 请求，那么很容易就联想到如果写成 post 哪就表示是接受一个post请求 斜杠 / 表示首页 在 url 中就是域名后面的那个斜杠 study.laraveltest.com/ 只不过后面如果没有其他内容的话一般是被省略了于是我们就很容易的模仿一下 Route::get('test1', function () { return view('welcome'); }); 这样的写的话那 url 就应该是 http://study.laraveltest.com/article view 函数可以直接定位到 resources/views 目录，它可以接受一个参数这个参数就是 resources/views 目录下的文件名去掉 blade.php 后缀，这样我们创建一个hello.blade.php文件 里面写个hello world吧， 在注册下路由 Route::get('hello', function () { return view('hello'); }); 我们访问 http://study.laraveltest.com/hello 看到这样的内容就表示成功了； 如果访问 http://study.laraveltest.com/hello 报错可以试一下http://study.laraveltest.com/index.php/hello 加了 index.php 就正常了的话说明是没有成功开启 rewrite ； ","link":"https://www.vincent.ac.cn/post/laravel2/"},{"title":"laravel 学习之路  安装 ","content":"安装条件 安装需要的环境搞定后，咱在来说laravel的下载 composer 你需要安装好 composer [1] 配置好本地环境， PHP开发环境 我用的是 Homebrew [2] 安装的。 环境的安装网上很多教程我就不多描述了，最新版是 Laravel 6 让我们来大胆的学习最新版本 好现在我们来玩安装 （Laravel 6 中文文档） laravel 安装方式很多这里介绍两种 一种是使用 [^composer create-project]: composer 直接创建项目 composer create-project --prefer-dist laravel/laravel LaravelStudy 一种是 使用 laravel 的安装器； composer global require &quot;laravel/installer&quot; composer global后就可以各种 new 项目了； laravel new LaravelStudy 我选择了 laravel 安装器,因为更加方便并且可以直接从缓存中加载,速度更加快； 简单了解目录结构 我这边操作完有了一个LaravelStudy目录我们来看一下 目录是挺多的不过刚开始记住截图里标注的就好了 不过在我截图的时候发现并没有models目录于是我去翻看了官方文档 下面是官方解释 所以不用担心我们手动创建个Models就好了 访问Laravel public/index.php 文件是项目的入口文件，laravel 框架是单入口所有的请求都是先到 index.php ，也就是说我们在配置环境的时候，需要把根目录指向到 index.php 所在的目录，也就是 public 目录下面； nginx 是这样的； server { # ... root /Users/vincent/LocalProject/laravelStudy/public; # ... } 配置好目录我们就可以访问项目了； 打开 http://study.laraveltest.com/ 今天要学习实现的目标就达到了； PHP 世界的包管理工具 ↩︎ Homebrew是一款MacOS平台下的软件包管理工具 ↩︎ ","link":"https://www.vincent.ac.cn/post/laravel1/"},{"title":" Centos安装docker 以及 docker基本概念","content":"Centos 安装docker 更新update到最新的版本 yum update 卸载老版本docker yum remove docker docker-common docker-selinux docker-engine 安装需要的软件包 yum install -y yum-utils device-mapper-persistent-data lvm2 设置yum源 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 查看docker版本 yum list docker-ce --showduplicates|sort -r 安装docker yum install docker-ce-18.03.1.ce -y 启动docker systemctl start docker 加入开机自启 systemctl enable docker 配置国内镜像 vi /etc/docker/daemon.json { &quot;registry-mirrors&quot;: [&quot;http://hub-mirror.c.163.com&quot;] } Docker基本概念 Docker 包括三个基本概念: 镜像（Image） 容器（Container） 仓库（Repository） Docker 镜像就是一个只读的模板。 例如：一个镜像可以包含一个完整的 ubuntu 操作系统环境，里面仅安装了 Apache 或用户需要的其它应用程序。 镜像可以用来创建 Docker 容器。 Docker 提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。 Docker 容器 Docker 利用容器来运行应用。 容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。 可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。 Docker 仓库 仓库是集中存放镜像文件的场所。有时候会把仓库和仓库注册服务器（Registry）混为一谈，并不严格区分。实际上，仓库注册服务器上往往存放着多个仓库， 每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。 仓库分为公开仓库（Public）和私有仓库（Private）两种形式。 最大的公开仓库是 Docker Hub，存放了数量庞大的镜像供用户下载。 ","link":"https://www.vincent.ac.cn/post/docker2/"},{"title":"Docker是什么？","content":"Docker是什么？ Docker 是一个开源的应用容器引擎，你可以将其理解为一个轻量级的虚拟机，开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上。 为什么要使用 Docker？ 作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。 更高效的利用系统资源 由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。 无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数 量的应用。 更快速的启动时间 传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。 一致的运行环境 开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 持续交付和部署 对开发和运维（DevOps）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。 使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 Dockerfile 来进行镜像构建，并结合持续集成(Continuous Integration) 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署(Continuous Delivery/Deployment) 系统进行自动部署。 而且使用 Dockerfile 使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。 更轻松的迁移 由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。 更轻松的维护和扩展 Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker 团队同各个开源项目团队一起维护了一大批高质量的 官方镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 对比传统虚拟机总结 Docker 的主要用途，目前有三大类。 提供一次性的环境。比如，本地测试他人的软件、持续集成的时候提供单元测试和构建的环境。 提供弹性的云服务。因为 Docker 容器可以随开随关，很适合动态扩容和缩容。 组建微服务架构。通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构。 ","link":"https://www.vincent.ac.cn/post/docker1/"},{"title":"Hello Gridea","content":"👏 欢迎使用 Gridea ！ ✍️ Gridea 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... Github Gridea 主页 示例网站 特性👇 📝 你可以使用最酷的 Markdown 语法，进行快速创作 🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片 🏷️ 你可以对文章进行标签分组 📋 你可以自定义菜单，甚至可以创建外部链接菜单 💻 你可以在 𝖶𝗂𝗇𝖽𝗈𝗐𝗌 或 𝖬𝖺𝖼𝖮𝖲 设备上使用此客户端 🌎 你可以使用 𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌 或 Coding Pages 向世界展示，未来将支持更多平台 💬 你可以进行简单的配置，接入 Gitalk 或 DisqusJS 评论系统 🇬🇧 你可以使用中文简体或英语 🌁 你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力 🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步 🌱 当然 Gridea 还很年轻，有很多不足，但请相信，它会不停向前🏃 未来，它一定会成为你离不开的伙伴 尽情发挥你的才华吧！ 😘 Enjoy~ ","link":"https://www.vincent.ac.cn/post/hello-gridea/"}]}